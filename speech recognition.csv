repo_name,description,owner,topic,urls,user_api,repo_api,location
vosk-asterisk,Speech Recognition in Asterisk with Vosk Server,alphacep,"['asr', 'asterisk', 'speech-recognition', 'speech-to-text', 'vosk']",https://github.com/alphacep/vosk-asterisk,https://api.github.com/users/alphacep,https://api.github.com/repos/alphacep/vosk-asterisk,α Cep
edgedict,Working online speech recognition based on RNN Transducer. ( Trained model release available in release ),theblackcat102,"['asr', 'online-speech-recognition', 'openvino', 'rnn-transducer', 'speech', 'speech-recognition', 'speech-to-text']",https://github.com/theblackcat102/edgedict,https://api.github.com/users/theblackcat102,https://api.github.com/repos/theblackcat102/edgedict,"Taiwan, Taipei"
DeepAsr,Keras(Tensorflow) implementations of Automatic Speech Recognition,scionoftech,"['asr', 'deepspeech2', 'speech-recognition', 'speech-to-text']",https://github.com/scionoftech/DeepAsr,https://api.github.com/users/scionoftech,https://api.github.com/repos/scionoftech/DeepAsr,"Hyderabad, India"
DroidSpeech2.0,Android kotlin library for continuous speech recognition with localisations.,vikramezhil,[],https://github.com/vikramezhil/DroidSpeech2.0,https://api.github.com/users/vikramezhil,https://api.github.com/repos/vikramezhil/DroidSpeech2.0,"Bangalore, India"
Taris,Transformer-based online speech recognition system with TensorFlow 2,georgesterpu,"['audio-visual', 'audio-visual-speech-recognition', 'deep-learning', 'live-caption', 'mahcine-learning', 'multimodal', 'multimodal-deep-learning', 'online', 'python', 'speech-recognition', 'speech-recognizer', 'taris', 'tensorflow', 'tensorflow2', 'transformer']",https://github.com/georgesterpu/Taris,https://api.github.com/users/georgesterpu,https://api.github.com/repos/georgesterpu/Taris,Ireland
SpecAugment,SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,pyyush,"['automatic-speech-recognition', 'data-augmentation', 'librispeech', 'masking', 'specaugment', 'spectrogram']",https://github.com/pyyush/SpecAugment,https://api.github.com/users/pyyush,https://api.github.com/repos/pyyush/SpecAugment,United States
Hindi-ASR-Challenge,🎯 Speech Recognition Challenge by Speech Lab - IIT Madras,Syzygianinfern0,[],https://github.com/Syzygianinfern0/Hindi-ASR-Challenge,https://api.github.com/users/Syzygianinfern0,https://api.github.com/repos/Syzygianinfern0/Hindi-ASR-Challenge,"Earth, mostly."
node-red-contrib-voice2json,Node-RED nodes for local speech and intent recognition via voice2json,johanneskropf,[],https://github.com/johanneskropf/node-red-contrib-voice2json,https://api.github.com/users/johanneskropf,https://api.github.com/repos/johanneskropf/node-red-contrib-voice2json,Berlin
project_news_alan_ai,"In this video, we're going to build a Conversational Voice Controlled React News Application using Alan AI. Alan AI is a revolutionary speech recognition software that allows you to add voice capabilities to your applications. ",adrianhajdin,"['react', 'react-project', 'reactjs', 'voice-assistant', 'voice-recognition']",https://github.com/adrianhajdin/project_news_alan_ai,https://api.github.com/users/adrianhajdin,https://api.github.com/repos/adrianhajdin/project_news_alan_ai,Croatia
EmotionalConversionStarGAN,"This repository contains code to replicate results from the ICASSP 2020 paper ""StarGAN for Emotional Speech Conversion: Validated by Data Augmentation of End-to-End Emotion Recognition"".",glam-imperial,"['augsburg-university', 'data-augmentation', 'deep-learning', 'deep-neural-networks', 'emotion-recognition', 'generative-adversarial-network', 'icassp', 'icassp-2020', 'imperial-college-london', 'imperial-glam', 'speech-synthesis', 'stargan', 'stargan-vc']",https://github.com/glam-imperial/EmotionalConversionStarGAN,https://api.github.com/users/glam-imperial,https://api.github.com/repos/glam-imperial/EmotionalConversionStarGAN,"London, UK"
gujarati_speech_recognition,Offline speech recognition for Gujarati Language. ,sutariyaraj,"['asr', 'deeplearning', 'deepspeech', 'gujarati', 'speech-recognition']",https://github.com/sutariyaraj/gujarati_speech_recognition,https://api.github.com/users/sutariyaraj,https://api.github.com/repos/sutariyaraj/gujarati_speech_recognition,Germany
speech2text_keras,"This repository reports how to build a speech to text model to recognize short commands. Best of all, developing and including speech recognition in a Python project using Keras is really simple.",arthurfortes,"['deep-learning', 'keras', 'keras-tensorflow', 'python', 'speech-recognition', 'speech-to-text']",https://github.com/arthurfortes/speech2text_keras,https://api.github.com/users/arthurfortes,https://api.github.com/repos/arthurfortes/speech2text_keras,"Campinas, SP, Brazil"
SpeakingFaces,"A large-scale publicly-available visual-thermal-audio dataset designed to encourage research in the general areas of user authentication, facial recognition, speech recognition, and human-computer interaction. ",IS2AI,[],https://github.com/IS2AI/SpeakingFaces,https://api.github.com/users/IS2AI,https://api.github.com/repos/IS2AI/SpeakingFaces,"Nur-Sultan, Kazakhstan"
UnityAndroidSpeechRecognizer,🗣️ Speech recognition on Unity and Android without the annoying google popup!,EricBatlle,"['android', 'android-plugin', 'plugin', 'speech-recognition', 'speech-to-text', 'unity', 'unity3d']",https://github.com/EricBatlle/UnityAndroidSpeechRecognizer,https://api.github.com/users/EricBatlle,https://api.github.com/repos/EricBatlle/UnityAndroidSpeechRecognizer,"Barcelona, Spain"
Voice_Controlled_Mouse,A guide to Speech Recognition & GUI Automation in Python,arindomjit,[],https://github.com/arindomjit/Voice_Controlled_Mouse,https://api.github.com/users/arindomjit,https://api.github.com/repos/arindomjit/Voice_Controlled_Mouse,Singapore
speechbook,articles about speech recognition,ratsgo,['speech'],https://github.com/ratsgo/speechbook,https://api.github.com/users/ratsgo,https://api.github.com/repos/ratsgo/speechbook,Seoul
speech-emotion-recognition-using-self-attention,"Implementation of the paper ""Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning"" From INTERSPEECH 2019",KrishnaDN,"['deep-learning', 'emotion-recognition', 'speech', 'speech-emotion-recognition']",https://github.com/KrishnaDN/speech-emotion-recognition-using-self-attention,https://api.github.com/users/KrishnaDN,https://api.github.com/repos/KrishnaDN/speech-emotion-recognition-using-self-attention,Bengaluru
google-cloud-speech-webaudio,Speech recognition and synthesis using the Google Cloud Speech APIs integrated with the Web Audio API for microphone input and playback directly in the browser.,idevelop,[],https://github.com/idevelop/google-cloud-speech-webaudio,https://api.github.com/users/idevelop,https://api.github.com/repos/idevelop/google-cloud-speech-webaudio,"London, UK"
tal-asrd,Code for the Paper Speech Recognition and Multi-Speaker Diarization of Long Conversations,calclavia,[],https://github.com/calclavia/tal-asrd,https://api.github.com/users/calclavia,https://api.github.com/repos/calclavia/tal-asrd,California
BERT-like-is-All-You-Need,"The code for our INTERSPEECH 2020 paper - Jointly Fine-Tuning  ""BERT-like'"" Self Supervised Models to Improve Multimodal Speech Emotion Recognition",shamanez,"['bert-model', 'fine-tuning', 'multimodal-emotion-recognition', 'multimodal-representation', 'pretrained-models', 'self-supervised-learning', 'sentiment-analysis', 'speech-emotion-recognition']",https://github.com/shamanez/BERT-like-is-All-You-Need,https://api.github.com/users/shamanez,https://api.github.com/repos/shamanez/BERT-like-is-All-You-Need,Auckland New Zealand
ASRT_SpeechClient_JavaWeb,An JavaWeb client website for ASRT speech recognition system. 一个可用于ASRT语音识别系统的JavaWeb网站客户端,nl8590687,"['asrt-javaweb', 'asrt-speech-recognition', 'speech-recognition', 'speech-to-text']",https://github.com/nl8590687/ASRT_SpeechClient_JavaWeb,https://api.github.com/users/nl8590687,https://api.github.com/repos/nl8590687/ASRT_SpeechClient_JavaWeb,China
chatbot_verbal,"Python voice chatbot using NLTK , Speech Recognition  , Google text-to-speech , Scikit-learn ",nitinp14920914,[],https://github.com/nitinp14920914/chatbot_verbal,https://api.github.com/users/nitinp14920914,https://api.github.com/repos/nitinp14920914/chatbot_verbal,New Delhi 
Speech2dCNN_LSTM,A pytorch implementation of Speech emotion recognition using deep 1D & 2D CNN LSTM networks,RicardoP0,[],https://github.com/RicardoP0/Speech2dCNN_LSTM,https://api.github.com/users/RicardoP0,https://api.github.com/repos/RicardoP0/Speech2dCNN_LSTM,Chile
Indian-Sign-Language-Recognition,A deep learning based sign language recognition system for speech impaired people in India using Bag of Visual Words with Convolutional Neural Networks.,shag527,"['bag-of-visual-words', 'convolutional-neural-network', 'google-speech-recognition', 'surf-feature-extraction']",https://github.com/shag527/Indian-Sign-Language-Recognition,https://api.github.com/users/shag527,https://api.github.com/repos/shag527/Indian-Sign-Language-Recognition,Palampur
end-to-end_asr_pytorch,"Implements of CTC, Speech-Transformer and CIF for end-to-end speech recognition with pytorch",eastonYi,[],https://github.com/eastonYi/end-to-end_asr_pytorch,https://api.github.com/users/eastonYi,https://api.github.com/repos/eastonYi/end-to-end_asr_pytorch,China
SpeechEmotionRecognition-emodb,Speech Emotion Recognition,hellolzc,[],https://github.com/hellolzc/SpeechEmotionRecognition-emodb,https://api.github.com/users/hellolzc,https://api.github.com/repos/hellolzc/SpeechEmotionRecognition-emodb,China
ASR-SG-HMM-GMM,"speech recognition of digits based on single Gaussian, Gaussian Mixture, and Hidden Markov Models",yuweiwan,[],https://github.com/yuweiwan/ASR-SG-HMM-GMM,https://api.github.com/users/yuweiwan,https://api.github.com/repos/yuweiwan/ASR-SG-HMM-GMM,Baltimore
speech-emotion-recognition,Speech emotion recognition with PyTorch,terranivium,"['audio-analysis', 'data-science', 'deep-learning', 'librosa', 'neural-network', 'pytorch', 'signal-processing', 'speech-emotion-recognition']",https://github.com/terranivium/speech-emotion-recognition,https://api.github.com/users/terranivium,https://api.github.com/repos/terranivium/speech-emotion-recognition,"Glasgow, Scotland"
Classical-Speech-Algorithms,Classical speech recognition and speaker recognition algorithms,zhaoyi2,"['asr', 'speaker-recognition']",https://github.com/zhaoyi2/Classical-Speech-Algorithms,https://api.github.com/users/zhaoyi2,https://api.github.com/repos/zhaoyi2/Classical-Speech-Algorithms,beijing china
torgo_asr,A Kaldi recipe for training automatic speech recognition systems on the Torgo corpus of dysarthric speech,idiap,[],https://github.com/idiap/torgo_asr,https://api.github.com/users/idiap,https://api.github.com/repos/idiap/torgo_asr,"Centre du Parc, Martigny, Switzerland"
deep_mlp_ser,Repository for my paper: Deep Multilayer Perceptrons for Dimensional Speech Emotion Recognition,bagustris,"['paper-with-code', 'speech-emotion-recognition']",https://github.com/bagustris/deep_mlp_ser,https://api.github.com/users/bagustris,https://api.github.com/repos/bagustris/deep_mlp_ser,Tsukuba
Sumerian-Translation-Pipeline,"UrIII Period (Sumerian Language) Information Extraction pipeline including, Named Entity Recognition, Part Of Speech Tagging and Machine Translation",cdli-gh,[],https://github.com/cdli-gh/Sumerian-Translation-Pipeline,https://api.github.com/users/cdli-gh,https://api.github.com/repos/cdli-gh/Sumerian-Translation-Pipeline,"Los Angeles, Oxford, Berlin"
roby-chatbot,"Roby is an open source AI chatbot, with Local speech recognition and speech synthesis system.",ideamark,[],https://github.com/ideamark/roby-chatbot,https://api.github.com/users/ideamark,https://api.github.com/repos/ideamark/roby-chatbot,"Hangzhou, China"
Speech-Recognition,"Speech Recognition using HMM, GMM",goodnightng0,[],https://github.com/goodnightng0/Speech-Recognition,https://api.github.com/users/goodnightng0,https://api.github.com/repos/goodnightng0/Speech-Recognition,Seoul
labyrinth,Personal speech recognition project,ltbringer,[],https://github.com/ltbringer/labyrinth,https://api.github.com/users/ltbringer,https://api.github.com/repos/ltbringer/labyrinth,"Bengaluru, India"
speech-papers,"Summary of speech papers, including speech recognition,  AVSR, speech conversion.",zhaoyang9425,[],https://github.com/zhaoyang9425/speech-papers,https://api.github.com/users/zhaoyang9425,https://api.github.com/repos/zhaoyang9425/speech-papers,"Xi'an, Shaanxi, China"
vue-speech-input,"Vue Speech Input - Speech to text with Vue.js | Speech Recognition with Vue,js",SSBarik,"['hacktoberfest2020', 'hactoberfest', 'speech-input', 'speech-recognition', 'speech-to-text', 'vuejs', 'vuetifyjs', 'web-speech-api']",https://github.com/SSBarik/vue-speech-input,https://api.github.com/users/SSBarik,https://api.github.com/repos/SSBarik/vue-speech-input,India
Cali,Cali: A simple virtual assistant that demonstrates how to use Google Speech Recognition and IBM text to speech in Python,iamabeljoshua,"['ibm-watson', 'speech-recognition', 'speech-to-text', 'text-to-speech', 'virtual-assistant']",https://github.com/iamabeljoshua/Cali,https://api.github.com/users/iamabeljoshua,https://api.github.com/repos/iamabeljoshua/Cali,Abuja
ASR-HMM-DNN,speech recognition based on deep neural network/hidden markov model,yuweiwan,[],https://github.com/yuweiwan/ASR-HMM-DNN,https://api.github.com/users/yuweiwan,https://api.github.com/repos/yuweiwan/ASR-HMM-DNN,Baltimore
OfflineSpeechRecognition,Offline Speech Recognition For Android Library,shreyashghag,"['android', 'kotlin', 'kotlin-library', 'library', 'offline-speech-recognition', 'speech-recognition', 'speech-recognizer']",https://github.com/shreyashghag/OfflineSpeechRecognition,https://api.github.com/users/shreyashghag,https://api.github.com/repos/shreyashghag/OfflineSpeechRecognition,Mumbai
deepspeech-swiss-german,Automatic Speech Recognition (ASR) - Swiss-German,AASHISHAG,"['mozilla-deepspeech', 'speech-recognition', 'swiss', 'swiss-german']",https://github.com/AASHISHAG/deepspeech-swiss-german,https://api.github.com/users/AASHISHAG,https://api.github.com/repos/AASHISHAG/deepspeech-swiss-german,"Duisburg, Germany"
Real-Time-SR,Real time speech recognition model based on pytorch on android application,qute012,[],https://github.com/qute012/Real-Time-SR,https://api.github.com/users/qute012,https://api.github.com/repos/qute012/Real-Time-SR,"Daegu, Korea"
TChatBot,"A ChatBot framework to create customizable all purpose Chatbots using NLP, Tensorflow, Speech Recognition ",deepraj1729,"['artificial-intelligence', 'chatbot-framework', 'conda', 'deep-learning', 'framework', 'git', 'github', 'machine-learning', 'neural-networks', 'nlp', 'nltk', 'numpy', 'pip', 'pypi', 'python3', 'sklearn', 'speech-recognition', 'tensorflow', 'virtual-environment']",https://github.com/deepraj1729/TChatBot,https://api.github.com/users/deepraj1729,https://api.github.com/repos/deepraj1729/TChatBot,India
SpeechToText,Angular Speech to Text Continuous Recognition with Microsoft Cognitive services speech SDK,compuwizpiyu,[],https://github.com/compuwizpiyu/SpeechToText,https://api.github.com/users/compuwizpiyu,https://api.github.com/repos/compuwizpiyu/SpeechToText,Singapore
korerorero-speech-recognition,Providing speech recognition services.,ServiceInnovationLab,[],https://github.com/ServiceInnovationLab/korerorero-speech-recognition,https://api.github.com/users/ServiceInnovationLab,https://api.github.com/repos/ServiceInnovationLab/korerorero-speech-recognition,Aotearoa
Audio-recognition,Audio speech recognition,RusselZHANG,"['audio', 'signal-processing']",https://github.com/RusselZHANG/Audio-recognition,https://api.github.com/users/RusselZHANG,https://api.github.com/repos/RusselZHANG/Audio-recognition,Hangzhou
Gender-Recog-FOUR-STEP,Realization of  speech gender recognition within FOUR steps.,chentianyangWHU,[],https://github.com/chentianyangWHU/Gender-Recog-FOUR-STEP,https://api.github.com/users/chentianyangWHU,https://api.github.com/repos/chentianyangWHU/Gender-Recog-FOUR-STEP,"Wuchang District, Wuhan, Hubei P."
Ionic-5-Speech-Recognition,Ionic 5 code for creating a simple Speech Recognition app,lallen30,[],https://github.com/lallen30/Ionic-5-Speech-Recognition,https://api.github.com/users/lallen30,https://api.github.com/repos/lallen30/Ionic-5-Speech-Recognition,"Knoxville, TN"
speech-recognition,a device-state based speech recognition script,Sheldon1999,"['cmu-sphinx', 'pocketsphinx', 'python', 'speech-recognition']",https://github.com/Sheldon1999/speech-recognition,https://api.github.com/users/Sheldon1999,https://api.github.com/repos/Sheldon1999/speech-recognition,"Bareilly , India"
ASR_RL_Optimization,Optimization algorithm for Automated Speech Recognition Systems,ana-kuznetsova,[],https://github.com/ana-kuznetsova/ASR_RL_Optimization,https://api.github.com/users/ana-kuznetsova,https://api.github.com/repos/ana-kuznetsova/ASR_RL_Optimization,"Bloomington, IN"
Human-Speech-Recognition-for-Synchronous-IDE-with-CTC-Framework,Human Speech Recognition using Java and JSP,juilirk,[],https://github.com/juilirk/Human-Speech-Recognition-for-Synchronous-IDE-with-CTC-Framework,https://api.github.com/users/juilirk,https://api.github.com/repos/juilirk/Human-Speech-Recognition-for-Synchronous-IDE-with-CTC-Framework,"Pune , Maharashtra , India"
Jarvis,Jarvis using speech recognition in python,ankit1509,[],https://github.com/ankit1509/Jarvis,https://api.github.com/users/ankit1509,https://api.github.com/repos/ankit1509/Jarvis,"Rajasthan, India"
A-Simple-Browser-based-Alpha-Numeric-Prediction-and-Text-to-Speech-using-TensorFlow,A handwriting Recognition System with text to speech,ArchanGhosh,[],https://github.com/ArchanGhosh/A-Simple-Browser-based-Alpha-Numeric-Prediction-and-Text-to-Speech-using-TensorFlow,https://api.github.com/users/ArchanGhosh,https://api.github.com/repos/ArchanGhosh/A-Simple-Browser-based-Alpha-Numeric-Prediction-and-Text-to-Speech-using-TensorFlow,Kolkata
ArabicSpeechRecognitionML,Arabic Speech Recognition Model using both lipreading and voice recognition,omardroubi,[],https://github.com/omardroubi/ArabicSpeechRecognitionML,https://api.github.com/users/omardroubi,https://api.github.com/repos/omardroubi/ArabicSpeechRecognitionML,"Cupertino, CA"
ASR-Accent-Analysis,Analysis and investigating the confounding effect of accents in end-to-end Automatic Speech Recognition models.,archiki,"['accent-adaptation', 'accents', 'analysis', 'automatic-speech-recognition', 'deepspeech', 'end-to-end-learning', 'explainability', 'gradient-analysis', 'interpretability', 'mutual-information', 'paper', 'phones', 'probes', 'pytorch', 'representation-similarity']",https://github.com/archiki/ASR-Accent-Analysis,https://api.github.com/users/archiki,https://api.github.com/repos/archiki/ASR-Accent-Analysis,Mumbai
abalone,A speech recognition based input method for GNU/Linux desktops,Elleo,[],https://github.com/Elleo/abalone,https://api.github.com/users/Elleo,https://api.github.com/repos/Elleo/abalone,Newcastle
background_tts_stt,A flutter project to run speech recognition service in background.,umair13adil,"['android', 'filledstacks', 'flutter', 'mvvm-architecture', 'reactive-streams', 'speechtotext', 'texttospeech']",https://github.com/umair13adil/background_tts_stt,https://api.github.com/users/umair13adil,https://api.github.com/repos/umair13adil/background_tts_stt,"Islamabad, Pakistan"
bimodal-emotion-recognition,Bimodal emotion recognition from speech and text,Mr-Patty,[],https://github.com/Mr-Patty/bimodal-emotion-recognition,https://api.github.com/users/Mr-Patty,https://api.github.com/repos/Mr-Patty/bimodal-emotion-recognition,Moscow
speech_recognition,ASR( Automatic speech Recognition) and Audio analyser  ,altanai,[],https://github.com/altanai/speech_recognition,https://api.github.com/users/altanai,https://api.github.com/repos/altanai/speech_recognition,Seattle
keyword-spotter,Speech recognition API for keyword-spotting in audio files.,accraze,"['audio-files', 'keyword-spotter', 'machine-learning', 'speech-recognition-api']",https://github.com/accraze/keyword-spotter,https://api.github.com/users/accraze,https://api.github.com/repos/accraze/keyword-spotter,Zone 8b
speechrecognition-mfcc-dtw,speech recognition using MFCC and DTW,rakeshacharya-d,[],https://github.com/rakeshacharya-d/speechrecognition-mfcc-dtw,https://api.github.com/users/rakeshacharya-d,https://api.github.com/repos/rakeshacharya-d/speechrecognition-mfcc-dtw,Hyderabad/Chennai
ADReSS-Challenge2020,Alzheimer's Dementia Recognition through Spontaneous Speech,KarolChlasta,[],https://github.com/KarolChlasta/ADReSS-Challenge2020,https://api.github.com/users/KarolChlasta,https://api.github.com/repos/KarolChlasta/ADReSS-Challenge2020,"Warsaw, Poland"
Speech-Emotion-Recognition-with-Librosa,Building a Speech Emotion Recognition system that detects emotion from human speech tone using Scikit-learn library in Python,pranavvjha,[],https://github.com/pranavvjha/Speech-Emotion-Recognition-with-Librosa,https://api.github.com/users/pranavvjha,https://api.github.com/repos/pranavvjha/Speech-Emotion-Recognition-with-Librosa,"sliet, sanguur"
ccc_mse_ser,Repository for my paper: Evaluation of Error and Correlation-Based Loss Functions For Multitask Learning Dimensional Speech Emotion Recognition,bagustris,[],https://github.com/bagustris/ccc_mse_ser,https://api.github.com/users/bagustris,https://api.github.com/repos/bagustris/ccc_mse_ser,Tsukuba
Speech_recognition,Speech recognition,frankye1000,[],https://github.com/frankye1000/Speech_recognition,https://api.github.com/users/frankye1000,https://api.github.com/repos/frankye1000/Speech_recognition,Taiwan Hsinchu
recognition,speech recognition,Jiahao1999,[],https://github.com/Jiahao1999/recognition,https://api.github.com/users/Jiahao1999,https://api.github.com/repos/Jiahao1999/recognition,Hebei Normal University
Speech-Recognition,Speech Recognition,prem2597,[],https://github.com/prem2597/Speech-Recognition,https://api.github.com/users/prem2597,https://api.github.com/repos/prem2597/Speech-Recognition,Hyderabad
MyApplication2,Speech Recognition,novaariyanto,[],https://github.com/novaariyanto/MyApplication2,https://api.github.com/users/novaariyanto,https://api.github.com/repos/novaariyanto/MyApplication2,Pati
Speech-recognition-module-for-Python-supporting-several-engines-and-APIs-online-and-offline, speech_recognition,balaji11i,[],https://github.com/balaji11i/Speech-recognition-module-for-Python-supporting-several-engines-and-APIs-online-and-offline,https://api.github.com/users/balaji11i,https://api.github.com/repos/balaji11i/Speech-recognition-module-for-Python-supporting-several-engines-and-APIs-online-and-offline,"13.139949,80.252617"
Speech-To-Text-Recognition,Speech Recognition,pratikkaushik14,[],https://github.com/pratikkaushik14/Speech-To-Text-Recognition,https://api.github.com/users/pratikkaushik14,https://api.github.com/repos/pratikkaushik14/Speech-To-Text-Recognition,Gurugram
Ana,"Assistente feita em Python utilizando Speech_recognition, e APIs do Google",JN513,"['ana', 'api', 'api-client', 'audios', 'python3', 'speech-recognition', 'speech-to-text']",https://github.com/JN513/Ana,https://api.github.com/users/JN513,https://api.github.com/repos/JN513/Ana,"Minas Gerais, Brasil"
Covid19-SpeechRecognition,Web Covid-19 Speech Recognition - website for update information of covid-19 in province Indonesia with speech recognition,VieriLusen,"['climate-change', 'covid-19', 'speech-recognition']",https://github.com/VieriLusen/Covid19-SpeechRecognition,https://api.github.com/users/VieriLusen,https://api.github.com/repos/VieriLusen/Covid19-SpeechRecognition,Indonesia
asr-sclite-scoring-docker,"The docker for sclite, scoring utilities, part of SCTK - ""NIST Speech Recognition Scoring Toolkit (SCTK)""",vthily,"['docker', 'docker-compose', 'sclite']",https://github.com/vthily/asr-sclite-scoring-docker,https://api.github.com/users/vthily,https://api.github.com/repos/vthily/asr-sclite-scoring-docker,Singapore
Speech-Recognition-Color-Game,Speech Recognition Color Game using Speech recognition chrome API,splinekonstantin,[],https://github.com/splinekonstantin/Speech-Recognition-Color-Game,https://api.github.com/users/splinekonstantin,https://api.github.com/repos/splinekonstantin/Speech-Recognition-Color-Game,Shenzhen
Speech-Recognition-Python,"Speech Recognition using python, pyaudio and speech recognition module",created-by-varun,[],https://github.com/created-by-varun/Speech-Recognition-Python,https://api.github.com/users/created-by-varun,https://api.github.com/repos/created-by-varun/Speech-Recognition-Python,Bangalore
dimensional-ser,Repository for my paper: Dimensional Speech Emotion Recognition Using Acoustic Features and Word Embeddings using Multitask Learning,bagustris,"['dimensional-emotion', 'feature-fusion', 'speech-emotion-recognition']",https://github.com/bagustris/dimensional-ser,https://api.github.com/users/bagustris,https://api.github.com/repos/bagustris/dimensional-ser,Tsukuba
speech-to-text,Speech  Recognition using the web speech api,vishalibitwar,[],https://github.com/vishalibitwar/speech-to-text,https://api.github.com/users/vishalibitwar,https://api.github.com/repos/vishalibitwar/speech-to-text,"Nanded , Maharashtra"
WebSpeech,Speech Recognition using Web Speech API,AkmarNafi,[],https://github.com/AkmarNafi/WebSpeech,https://api.github.com/users/AkmarNafi,https://api.github.com/repos/AkmarNafi/WebSpeech,"Banglore, India"
F.R.I.D.A.Y,Simple AI assistant capable of Speech Recognition and minor tasks with text-to-speech feature,i-Rony,"['speech-recognition', 'text-to-speech']",https://github.com/i-Rony/F.R.I.D.A.Y,https://api.github.com/users/i-Rony,https://api.github.com/repos/i-Rony/F.R.I.D.A.Y,Dehradun
speech_recognition_using_python,Speech Recognition using Python,marcelocd,[],https://github.com/marcelocd/speech_recognition_using_python,https://api.github.com/users/marcelocd,https://api.github.com/repos/marcelocd/speech_recognition_using_python,"Goiânia - GO, Brasil"
Speech-Recognition,Speech Recognition in Python,ChristopherBrown1,[],https://github.com/ChristopherBrown1/Speech-Recognition,https://api.github.com/users/ChristopherBrown1,https://api.github.com/repos/ChristopherBrown1/Speech-Recognition,Orlando Florida
SpeechCode,Speech recognition for coding,riisatoro,[],https://github.com/riisatoro/SpeechCode,https://api.github.com/users/riisatoro,https://api.github.com/repos/riisatoro/SpeechCode,Ukrain
Python3_Workshop,"Computer Vision, Speech Recognition",kalpitmalviya,[],https://github.com/kalpitmalviya/Python3_Workshop,https://api.github.com/users/kalpitmalviya,https://api.github.com/repos/kalpitmalviya/Python3_Workshop,"Udaipur, Rajasthan"
speech-recognition,speech recognition using colab,andrewshiva,[],https://github.com/andrewshiva/speech-recognition,https://api.github.com/users/andrewshiva,https://api.github.com/repos/andrewshiva/speech-recognition,noida india
speech_recognition_test,speech recognition_test,huseyinyilmaz,[],https://github.com/huseyinyilmaz/speech_recognition_test,https://api.github.com/users/huseyinyilmaz,https://api.github.com/repos/huseyinyilmaz/speech_recognition_test," San Francisco, CA"
Speech-Recognition,Speech Recognition in Python,Sai-Phani-Shankar,[],https://github.com/Sai-Phani-Shankar/Speech-Recognition,https://api.github.com/users/Sai-Phani-Shankar,https://api.github.com/repos/Sai-Phani-Shankar/Speech-Recognition,Hyderabad
SpeechRecognizerDemo,Implementing Speech Recognition,Joule87,[],https://github.com/Joule87/SpeechRecognizerDemo,https://api.github.com/users/Joule87,https://api.github.com/repos/Joule87/SpeechRecognizerDemo,Uruguay
DEV287x,Speech Recognition Systems,dennislamcv1,[],https://github.com/dennislamcv1/DEV287x,https://api.github.com/users/dennislamcv1,https://api.github.com/repos/dennislamcv1/DEV287x,Malaysia
Speech_Recognition,Speech recognition and transcription,nel417,[],https://github.com/nel417/Speech_Recognition,https://api.github.com/users/nel417,https://api.github.com/repos/nel417/Speech_Recognition,Ozark Mountains
SpeechRec2,Speech recognition test,laitinent,[],https://github.com/laitinent/SpeechRec2,https://api.github.com/users/laitinent,https://api.github.com/repos/laitinent/SpeechRec2,Finland
Speech-Recognition,Speech Recognition Example,Brynm32,[],https://github.com/Brynm32/Speech-Recognition,https://api.github.com/users/Brynm32,https://api.github.com/repos/Brynm32/Speech-Recognition,Virginia
SRU-,SPEECH EMOTION RECOGNITION,iamphlegmatic,[],https://github.com/iamphlegmatic/SRU-,https://api.github.com/users/iamphlegmatic,https://api.github.com/repos/iamphlegmatic/SRU-,Noida 
speech-recognition,Azure speech-recognition sandbox,dawidPereira,[],https://github.com/dawidPereira/speech-recognition,https://api.github.com/users/dawidPereira,https://api.github.com/repos/dawidPereira/speech-recognition,Rzeszów
twitter-analytics-using-spark,Hate speech recognition,Dhivyaa21,[],https://github.com/Dhivyaa21/twitter-analytics-using-spark,https://api.github.com/users/Dhivyaa21,https://api.github.com/repos/Dhivyaa21/twitter-analytics-using-spark,"Ottawa, Canada."
Speech-Detection,JavaScript Speech Recognition,sachingowdaac,[],https://github.com/sachingowdaac/Speech-Detection,https://api.github.com/users/sachingowdaac,https://api.github.com/repos/sachingowdaac/Speech-Detection,"Bengaluru, Karnataka, India"
speech-recognition,speech-recognition using JS,DarrenKwonDev,[],https://github.com/DarrenKwonDev/speech-recognition,https://api.github.com/users/DarrenKwonDev,https://api.github.com/repos/DarrenKwonDev/speech-recognition,Seoul
Speech-Recognition,Python speech recognition app,akpante3,[],https://github.com/akpante3/Speech-Recognition,https://api.github.com/users/akpante3,https://api.github.com/repos/akpante3/Speech-Recognition,"Lagos, Nigeria"
Google-Speech-Recognition,Persian-Speech-Recognition,mohammadhasananisi,[],https://github.com/mohammadhasananisi/Google-Speech-Recognition,https://api.github.com/users/mohammadhasananisi,https://api.github.com/repos/mohammadhasananisi/Google-Speech-Recognition,"iran,qom"
speech_processing,speech recognition using HMM,jayprakashp,['digit-recognition-system'],https://github.com/jayprakashp/speech_processing,https://api.github.com/users/jayprakashp,https://api.github.com/repos/jayprakashp/speech_processing,IIT GUWAHATI
Speech_Recognition_Python,My First Speech Recognition.,AndylLow,[],https://github.com/AndylLow/Speech_Recognition_Python,https://api.github.com/users/AndylLow,https://api.github.com/repos/AndylLow/Speech_Recognition_Python,Istanbul/Turkey
SRP,Speech recognition project,ben-wycliff,[],https://github.com/ben-wycliff/SRP,https://api.github.com/users/ben-wycliff,https://api.github.com/repos/ben-wycliff/SRP,"Kampala, Uganda"
speech-recognition,Python speech recognition code,wittySana89,[],https://github.com/wittySana89/speech-recognition,https://api.github.com/users/wittySana89,https://api.github.com/repos/wittySana89/speech-recognition,"Brisbane, Australia"
Python-Speech-Recognition,Speech Recognition with Python,Hereiam123,[],https://github.com/Hereiam123/Python-Speech-Recognition,https://api.github.com/users/Hereiam123,https://api.github.com/repos/Hereiam123/Python-Speech-Recognition,"Orlando, FL"
speechrecognitor,Speech Recognition Tests,xavi-b,[],https://github.com/xavi-b/speechrecognitor,https://api.github.com/users/xavi-b,https://api.github.com/repos/xavi-b/speechrecognitor,"Paris, France"
speech-recognition-python,Speech recognition using python,iamsadiqshaik1,[],https://github.com/iamsadiqshaik1/speech-recognition-python,https://api.github.com/users/iamsadiqshaik1,https://api.github.com/repos/iamsadiqshaik1/speech-recognition-python,Chennai
speech-recog,speech recognition using google,smoke-hux,[],https://github.com/smoke-hux/speech-recog,https://api.github.com/users/smoke-hux,https://api.github.com/repos/smoke-hux/speech-recog,Nairobi-Kenya
speech-detection,JS30 - speech recognition ,jasoncollum,[],https://github.com/jasoncollum/speech-detection,https://api.github.com/users/jasoncollum,https://api.github.com/repos/jasoncollum/speech-detection,"Nashville, TN"
speech-recognition-api-test,Speech Recognition API Test,PaulloClara,['speech-recognition'],https://github.com/PaulloClara/speech-recognition-api-test,https://api.github.com/users/PaulloClara,https://api.github.com/repos/PaulloClara/speech-recognition-api-test,"Teresina, Brazil"
speech-emotion-recognition,Speech Emotion Recognition Repo,luisbch9,[],https://github.com/luisbch9/speech-emotion-recognition,https://api.github.com/users/luisbch9,https://api.github.com/repos/luisbch9/speech-emotion-recognition,Arequipa
Speech-Recognition-Python,Simple speech recognition code ,ranjeetraj198,[],https://github.com/ranjeetraj198/Speech-Recognition-Python,https://api.github.com/users/ranjeetraj198,https://api.github.com/repos/ranjeetraj198/Speech-Recognition-Python,India
web-speech-recognition,web-speech-recognition,DatsGawas,[],https://github.com/DatsGawas/web-speech-recognition,https://api.github.com/users/DatsGawas,https://api.github.com/repos/DatsGawas/web-speech-recognition,pune
Hanh-Nazneen-Project-Client,"React, Redux, Speech Recognition",nazneen1022,"['react', 'react-bootstrap', 'redux', 'redux-thunk', 'speech-recognition']",https://github.com/nazneen1022/Hanh-Nazneen-Project-Client,https://api.github.com/users/nazneen1022,https://api.github.com/repos/nazneen1022/Hanh-Nazneen-Project-Client,"Den Haag, Netherlands"
Speech-Recognition,Speech Recognition using Python,Moneshsoni,[],https://github.com/Moneshsoni/Speech-Recognition,https://api.github.com/users/Moneshsoni,https://api.github.com/repos/Moneshsoni/Speech-Recognition,Indore 
asr,Automatic Speech Recognition ( ASR ),yiyichanmyae,[],https://github.com/yiyichanmyae/asr,https://api.github.com/users/yiyichanmyae,https://api.github.com/repos/yiyichanmyae/asr,"Yangon, Myanmar"
Online-Speech-Recognition,Speech recognition short program.,RabiaRabbani,[],https://github.com/RabiaRabbani/Online-Speech-Recognition,https://api.github.com/users/RabiaRabbani,https://api.github.com/repos/RabiaRabbani/Online-Speech-Recognition,Pakistan
ASR,Speech Recognition Experiments,hamidali0391,[],https://github.com/hamidali0391/ASR,https://api.github.com/users/hamidali0391,https://api.github.com/repos/hamidali0391/ASR,"Lahore, Pakistan"
AppTest,Python speech_recognition,RustamKeneev,[],https://github.com/RustamKeneev/AppTest,https://api.github.com/users/RustamKeneev,https://api.github.com/repos/RustamKeneev/AppTest,Bishkek
speech_recognition,speech recognition-JARVIS,niladribit69,[],https://github.com/niladribit69/speech_recognition,https://api.github.com/users/niladribit69,https://api.github.com/repos/niladribit69/speech_recognition,Bhubaneswar
Speech-recognition,Speech recognition application,eryk-slowinski,[],https://github.com/eryk-slowinski/Speech-recognition,https://api.github.com/users/eryk-slowinski,https://api.github.com/repos/eryk-slowinski/Speech-recognition,Poland
speech_recognition,speech recognition python,theCodeNilesh,[],https://github.com/theCodeNilesh/speech_recognition,https://api.github.com/users/theCodeNilesh,https://api.github.com/repos/theCodeNilesh/speech_recognition,"Nashik,India"
Speech-Recognition,Javascript Speech Recognition App,NasreenKhalid,[],https://github.com/NasreenKhalid/Speech-Recognition,https://api.github.com/users/NasreenKhalid,https://api.github.com/repos/NasreenKhalid/Speech-Recognition,Pakistan
Speech-Speaker-Recognition,Speech and speaker recognition ,Yuhu-kth,[],https://github.com/Yuhu-kth/Speech-Speaker-Recognition,https://api.github.com/users/Yuhu-kth,https://api.github.com/repos/Yuhu-kth/Speech-Speaker-Recognition,"Stockholm, Sweden"
Speech_Recognition,Automatic Speech recognition,suvarnsingbhable,[],https://github.com/suvarnsingbhable/Speech_Recognition,https://api.github.com/users/suvarnsingbhable,https://api.github.com/repos/suvarnsingbhable/Speech_Recognition,Aurangabad
speech_recognition_V2,This the Version 2 of the Speech Recognition.,pranayjoshi,[],https://github.com/pranayjoshi/speech_recognition_V2,https://api.github.com/users/pranayjoshi,https://api.github.com/repos/pranayjoshi/speech_recognition_V2,India
godiscordspeechbot,Golang Discord bot with speech recognition and replies,Ayuei,[],https://github.com/Ayuei/godiscordspeechbot,https://api.github.com/users/Ayuei,https://api.github.com/repos/Ayuei/godiscordspeechbot,Australia
Speech-Sentiment-Analyzer,Speech Recognition and then identifying the sentiment in each sentences. ,python-academy,[],https://github.com/python-academy/Speech-Sentiment-Analyzer,https://api.github.com/users/python-academy,https://api.github.com/repos/python-academy/Speech-Sentiment-Analyzer,"Nagpur,Maharashtra,India"
SpeechRecognitionAI,Speech recognition AI based on FFNN in Java,viktorvano,[],https://github.com/viktorvano/SpeechRecognitionAI,https://api.github.com/users/viktorvano,https://api.github.com/repos/viktorvano/SpeechRecognitionAI,Bratislava
sign-lang-recog,American Sign Language Recognition and Conversion to Speech,sankalpshekhar14,[],https://github.com/sankalpshekhar14/sign-lang-recog,https://api.github.com/users/sankalpshekhar14,https://api.github.com/repos/sankalpshekhar14/sign-lang-recog,"Kolkata, India"
CAVILL-TheSmartCalculator,Voice controlled calculator which uses text-to-speech and speech-to-text (google API-speech recognition) including the basic calculator keys if internet is unstable.,rahulsingh237,[],https://github.com/rahulsingh237/CAVILL-TheSmartCalculator,https://api.github.com/users/rahulsingh237,https://api.github.com/repos/rahulsingh237/CAVILL-TheSmartCalculator,New Delhi
Speech-Recognition,Speech Recognition using python's speech recognition library and Google's Speech to Text API.,Akhilesh64,[],https://github.com/Akhilesh64/Speech-Recognition,https://api.github.com/users/Akhilesh64,https://api.github.com/repos/Akhilesh64/Speech-Recognition,Jammu
Speech-Recognition,Implementation of Runtime Speech Recognition,ekdnam,[],https://github.com/ekdnam/Speech-Recognition,https://api.github.com/users/ekdnam,https://api.github.com/repos/ekdnam/Speech-Recognition,Pune
Speech_Recognizer_Udacity,Speech Recognition with Neural Networks,inna-vogel,[],https://github.com/inna-vogel/Speech_Recognizer_Udacity,https://api.github.com/users/inna-vogel,https://api.github.com/repos/inna-vogel/Speech_Recognizer_Udacity,Darmstadt 
realtime-stt-demo,Realtime speech recognition demo application,iqtek,[],https://github.com/iqtek/realtime-stt-demo,https://api.github.com/users/iqtek,https://api.github.com/repos/iqtek/realtime-stt-demo,"Russia, Omsk"
odysseus,🏛 Speech Recognition wrapper for iOS,emannuelOC,[],https://github.com/emannuelOC/odysseus,https://api.github.com/users/emannuelOC,https://api.github.com/repos/emannuelOC/odysseus,"São Paulo, Brazil"
speechrecognition,Javascript30 Day 20 - Speech Recognition,dandyson,[],https://github.com/dandyson/speechrecognition,https://api.github.com/users/dandyson,https://api.github.com/repos/dandyson/speechrecognition,Grantham
Speech-recognition-AI,A simple speech recognition application,smj007,[],https://github.com/smj007/Speech-recognition-AI,https://api.github.com/users/smj007,https://api.github.com/repos/smj007/Speech-recognition-AI,"Coimbatore, Tamilnadu"
python-speech-assistant,Making a speech recognition application.,newedition994,[],https://github.com/newedition994/python-speech-assistant,https://api.github.com/users/newedition994,https://api.github.com/repos/newedition994/python-speech-assistant,"Boston, MA"
Flutter_Speech_Recognition,Flutter example for Speech recognition,Harshit564,[],https://github.com/Harshit564/Flutter_Speech_Recognition,https://api.github.com/users/Harshit564,https://api.github.com/repos/Harshit564/Flutter_Speech_Recognition,Punjab Engineering College
PY-Speech,Python Development for speech recognition,Devan0369,[],https://github.com/Devan0369/PY-Speech,https://api.github.com/users/Devan0369,https://api.github.com/repos/Devan0369/PY-Speech,US - California
python-speech-recognition,gTTS test for speech recognition,stefaneacsu147,"['gtts', 'python', 'python3', 'speech-recognition', 'text', 'to']",https://github.com/stefaneacsu147/python-speech-recognition,https://api.github.com/users/stefaneacsu147,https://api.github.com/repos/stefaneacsu147/python-speech-recognition,"Amsterdam, Netherlands"
speech-recognition,simple flutter speech-recognition app,atrishabhsharma,[],https://github.com/atrishabhsharma/speech-recognition,https://api.github.com/users/atrishabhsharma,https://api.github.com/repos/atrishabhsharma/speech-recognition,"Delhi , India"
SpeechRecognition,Speech Recognition with Microsoft CNTK,wsteams,"['atr503', 'audio-synthesis', 'cnn', 'cntk', 'common-voice', 'ctc', 'deep-learning', 'genre-classification', 'gtzan-dataset', 'mel-spectrogram', 'phoneme-prediction', 'rnn', 'speech-recognition', 'speech-to-text', 'transformer', 'voice-conversion', 'wavenet', 'wavernn']",https://github.com/wsteams/SpeechRecognition,https://api.github.com/users/wsteams,https://api.github.com/repos/wsteams/SpeechRecognition,Japan
he-s-listening,Repo for speech recognition codes,wduan1025,[],https://github.com/wduan1025/he-s-listening,https://api.github.com/users/wduan1025,https://api.github.com/repos/wduan1025/he-s-listening,NYC
Speech-recognition,speech recognition(Natural Language Processing),Fintecuriosity11,[],https://github.com/Fintecuriosity11/Speech-recognition,https://api.github.com/users/Fintecuriosity11,https://api.github.com/repos/Fintecuriosity11/Speech-recognition,"Seoul, Korea"
speech-recognition,Speech Recognition with Neural Networks,j-n-t,"['automatic-speech-recognition', 'natural-language-processing', 'nlp', 'speech-recognition']",https://github.com/j-n-t/speech-recognition,https://api.github.com/users/j-n-t,https://api.github.com/repos/j-n-t/speech-recognition,"Porto, Portugal"
Speech-to-Text-App,Speech Recognition App using java,SachindraFernando,[],https://github.com/SachindraFernando/Speech-to-Text-App,https://api.github.com/users/SachindraFernando,https://api.github.com/repos/SachindraFernando/Speech-to-Text-App,"Wennappuwa, Sri Lanka"
csr-pytorch,Continuous speech recognition using pytorch,gheyret,[],https://github.com/gheyret/csr-pytorch,https://api.github.com/users/gheyret,https://api.github.com/repos/gheyret/csr-pytorch,Japan
js-speech-recognition,Vanilla JS speech recognition game,angie-markov,[],https://github.com/angie-markov/js-speech-recognition,https://api.github.com/users/angie-markov,https://api.github.com/repos/angie-markov/js-speech-recognition,"Vancouver, BC"
Speech_Recognition,Simple speech recognition using python,tapajyotideb,[],https://github.com/tapajyotideb/Speech_Recognition,https://api.github.com/users/tapajyotideb,https://api.github.com/repos/tapajyotideb/Speech_Recognition,India
speech_recognition,localhost javascript speech recognition try,recchan13,[],https://github.com/recchan13/speech_recognition,https://api.github.com/users/recchan13,https://api.github.com/repos/recchan13/speech_recognition,"Bandar Lampung, Indonesia"
SERaaS-User-Management-Service,Basic Node.js API for handling generic user authentication and storage requirements for Speech Emotion Recognition as a Service.,SERaaS,"['authentication-backend', 'nodejs', 'swagger']",https://github.com/SERaaS/SERaaS-User-Management-Service,https://api.github.com/users/SERaaS,https://api.github.com/repos/SERaaS/SERaaS-User-Management-Service,Ireland
SSAFY_brbrbr,SSAFY_brbrbr: Indoor guide robot project through auto driving and speech recognition,humbleYoon,[],https://github.com/humbleYoon/SSAFY_brbrbr,https://api.github.com/users/humbleYoon,https://api.github.com/repos/humbleYoon/SSAFY_brbrbr,"Seoul, Republic of Korea"
kaldi_emo,Hidden Markov model (HMM)-based speech emotion recognition (SER) using Kaldi.,Maoshuiyang,[],https://github.com/Maoshuiyang/kaldi_emo,https://api.github.com/users/Maoshuiyang,https://api.github.com/repos/Maoshuiyang/kaldi_emo,Hong Kong
personalized_asr,[MTAP] Official implementation: A mechanism for personalized Automatic Speech Recognition for less frequently spoken languages: the Greek case,PanosAntoniadis,"['automatic-speech-recognition', 'clustering', 'dictation', 'personalization']",https://github.com/PanosAntoniadis/personalized_asr,https://api.github.com/users/PanosAntoniadis,https://api.github.com/repos/PanosAntoniadis/personalized_asr,"Amsterdam, Netherlands"
SpeechRobot,Web Audio Speech Synthesis and Speech Recognition Framework,Zlynt,"['speech-api', 'speech-processing', 'speech-recognition', 'speech-synthesis', 'speech-to-text']",https://github.com/Zlynt/SpeechRobot,https://api.github.com/users/Zlynt,https://api.github.com/repos/Zlynt/SpeechRobot,Portugal
Speech-Assistant-Project,Python app that uses speech recognition and text-to-speech,chetjones003,[],https://github.com/chetjones003/Speech-Assistant-Project,https://api.github.com/users/chetjones003,https://api.github.com/repos/chetjones003/Speech-Assistant-Project,"Beaumont, Texas"
valkyrie-assistant,"Python Speech Assistant: speech recognition, text-to-speech and Google text-to-speech API.",lashewi,[],https://github.com/lashewi/valkyrie-assistant,https://api.github.com/users/lashewi,https://api.github.com/repos/lashewi/valkyrie-assistant,"Colombo, Sri Lanka"
eve,Python Script using Google Speech Recognition & Google Text to Speech,charlyecastro,[],https://github.com/charlyecastro/eve,https://api.github.com/users/charlyecastro,https://api.github.com/repos/charlyecastro/eve,Seattle Wa
simple-speech-recon,Simple Speech Recognition Script Using Google Speech APIs,oosswwaalldd,[],https://github.com/oosswwaalldd/simple-speech-recon,https://api.github.com/users/oosswwaalldd,https://api.github.com/repos/oosswwaalldd/simple-speech-recon,Tampa FL
NLP-Speech-in-one-language-to-speech-in-other-language,Speech recognition and conversion into speech of any other language,Riturao,"['googlespeech', 'gtts', 'indian-language', 'indianlanguagenlp', 'nlp', 'nlp-apis', 'speech', 'speech-processing', 'speech-recognition', 'speech-synthesis', 'speech-to-text', 'speechrecognition']",https://github.com/Riturao/NLP-Speech-in-one-language-to-speech-in-other-language,https://api.github.com/users/Riturao,https://api.github.com/repos/Riturao/NLP-Speech-in-one-language-to-speech-in-other-language,Mumbai
Speech_Recognition,Speech to Text using Google Speech Recognition API,harsh1541,[],https://github.com/harsh1541/Speech_Recognition,https://api.github.com/users/harsh1541,https://api.github.com/repos/harsh1541/Speech_Recognition,Bangalore
AVSpeechToText,This is a sample demonstrating Speech Recognition using Speech Framework,caffieneToCode,[],https://github.com/caffieneToCode/AVSpeechToText,https://api.github.com/users/caffieneToCode,https://api.github.com/repos/caffieneToCode/AVSpeechToText,Pune
Speech-Command-Recognition,Speech Command recognition using 1-D Convolutional Neural Network for Tensor Flow Speech Recognition Challenge Dataset,anejaK,[],https://github.com/anejaK/Speech-Command-Recognition,https://api.github.com/users/anejaK,https://api.github.com/repos/anejaK/Speech-Command-Recognition,New York
AI-class-2020-1,Speech recognition practice - source from: https://realpython.com/python-speech-recognition/,Chatherina423,[],https://github.com/Chatherina423/AI-class-2020-1,https://api.github.com/users/Chatherina423,https://api.github.com/repos/Chatherina423/AI-class-2020-1,SEOUL
Machine-Learning-Models,"face identification & recognition, speech recognition , and Text Multi Classifier",AbdullahMoustafa,[],https://github.com/AbdullahMoustafa/Machine-Learning-Models,https://api.github.com/users/AbdullahMoustafa,https://api.github.com/repos/AbdullahMoustafa/Machine-Learning-Models,"Alexandria,Egypt"
liri-node-app,Basically Siri without the speech recognition,HunterLintz,[],https://github.com/HunterLintz/liri-node-app,https://api.github.com/users/HunterLintz,https://api.github.com/repos/HunterLintz/liri-node-app,"Lakeland, FL"
ann_multiclass,A deep learning model for speech recognition.,gsalvoni,[],https://github.com/gsalvoni/ann_multiclass,https://api.github.com/users/gsalvoni,https://api.github.com/repos/gsalvoni/ann_multiclass,"Vancouver, BC"
Voice-Data-Control,3D Speech-Recognition game project for dissertation.  ,DoryanSadi,[],https://github.com/DoryanSadi/Voice-Data-Control,https://api.github.com/users/DoryanSadi,https://api.github.com/repos/DoryanSadi/Voice-Data-Control,London
SpeechRecognition,My first experience in Speech Recognition.,we1come32,[],https://github.com/we1come32/SpeechRecognition,https://api.github.com/users/we1come32,https://api.github.com/repos/we1come32/SpeechRecognition,"Russia, Moscow"
number-guessing-speech-recognition,Speech recognition game using the HTML API.,ivanvgarcia,[],https://github.com/ivanvgarcia/number-guessing-speech-recognition,https://api.github.com/users/ivanvgarcia,https://api.github.com/repos/ivanvgarcia/number-guessing-speech-recognition,"Tokyo, Japan"
Speech-Recognition-spaCy-NLP,Speech recognition example with SpaCy NLP,dboland77,[],https://github.com/dboland77/Speech-Recognition-spaCy-NLP,https://api.github.com/users/dboland77,https://api.github.com/repos/dboland77/Speech-Recognition-spaCy-NLP,London
Utter,"Utter is a free ware windows API automation script.It can do most of the sapi dll functions.""SAPI"" stands for Windows Speech Reconition API,SAPI.dll is the file which manages the speech recognition of windows Utter utilises most of the SAPI  functions making use of the best potential of SAPI.dll,You can include speech  recognition to your project by using utter",thesunRider,[],https://github.com/thesunRider/Utter,https://api.github.com/users/thesunRider,https://api.github.com/repos/thesunRider/Utter,somewhere in the distant universe...
seq2seq-speech-recognition,A Seq2Seq Model for Speech Recognition System,neelrast,[],https://github.com/neelrast/seq2seq-speech-recognition,https://api.github.com/users/neelrast,https://api.github.com/repos/neelrast/seq2seq-speech-recognition,Ohio
speech-recognition-ml,Speech Recognition Kaggle competition - Tilburg University,IreneFP,[],https://github.com/IreneFP/speech-recognition-ml,https://api.github.com/users/IreneFP,https://api.github.com/repos/IreneFP/speech-recognition-ml,"New York, NY"
ml-speech,Fun with speech recognition and ml-algorithms,hhaydar,[],https://github.com/hhaydar/ml-speech,https://api.github.com/users/hhaydar,https://api.github.com/repos/hhaydar/ml-speech,"Bogotá, Colombia"
speechstamp,Speech recognition on top of OpenVINO,mdkcore0,[],https://github.com/mdkcore0/speechstamp,https://api.github.com/users/mdkcore0,https://api.github.com/repos/mdkcore0/speechstamp,"Florianópolis, Brazil"
DNN-Speech-Recognition,Deep Neural Network Speech Recognition Project,3ba2ii,"['asr', 'deep-neural-network', 'dnn', 'nanodegree', 'natural-language-processing', 'nlp', 'speech-recognition', 'vui']",https://github.com/3ba2ii/DNN-Speech-Recognition,https://api.github.com/users/3ba2ii,https://api.github.com/repos/3ba2ii/DNN-Speech-Recognition,Egypt
speechrecognitionlab,my experiment repo for speech recognition,emkamal,[],https://github.com/emkamal/speechrecognitionlab,https://api.github.com/users/emkamal,https://api.github.com/repos/emkamal/speechrecognitionlab,Helsinki
rnspeech,Testing speech recognition in react native.,johnbowdenatfacet,[],https://github.com/johnbowdenatfacet/rnspeech,https://api.github.com/users/johnbowdenatfacet,https://api.github.com/repos/johnbowdenatfacet/rnspeech,Brisbane
TensorFlow_Speech_Recognition_Challenge,Repository for the TensorFlow Speech Recognition Challenge,JamieMcQuire23,[],https://github.com/JamieMcQuire23/TensorFlow_Speech_Recognition_Challenge,https://api.github.com/users/JamieMcQuire23,https://api.github.com/repos/JamieMcQuire23/TensorFlow_Speech_Recognition_Challenge,Newcastle upon Tyne
Speech-Recognition-App,Guess number app with Speech Recognition,julianoperin,[],https://github.com/julianoperin/Speech-Recognition-App,https://api.github.com/users/julianoperin,https://api.github.com/repos/julianoperin/Speech-Recognition-App,Jersey City - NJ
js-speech,Practicing using speech recognition with vanilla JS,sachinm78,[],https://github.com/sachinm78/js-speech,https://api.github.com/users/sachinm78,https://api.github.com/repos/sachinm78/js-speech,"Chicago, IL"
speech_recognition,Speech Recognition in Python (Basic Programming),nipundeept,[],https://github.com/nipundeept/speech_recognition,https://api.github.com/users/nipundeept,https://api.github.com/repos/nipundeept/speech_recognition,"Bhagalpur, Bihar"
CSound,digit recognition by voice and speech analysis,canxkoz,[],https://github.com/canxkoz/CSound,https://api.github.com/users/canxkoz,https://api.github.com/repos/canxkoz/CSound,"Ix, Alkalurops"
SummerAI,Virtual Assistant AI with Speech Recognition,neves768,[],https://github.com/neves768/SummerAI,https://api.github.com/users/neves768,https://api.github.com/repos/neves768/SummerAI,"Natal, Rio Grande do Norte, Brazil"
OpenEarsSample1,OpenEars SDK sample app: Offline speech recognition,tatsuyamoriguchi,[],https://github.com/tatsuyamoriguchi/OpenEarsSample1,https://api.github.com/users/tatsuyamoriguchi,https://api.github.com/repos/tatsuyamoriguchi/OpenEarsSample1,"Irvine, California U.S.A."
speechary,Project speech recognition and summarization for virushack,TikhonP,[],https://github.com/TikhonP/speechary,https://api.github.com/users/TikhonP,https://api.github.com/repos/TikhonP/speechary,Moscow
SR-Functions,Azure Function applications for speech recognition,meerfolk,[],https://github.com/meerfolk/SR-Functions,https://api.github.com/users/meerfolk,https://api.github.com/repos/meerfolk/SR-Functions,"Russia, Chelyabinsk"
Alexander-Speech-Assistant,A python speech assistant using voice recognition ,cardosoIsaac,[],https://github.com/cardosoIsaac/Alexander-Speech-Assistant,https://api.github.com/users/cardosoIsaac,https://api.github.com/repos/cardosoIsaac/Alexander-Speech-Assistant,Texas
gbui_speech_recognition,Speech recognition though Python and subsequent libraries,MorganReilly,[],https://github.com/MorganReilly/gbui_speech_recognition,https://api.github.com/users/MorganReilly,https://api.github.com/repos/MorganReilly/gbui_speech_recognition,Galway
speech-recognition-poc,Proof of concept for speech recognition api,josephscha,[],https://github.com/josephscha/speech-recognition-poc,https://api.github.com/users/josephscha,https://api.github.com/repos/josephscha/speech-recognition-poc,NYC
J.A.R.V.I.S,"A speech recognition AI, built using Python ",DoryanSadi,[],https://github.com/DoryanSadi/J.A.R.V.I.S,https://api.github.com/users/DoryanSadi,https://api.github.com/repos/DoryanSadi/J.A.R.V.I.S,London
jarvis_as_alice,A speech recognition assistance in python,Anunema,[],https://github.com/Anunema/jarvis_as_alice,https://api.github.com/users/Anunema,https://api.github.com/repos/Anunema/jarvis_as_alice,indore
lisn-vuejs-front,Note taking service using speech recognition,1nthek,[],https://github.com/1nthek/lisn-vuejs-front,https://api.github.com/users/1nthek,https://api.github.com/repos/1nthek/lisn-vuejs-front,"Seoul, Korea"
SpeechRec,basic speech recognition app for English language,zladzeyka,[],https://github.com/zladzeyka/SpeechRec,https://api.github.com/users/zladzeyka,https://api.github.com/repos/zladzeyka/SpeechRec,Munich
UnitySpeechRecognition,Unity basic speech recognition using Microsoft Cortana.,Mikeultron,[],https://github.com/Mikeultron/UnitySpeechRecognition,https://api.github.com/users/Mikeultron,https://api.github.com/repos/Mikeultron/UnitySpeechRecognition,Indonesia
ImpairedVoiceASR,Mandarin Speech Recognition for Impaired Voice,voidism,[],https://github.com/voidism/ImpairedVoiceASR,https://api.github.com/users/voidism,https://api.github.com/repos/voidism/ImpairedVoiceASR,"Cambridge, Massachusetts"
wildspeech,Speech emotion recognition in the wild,tabahi,[],https://github.com/tabahi/wildspeech,https://api.github.com/users/tabahi,https://api.github.com/repos/tabahi/wildspeech,"Bournemouth, UK"
raspi_respeaker,Code samples for raspi speech recognition demo,fhswf,[],https://github.com/fhswf/raspi_respeaker,https://api.github.com/users/fhswf,https://api.github.com/repos/fhswf/raspi_respeaker,"Iserlohn, Germany"
speech-recognition-telop,Speech Recognition Telop for Japanese broadcasting,SKAsApp,[],https://github.com/SKAsApp/speech-recognition-telop,https://api.github.com/users/SKAsApp,https://api.github.com/repos/SKAsApp/speech-recognition-telop,"Niigata, Japan"
Speak-Number-Guessing-Game-Speech-Recognition,Number Guessing game with speech recognition,SebastianPrzyimka,[],https://github.com/SebastianPrzyimka/Speak-Number-Guessing-Game-Speech-Recognition,https://api.github.com/users/SebastianPrzyimka,https://api.github.com/repos/SebastianPrzyimka/Speak-Number-Guessing-Game-Speech-Recognition,"Glasgow, Scotland"
speech-api-game,A Speech Recognition API based game ,vivekdogra02,[],https://github.com/vivekdogra02/speech-api-game,https://api.github.com/users/vivekdogra02,https://api.github.com/repos/vivekdogra02/speech-api-game,india
gocorona_speech_recogn,Go corona speech recognition hand sanitiser dispenser,J3Patel,[],https://github.com/J3Patel/gocorona_speech_recogn,https://api.github.com/users/J3Patel,https://api.github.com/repos/J3Patel/gocorona_speech_recogn,"Pune, India"
Speech-To-Recognition-Audio-to-text,Speech To Recognition code with python programming,abhaychougule,[],https://github.com/abhaychougule/Speech-To-Recognition-Audio-to-text,https://api.github.com/users/abhaychougule,https://api.github.com/repos/abhaychougule/Speech-To-Recognition-Audio-to-text,PUNE
ASREngine,Automatic Speech Recognition Engine for Swahili Language ,NickDawson,[],https://github.com/NickDawson/ASREngine,https://api.github.com/users/NickDawson,https://api.github.com/repos/NickDawson/ASREngine,Dar-es-salaam
Automatic-Speech-Recognition,Project: Speech Recognition with Neural Networks,gaurav0535,[],https://github.com/gaurav0535/Automatic-Speech-Recognition,https://api.github.com/users/gaurav0535,https://api.github.com/repos/gaurav0535/Automatic-Speech-Recognition,Noida
Speech2Text,AWS and GCP Speech to text recognition,nsollazzo,[],https://github.com/nsollazzo/Speech2Text,https://api.github.com/users/nsollazzo,https://api.github.com/repos/nsollazzo/Speech2Text,Milan
SpeechRecogniser,A speech recognition module utilising PocketSphinx.,simonmeaden,[],https://github.com/simonmeaden/SpeechRecogniser,https://api.github.com/users/simonmeaden,https://api.github.com/repos/simonmeaden/SpeechRecogniser,"Paignton, Devon, United Kingdom"
MoniqueAssistant,assistant using speech recognition called Monique,TomLeCollegue,[],https://github.com/TomLeCollegue/MoniqueAssistant,https://api.github.com/users/TomLeCollegue,https://api.github.com/repos/TomLeCollegue/MoniqueAssistant,"Chambery, FRANCE"
speech-emotion-recognition,Speech Emotion Recognition using CNN with Keras,Mbuhliagah,[],https://github.com/Mbuhliagah/speech-emotion-recognition,https://api.github.com/users/Mbuhliagah,https://api.github.com/repos/Mbuhliagah/speech-emotion-recognition,Saudi Arabia
Mini-Project_Speech_Recognation,Speech Emotion Recognition with python library librosa,I-Unicode-I,[],https://github.com/I-Unicode-I/Mini-Project_Speech_Recognation,https://api.github.com/users/I-Unicode-I,https://api.github.com/repos/I-Unicode-I/Mini-Project_Speech_Recognation,Ukraine
web-speech-recognition,Minimal web application to demonstrate Speech Recognition.,cseas,[],https://github.com/cseas/web-speech-recognition,https://api.github.com/users/cseas,https://api.github.com/repos/cseas/web-speech-recognition,"Bangalore, India"
speech_emotion_app,A speech emotion recognition Flask application ,moe-dev,[],https://github.com/moe-dev/speech_emotion_app,https://api.github.com/users/moe-dev,https://api.github.com/repos/moe-dev/speech_emotion_app,Canada
speech-recognition-python,A simple speech recognition using Python 3,HackerApe,[],https://github.com/HackerApe/speech-recognition-python,https://api.github.com/users/HackerApe,https://api.github.com/repos/HackerApe/speech-recognition-python,"Ottawa, Canada"
Recorder4ASR,Simple Record Tool for Speech Recognition,voidism,[],https://github.com/voidism/Recorder4ASR,https://api.github.com/users/voidism,https://api.github.com/repos/voidism/Recorder4ASR,"Cambridge, Massachusetts"
Speech_Recognition,Speech Recognition and Text-To-Speech implemented using Google Text-To-Speech Service.,ishandeveloper,"['google-speech-recognition', 'gtts', 'pyaudio', 'python', 'python-speechrecognition', 'speech-recognition', 'speech-to-text', 'text-to-speech']",https://github.com/ishandeveloper/Speech_Recognition,https://api.github.com/users/ishandeveloper,https://api.github.com/repos/ishandeveloper/Speech_Recognition,"Chandigarh, India"
BASIC-SPEECH-RECOGNITION-CHATBOT,"This basic speech recognition chatbot is made using pyown, pyttsx3, pygame and speech_recognition library in Python language.",jawadSajid,[],https://github.com/jawadSajid/BASIC-SPEECH-RECOGNITION-CHATBOT,https://api.github.com/users/jawadSajid,https://api.github.com/repos/jawadSajid/BASIC-SPEECH-RECOGNITION-CHATBOT,"Lahore, Pakistan"
simple-sr,A speech recognition app that can perform a few trivial tasks.,CharlesIvia,[],https://github.com/CharlesIvia/simple-sr,https://api.github.com/users/CharlesIvia,https://api.github.com/repos/CharlesIvia/simple-sr,"Nairobi, Kenya"
asr-wer,Simple Single File C++ Implementation for WER Calculation for Evaluating Automatic Speech Recognition,alokprasad,[],https://github.com/alokprasad/asr-wer,https://api.github.com/users/alokprasad,https://api.github.com/repos/alokprasad/asr-wer,India
Trigger_word_detection,Trigger word ( like ok google / alexa / hey siri ) detection using Attention. ---------- focus: Speech Recognition,VighneshNatarajanGanesh,[],https://github.com/VighneshNatarajanGanesh/Trigger_word_detection,https://api.github.com/users/VighneshNatarajanGanesh,https://api.github.com/repos/VighneshNatarajanGanesh/Trigger_word_detection,"Pilani, Rajasthan, India"
Domain-specific-ASR-with-Nvidia-NeMo,A deep learning project for automatic speech recognition in Spanish (for Gong.io),bstanie,[],https://github.com/bstanie/Domain-specific-ASR-with-Nvidia-NeMo,https://api.github.com/users/bstanie,https://api.github.com/repos/bstanie/Domain-specific-ASR-with-Nvidia-NeMo,"Tel Aviv, Israel"
speech-recognition-nn,Speech recognition of digits. The model predicts the digits which are spoken.,nipun24,[],https://github.com/nipun24/speech-recognition-nn,https://api.github.com/users/nipun24,https://api.github.com/repos/nipun24/speech-recognition-nn,"New Delhi, India"
ASR-for-Hindi,Creating an Automatic Speech Recognition Pipeline for Hindi using the Kaldi toolkit.,OhmVikrant,[],https://github.com/OhmVikrant/ASR-for-Hindi,https://api.github.com/users/OhmVikrant,https://api.github.com/repos/OhmVikrant/ASR-for-Hindi,"Roorkee, Uttarakhand, India"
Speech_Recognition_Using_MATLAB,Implementation of Speech Recognition System in MATLAB Environment using Correlation as well as using MFCC and DTW Algorithms.,AdityaKshettri,"['dtw-algorithm', 'feature-extraction', 'matlab', 'mfcc-algorithm', 'speech-recognition']",https://github.com/AdityaKshettri/Speech_Recognition_Using_MATLAB,https://api.github.com/users/AdityaKshettri,https://api.github.com/repos/AdityaKshettri/Speech_Recognition_Using_MATLAB,Bangalore
transcriptor-frontend,:zap: A rich Transcription based editor integrating the re-speak and speech APIs allowing the user to communicate directly with the Automatic Speech Recognition system (ASR) into a web based service for post transcription processing. (Mirror),CodHeK,[],https://github.com/CodHeK/transcriptor-frontend,https://api.github.com/users/CodHeK,https://api.github.com/repos/CodHeK/transcriptor-frontend,"New York, United States"
speech_assistant,A python speech assistant app built with Google Speech Recognition technology,BradleyTim,[],https://github.com/BradleyTim/speech_assistant,https://api.github.com/users/BradleyTim,https://api.github.com/repos/BradleyTim/speech_assistant,Nairobi
Speech-Assistant,"Python based Speech Assistant using speech_recognition, playsound and gTTS utilities",zawster,"['python', 'speech-assistant', 'speech-recognition', 'speech-to-text']",https://github.com/zawster/Speech-Assistant,https://api.github.com/users/zawster,https://api.github.com/repos/zawster/Speech-Assistant,Pakistan
voice-chatbot-with-vb-dotnet,Developed a chatbot that uses speech recognition to detect language and applies speech synthesis to convert text to speech.,ruplsingh,"['csharp', 'speech-recognition']",https://github.com/ruplsingh/voice-chatbot-with-vb-dotnet,https://api.github.com/users/ruplsingh,https://api.github.com/repos/ruplsingh/voice-chatbot-with-vb-dotnet,Dublin
speechRecognitionTranscriber,speechRecognitionTranscriber: Implementation of video / audio to text transcriber using speech recognition with the Google Speech API.,davidvelascogarcia,"['audio', 'audio-files', 'audio-processing', 'converts', 'google-translate', 'python', 'speech-recognition', 'transcriber']",https://github.com/davidvelascogarcia/speechRecognitionTranscriber,https://api.github.com/users/davidvelascogarcia,https://api.github.com/repos/davidvelascogarcia/speechRecognitionTranscriber,Spain
Virtual-Assistant,In this project i used speech recognition module  by using pyttx3(python text to speech module).,ankitsingh8046,[],https://github.com/ankitsingh8046/Virtual-Assistant,https://api.github.com/users/ankitsingh8046,https://api.github.com/repos/ankitsingh8046/Virtual-Assistant,"kharar,Punjab"
python-speech-assistant,python package speech recognition with google text to speech and a few more needed imports...,matthewlukebyrne,"['gtts-api', 'python3']",https://github.com/matthewlukebyrne/python-speech-assistant,https://api.github.com/users/matthewlukebyrne,https://api.github.com/repos/matthewlukebyrne/python-speech-assistant,Dublin
speech_recognition,Build a model on speech recognition using gTTS (google text to speech),aakash804,[],https://github.com/aakash804/speech_recognition,https://api.github.com/users/aakash804,https://api.github.com/repos/aakash804/speech_recognition,Bangalore
voice-text,built a speech assistant app using the speech recognition library and Google's text-to-speech API.,therealPatrick,[],https://github.com/therealPatrick/voice-text,https://api.github.com/users/therealPatrick,https://api.github.com/repos/therealPatrick/voice-text,beijing 
SpeechToText,Speech to Text Application using Web Speech Recognition API and JS.,hemantsaini-7,[],https://github.com/hemantsaini-7/SpeechToText,https://api.github.com/users/hemantsaini-7,https://api.github.com/repos/hemantsaini-7/SpeechToText,"Jaipur, Rajasthan"
awesome-speech-recognition-speech-synthesis-papers,"Speech synthesis, voice conversion, self-supervised learning, music generation,Automatic Speech Recognition, Speaker Verification, Speech Synthesis, Language Modeling",eric-erki,[],https://github.com/eric-erki/awesome-speech-recognition-speech-synthesis-papers,https://api.github.com/users/eric-erki,https://api.github.com/repos/eric-erki/awesome-speech-recognition-speech-synthesis-papers,Earth...
Speech_To_Text_Recognition,Code Implemented for Speech to text functionality using Google Speech Recognition.,sakshamjn,[],https://github.com/sakshamjn/Speech_To_Text_Recognition,https://api.github.com/users/sakshamjn,https://api.github.com/repos/sakshamjn/Speech_To_Text_Recognition,"Delhi, India"
Voice_Prescription, Prescription data can be generated automatically using Speech Recognition module. ,sonal1999,[],https://github.com/sonal1999/Voice_Prescription,https://api.github.com/users/sonal1999,https://api.github.com/repos/sonal1999/Voice_Prescription,Narayangaon
speech_recognition,Basic Speech Recognition with python 3.7.5,egin10,[],https://github.com/egin10/speech_recognition,https://api.github.com/users/egin10,https://api.github.com/repos/egin10/speech_recognition,"Malang, Indonesia"
GRE-vocab,A fun vocabulary quiz game (speech recognition enabled).,vikash423q,"['javascript', 'portfolio', 'react']",https://github.com/vikash423q/GRE-vocab,https://api.github.com/users/vikash423q,https://api.github.com/repos/vikash423q/GRE-vocab,Kolkata
asr-lab-e6870,my solution to labs of automatic speech recognition course e6870.,w1d2s,[],https://github.com/w1d2s/asr-lab-e6870,https://api.github.com/users/w1d2s,https://api.github.com/repos/w1d2s/asr-lab-e6870,"Beijing,China"
speech_recognition_and_AI,Collection of my work in Speech Recognition and AI,baiden00,[],https://github.com/baiden00/speech_recognition_and_AI,https://api.github.com/users/baiden00,https://api.github.com/repos/baiden00/speech_recognition_and_AI,USA
SimpleVoiceSearch,Voice Search on YouTube by implementing speech recognition module,ahmedbr,[],https://github.com/ahmedbr/SimpleVoiceSearch,https://api.github.com/users/ahmedbr,https://api.github.com/repos/ahmedbr/SimpleVoiceSearch,"Istanbul , Turkey"
Artificial-Intelligence-Digital-Assistant-KAREN-,It is an AI Assistant work with your speech recognition.,Akashsingh310,[],https://github.com/Akashsingh310/Artificial-Intelligence-Digital-Assistant-KAREN-,https://api.github.com/users/Akashsingh310,https://api.github.com/repos/Akashsingh310/Artificial-Intelligence-Digital-Assistant-KAREN-,DELHI
hello-pyri,A basic example of speech recognition in Python.,charlesmartinreed,[],https://github.com/charlesmartinreed/hello-pyri,https://api.github.com/users/charlesmartinreed,https://api.github.com/repos/charlesmartinreed/hello-pyri,"Dallas, Texas"
spamrecognition,Spam Call detection using Speech Recognition and Text Mining,chatterjeesubhajit,[],https://github.com/chatterjeesubhajit/spamrecognition,https://api.github.com/users/chatterjeesubhajit,https://api.github.com/repos/chatterjeesubhajit/spamrecognition,"Texas, USA"
mb-1.0,This is a simple conversational robot that uses speech recognition.,olabode-dev,[],https://github.com/olabode-dev/mb-1.0,https://api.github.com/users/olabode-dev,https://api.github.com/repos/olabode-dev/mb-1.0,"Lagos, Nigeria"
Corona-Assistant,Command line Speech recognition Tool as Covid data analyzer,powerexploit,"['coronavirus', 'scraping', 'speech-recognition']",https://github.com/powerexploit/Corona-Assistant,https://api.github.com/users/powerexploit,https://api.github.com/repos/powerexploit/Corona-Assistant,India
Python-Speech-Recognition,This program uses Google API for speech recognition,amberkakkar01,"['speech-recognition', 'speech-recognizer', 'speechrecognition']",https://github.com/amberkakkar01/Python-Speech-Recognition,https://api.github.com/users/amberkakkar01,https://api.github.com/repos/amberkakkar01/Python-Speech-Recognition,DehraDun India
nlp-solverminds,"NLP pipeline (Reading text from files .doc, .docx, .pdf, .txt; Basic text cleaning; Tokenization; Stemming; Lemmatization; Feature extraction; Sentiment detection; Topical modelling; Part-of-speech tagging; Word sense disambiguation; Text summarization; Named entity recognition; Relationship extraction; Terminology extraction)",askaydevs,[],https://github.com/askaydevs/nlp-solverminds,https://api.github.com/users/askaydevs,https://api.github.com/repos/askaydevs/nlp-solverminds,Earth
Speech-System,It contains the speech recognition system built on Reactjs,kumar184,[],https://github.com/kumar184/Speech-System,https://api.github.com/users/kumar184,https://api.github.com/repos/kumar184/Speech-System,Bangalore
Virtual-Assistant,A basic virtual assistant using python speech recognition feature.,Yutish,[],https://github.com/Yutish/Virtual-Assistant,https://api.github.com/users/Yutish,https://api.github.com/repos/Yutish/Virtual-Assistant,"Kolkata, West Bengal, India"
Intelligent-Assistant,Speech Recognition bot with multi-threading and inter-process communication,BurairAbbas,[],https://github.com/BurairAbbas/Intelligent-Assistant,https://api.github.com/users/BurairAbbas,https://api.github.com/repos/BurairAbbas/Intelligent-Assistant,"Karachi, Pakistan"
docker-deepspeech-cy-server,Gweinydd syml ar gyfer ddarparu gwasanaeth API at modelau adnabod lleferydd DeepSpeech // Simple server for providing API access to DeepSpeech speech recognition models.,techiaith,"['api-server', 'cymraeg', 'speech', 'speech-recognition', 'welsh']",https://github.com/techiaith/docker-deepspeech-cy-server,https://api.github.com/users/techiaith,https://api.github.com/repos/techiaith/docker-deepspeech-cy-server,Prifysgol Bangor University
simple-speech-recognition,A small and very simple program for speech recognition.,Shaban0818,[],https://github.com/Shaban0818/simple-speech-recognition,https://api.github.com/users/Shaban0818,https://api.github.com/repos/Shaban0818/simple-speech-recognition,India
Cloudmersive.APIClient.Python.VoiceRecognition,Python client for Cloudmersive Voice Recognition and Speech API,Cloudmersive,[],https://github.com/Cloudmersive/Cloudmersive.APIClient.Python.VoiceRecognition,https://api.github.com/users/Cloudmersive,https://api.github.com/repos/Cloudmersive/Cloudmersive.APIClient.Python.VoiceRecognition,"Walnut Creek, California, United States"
AndroidSpeechDemo,Sample of Android's automatic speech recognition (ASR),kaiidams,[],https://github.com/kaiidams/AndroidSpeechDemo,https://api.github.com/users/kaiidams,https://api.github.com/repos/kaiidams/AndroidSpeechDemo,Tokyo
speechrec-web-service,Web service to provide speech recognition facilities using Rust,deejcoder,"['deep-learning', 'rust', 'speech-recogition', 'web-service']",https://github.com/deejcoder/speechrec-web-service,https://api.github.com/users/deejcoder,https://api.github.com/repos/deejcoder/speechrec-web-service,New Zealand
voicecontrol-web,voice control app using browser speech recognition api,Rehre,[],https://github.com/Rehre/voicecontrol-web,https://api.github.com/users/Rehre,https://api.github.com/repos/Rehre/voicecontrol-web,"Bekasi,West Java,Indonesia"
native-voice-recognition,Native Speech Recognition used in simple html page.,haesooKr,[],https://github.com/haesooKr/native-voice-recognition,https://api.github.com/users/haesooKr,https://api.github.com/repos/haesooKr/native-voice-recognition,New Jersey
Speech-recognition-ioT,Python project speech recognition with Dialogflow | Raspberry Pi,Ai-Sasit,"['python', 'raspberry-pi', 'speech-recognition']",https://github.com/Ai-Sasit/Speech-recognition-ioT,https://api.github.com/users/Ai-Sasit,https://api.github.com/repos/Ai-Sasit/Speech-recognition-ioT,Thailand
Simultaneous-Machine-Translation,Google speech recognition + neural machine translation to translate conversations,ikergarcia1996,[],https://github.com/ikergarcia1996/Simultaneous-Machine-Translation,https://api.github.com/users/ikergarcia1996,https://api.github.com/repos/ikergarcia1996/Simultaneous-Machine-Translation,San Sebastián
speech,Speech Recognition Data and K&R C Code,melchisadeck,[],https://github.com/melchisadeck/speech,https://api.github.com/users/melchisadeck,https://api.github.com/repos/melchisadeck/speech,"Dublin, Ireland"
DNN_Speech_Recognition,Exploring various models architecture for automatic speech recognition pipeline,moelkhawagit,[],https://github.com/moelkhawagit/DNN_Speech_Recognition,https://api.github.com/users/moelkhawagit,https://api.github.com/repos/moelkhawagit/DNN_Speech_Recognition,"Cairo/Alexandria, Egypt"
bangla-speech-synthesis-and-recognition,speech synthesis and recognition for bangla(bn-bd) with javascript,ishafiul,[],https://github.com/ishafiul/bangla-speech-synthesis-and-recognition,https://api.github.com/users/ishafiul,https://api.github.com/repos/ishafiul/bangla-speech-synthesis-and-recognition,"Dhaka, Bangladesh"
SpeakTest-Android,Simple dictation app that uses native Android speech recognition,pkolb,[],https://github.com/pkolb/SpeakTest-Android,https://api.github.com/users/pkolb,https://api.github.com/repos/pkolb/SpeakTest-Android,Berlin
speech_recognition,codes for speech recognition based on mel-cepstral,Gamalielmch,[],https://github.com/Gamalielmch/speech_recognition,https://api.github.com/users/Gamalielmch,https://api.github.com/repos/Gamalielmch/speech_recognition,"Zacatecas, México"
Speech_Recognition,This is a speech🗣 recognition application based🙂 on Google usage.,subhayuroy,[],https://github.com/subhayuroy/Speech_Recognition,https://api.github.com/users/subhayuroy,https://api.github.com/repos/subhayuroy/Speech_Recognition,"DIT University, Dehradun"
thesarkvoicepad,A text editor with narration and speech recognition,shouvikkrsarkar,[],https://github.com/shouvikkrsarkar/thesarkvoicepad,https://api.github.com/users/shouvikkrsarkar,https://api.github.com/repos/shouvikkrsarkar/thesarkvoicepad,India
stunning-potato,Speech Processing and Recognition (101803) final project at UniGe,DiTo97,"['chatbot', 'speech-processing']",https://github.com/DiTo97/stunning-potato,https://api.github.com/users/DiTo97,https://api.github.com/repos/DiTo97/stunning-potato,"Genoa, Italy"
Speech-Recognition-for-the-Ga-Adangme-Language,Speech Recognition for Low Resource Language: Ga-Adangme,nii4u,[],https://github.com/nii4u/Speech-Recognition-for-the-Ga-Adangme-Language,https://api.github.com/users/nii4u,https://api.github.com/repos/nii4u/Speech-Recognition-for-the-Ga-Adangme-Language,Rwanda
AI,"Programs related to speech recognition , saying audio etc.",iPROGRAMMER007,[],https://github.com/iPROGRAMMER007/AI,https://api.github.com/users/iPROGRAMMER007,https://api.github.com/repos/iPROGRAMMER007/AI,Kolkata
DataWedge-VoiceRecognition-Sample,Using Zebra's DataWedge for voice / speech recognition,darryncampbell,['zebratechnologies'],https://github.com/darryncampbell/DataWedge-VoiceRecognition-Sample,https://api.github.com/users/darryncampbell,https://api.github.com/repos/darryncampbell/DataWedge-VoiceRecognition-Sample,UK
MedicalSpeech,Projects for improve the speech recognition result on medical fields.,FalsitaFine,[],https://github.com/FalsitaFine/MedicalSpeech,https://api.github.com/users/FalsitaFine,https://api.github.com/repos/FalsitaFine/MedicalSpeech,"Twin Cites, Minnesota"
Simple-Speech-Object-Detect,Using Yolo Model to Detect Objects using speech recognition ,don-thomas,[],https://github.com/don-thomas/Simple-Speech-Object-Detect,https://api.github.com/users/don-thomas,https://api.github.com/repos/don-thomas/Simple-Speech-Object-Detect,"Toronto, Canada"
ArabicSpeechRecognition-iOS,"Swift Implementation of Speech Recognition using SpeechKit, CoreML and AVFoundation",omardroubi,[],https://github.com/omardroubi/ArabicSpeechRecognition-iOS,https://api.github.com/users/omardroubi,https://api.github.com/repos/omardroubi/ArabicSpeechRecognition-iOS,"Cupertino, CA"
speechEmotionRecognition,Speech Emotion Recognition models implementation with TensorFlow and Keras,Abdiflame,[],https://github.com/Abdiflame/speechEmotionRecognition,https://api.github.com/users/Abdiflame,https://api.github.com/repos/Abdiflame/speechEmotionRecognition,"Seoul, South Korea"
speech-recognition,Wes Bos tutorial javascript30.com 'Native Speech Recognition',bakrall,[],https://github.com/bakrall/speech-recognition,https://api.github.com/users/bakrall,https://api.github.com/repos/bakrall/speech-recognition,"Kraków, Poland"
speech-recognition,speech recognition of any audio file using python,shivkantsharma33,[],https://github.com/shivkantsharma33/speech-recognition,https://api.github.com/users/shivkantsharma33,https://api.github.com/repos/shivkantsharma33/speech-recognition,Kanpur
speech-emotion-recognition,Speech Emotion Recognition from Spectrograms with Deep Convolutional Neural Network,zahramajd,"['convolutional-neural-networks', 'speech-emotion-recognition', 'tensorflow']",https://github.com/zahramajd/speech-emotion-recognition,https://api.github.com/users/zahramajd,https://api.github.com/repos/zahramajd/speech-emotion-recognition,"Tehran, Iran"
SpeechRecognition,Syfe's Speech Recognition and Data Science folder in Python,ItsSyfe,[],https://github.com/ItsSyfe/SpeechRecognition,https://api.github.com/users/ItsSyfe,https://api.github.com/repos/ItsSyfe/SpeechRecognition,United Kingdom
fergal-home,A home assistant using speech recognition to automate various tasks,F3rgz,[],https://github.com/F3rgz/fergal-home,https://api.github.com/users/F3rgz,https://api.github.com/repos/F3rgz/fergal-home,"Cork, Ireland"
PyramidASR,A DBus interface for CMU Pocketsphinx speech recognition.,ExpandingDev,"['daemon', 'dbus', 'dbus-cxx', 'linux', 'pocketsphinx', 'speech-recognition']",https://github.com/ExpandingDev/PyramidASR,https://api.github.com/users/ExpandingDev,https://api.github.com/repos/ExpandingDev/PyramidASR,"State College, PA"
VoiceRecognitionBot,A voice recognition/Text to speech bot windows application ,Sethmichael01,[],https://github.com/Sethmichael01/VoiceRecognitionBot,https://api.github.com/users/Sethmichael01,https://api.github.com/repos/Sethmichael01/VoiceRecognitionBot,"Jos, Plateau State. Nigeria"
virtual-piano,Virtual piano using hand tracking and speech recognition.,aklemen,[],https://github.com/aklemen/virtual-piano,https://api.github.com/users/aklemen,https://api.github.com/repos/aklemen/virtual-piano,Slovenia
ibm_watson_nlp,Modifications to the IBM Watson speech recognition and synthesis system,atherfawaz,[],https://github.com/atherfawaz/ibm_watson_nlp,https://api.github.com/users/atherfawaz,https://api.github.com/repos/atherfawaz/ibm_watson_nlp,"Lahore, Pakistan"
speech_recognition_nn_comparison,Comparisons between Neural Networks with LibriSpeech Speech Recognition,lithathampan,[],https://github.com/lithathampan/speech_recognition_nn_comparison,https://api.github.com/users/lithathampan,https://api.github.com/repos/lithathampan/speech_recognition_nn_comparison,"White Plains,New York"
SpeechRecognitionHMM_Basics,"Python speech recognition using HMM and MFCC - основы, обучение",UNREALre,[],https://github.com/UNREALre/SpeechRecognitionHMM_Basics,https://api.github.com/users/UNREALre,https://api.github.com/repos/UNREALre/SpeechRecognitionHMM_Basics,Russia
Raspberyy-Pi-and-Tensorflow-lite-based-Speech-Recognition-for-Control-of-Relay-Circuit-,A CNN based RPi and Tflite model for speech recognition.,imjaya,[],https://github.com/imjaya/Raspberyy-Pi-and-Tensorflow-lite-based-Speech-Recognition-for-Control-of-Relay-Circuit-,https://api.github.com/users/imjaya,https://api.github.com/repos/imjaya/Raspberyy-Pi-and-Tensorflow-lite-based-Speech-Recognition-for-Control-of-Relay-Circuit-,"Los Angeles, California"
Korean-Speech-Recognition,Korean Speech Recognition implemented PyTorch - TEAM Kai-Lib,triplet02,[],https://github.com/triplet02/Korean-Speech-Recognition,https://api.github.com/users/triplet02,https://api.github.com/repos/triplet02/Korean-Speech-Recognition,Seoul
Speech-Emotion-Recognition,https://github.com/harry-7/speech-emotion-recognition.git,Chiranjeevi731,[],https://github.com/Chiranjeevi731/Speech-Emotion-Recognition,https://api.github.com/users/Chiranjeevi731,https://api.github.com/repos/Chiranjeevi731/Speech-Emotion-Recognition,Kakinada
Ionic5-speech-recognition,Come integrare un'app per lo speech recognition,serenasensini,"['ionic5', 'speech-recognition']",https://github.com/serenasensini/Ionic5-speech-recognition,https://api.github.com/users/serenasensini,https://api.github.com/repos/serenasensini/Ionic5-speech-recognition,Rome
lipreading,Visual speech recognition model (LipNet) implemented using PyTorch.,khassanoff,[],https://github.com/khassanoff/lipreading,https://api.github.com/users/khassanoff,https://api.github.com/repos/khassanoff/lipreading,Kazakhstan
ASR_tf_keras,Automatic Speech Recognition  trial and error for chinese/mandarin,jjyock,[],https://github.com/jjyock/ASR_tf_keras,https://api.github.com/users/jjyock,https://api.github.com/repos/jjyock/ASR_tf_keras,china
CS763-Assignments-2019,Assignments for the course CS 763 (Automatic Speech Recognition) IITB,decoder746,[],https://github.com/decoder746/CS763-Assignments-2019,https://api.github.com/users/decoder746,https://api.github.com/repos/decoder746/CS763-Assignments-2019,Mumbai
PowerShellJarvis,dotnet speech synthesis / recognition script for executing simple commands,judegiordano,[],https://github.com/judegiordano/PowerShellJarvis,https://api.github.com/users/judegiordano,https://api.github.com/repos/judegiordano/PowerShellJarvis,http://localhost:3000/api/
browser-talk,Control your browser hands free using speech recognition technology ,philipk19238,[],https://github.com/philipk19238/browser-talk,https://api.github.com/users/philipk19238,https://api.github.com/repos/philipk19238/browser-talk,Austin
assistantJoey, Desktop assistant built with python using speech recognition.,yunghog,[],https://github.com/yunghog/assistantJoey,https://api.github.com/users/yunghog,https://api.github.com/repos/yunghog/assistantJoey,sagar
text-editor-WPF,My WPF text editor clone with speech recognition,diciocciojoseph,[],https://github.com/diciocciojoseph/text-editor-WPF,https://api.github.com/users/diciocciojoseph,https://api.github.com/repos/diciocciojoseph/text-editor-WPF,"Wethersfield, CT"
friday_virtual_assistant,Virtual Assistant with Speech and Voice Recognition built in Python,jcrommar,[],https://github.com/jcrommar/friday_virtual_assistant,https://api.github.com/users/jcrommar,https://api.github.com/repos/jcrommar/friday_virtual_assistant,"DFW, TX"
lstm-music-generation,Project repository for DT2119 Speech and Speaker Recognition at KTH.,nagyrajmund,[],https://github.com/nagyrajmund/lstm-music-generation,https://api.github.com/users/nagyrajmund,https://api.github.com/repos/nagyrajmund/lstm-music-generation,Stockholm
rnu-assistant,Really not useless assistant - offline speech recognition and synthesis,asidko,[],https://github.com/asidko/rnu-assistant,https://api.github.com/users/asidko,https://api.github.com/repos/asidko/rnu-assistant,"Kyiv, Ukraine"
speechRecognition,Speech Recognition System built as part of NLP project Udacity,manessaraj,[],https://github.com/manessaraj/speechRecognition,https://api.github.com/users/manessaraj,https://api.github.com/repos/manessaraj/speechRecognition,"Toronto, Canada"
AI_Jarvis_Model,"I am working on a AI Jarvis Speech Recognition model which can open Wikipedia , Google, Youtube & can send Emails With Voice Recognition (Will Update more new features)",arnabbarui5,[],https://github.com/arnabbarui5/AI_Jarvis_Model,https://api.github.com/users/arnabbarui5,https://api.github.com/repos/arnabbarui5/AI_Jarvis_Model,"Kolkata, India"
Speech-To-Text,A simple Speech to Text Conversion software that Takes Your Speech Through Microphone. This software is coded using Python and Speech Recognition module is used in listening Speech.,Arshad272,[],https://github.com/Arshad272/Speech-To-Text,https://api.github.com/users/Arshad272,https://api.github.com/repos/Arshad272/Speech-To-Text,"Puttur, Andhra Pradesh, India "
Digital-Primer," In this repository You will find some necessary software and content components which will allow You to create Your own variant of a digital Primer (DP). DP is a new kind of medium whose raison d'etre is to educate. Its ideal hardware embodiment looks like a book and has multiple properties of a book. Instead of using screens, device uses e-ink displays (mostly using IT8951 controller) to present visual or textual content. Strong emphasis is to be put on speech technologies (automatic speech recognition and speech synthesis) and touchless human-machine interaction. Recommended platform: Raspberry Pi Zero running Raspbian OS.",hromi,[],https://github.com/hromi/Digital-Primer,https://api.github.com/users/hromi,https://api.github.com/repos/hromi/Digital-Primer,Berlin
Voice-Based-Theme-Changer-Ionic,A Voice recognition based app used for changing the app theme with recognized speech color. Uses npm @ionic-native/speech-recognition package.,PavanAditya,[],https://github.com/PavanAditya/Voice-Based-Theme-Changer-Ionic,https://api.github.com/users/PavanAditya,https://api.github.com/repos/PavanAditya/Voice-Based-Theme-Changer-Ionic,Hyderabad
speech-processing,86.53 - Algorithms used in speech recognition and application use of the HTK toolkit for a speech recognition system to make phone calls with voice.,fedeboco,"['formants', 'htk', 'phone-call', 'speech-processing', 'speech-recognition']",https://github.com/fedeboco/speech-processing,https://api.github.com/users/fedeboco,https://api.github.com/repos/fedeboco/speech-processing,"Buenos Aires, Argentina"
AUDREI-desktop-assistant,Based on Google Speech Recognition using NLP to translate speech from a microphone input to a command as an output.,Joker-io,[],https://github.com/Joker-io/AUDREI-desktop-assistant,https://api.github.com/users/Joker-io,https://api.github.com/repos/Joker-io/AUDREI-desktop-assistant,TX
Speech_Command_Recognition,Multi-class classification of speech command data. Dataset collected from kaggle speech recognition challenge and used pyTorch for implementation.,aminul-huq,"['kaggle-dataset', 'multiclass-classification', 'pytorch-implementation', 'speech', 'speech-command-recognition', 'speech-commands', 'speech-recognition']",https://github.com/aminul-huq/Speech_Command_Recognition,https://api.github.com/users/aminul-huq,https://api.github.com/repos/aminul-huq/Speech_Command_Recognition,"Beijing, China"
SpeechRecognitionApplication,An application that uses Microsoft Azure Speech Recognition to identify user's speech and speak the text that user type,MO7YW4NG,[],https://github.com/MO7YW4NG/SpeechRecognitionApplication,https://api.github.com/users/MO7YW4NG,https://api.github.com/repos/MO7YW4NG/SpeechRecognitionApplication,Taiwan
nuton,"Nuton is a personal voice assistant developed using python, speech recognition, Chatterbot & eSpeak, a text to speech package   ",CathalButler,"['chatterbot', 'machine-learning', 'personal-assistant', 'python3', 'speech-recognition', 'text-to-speech']",https://github.com/CathalButler/nuton,https://api.github.com/users/CathalButler,https://api.github.com/repos/CathalButler/nuton,"Galway, Ireland"
Speech-Emotion-Recognition-using-GMM,Speech Emotion Recognition is a final year project which allows us to predict emotion from speech by training the speech dataset with GMM model.,niteshseram,[],https://github.com/niteshseram/Speech-Emotion-Recognition-using-GMM,https://api.github.com/users/niteshseram,https://api.github.com/repos/niteshseram/Speech-Emotion-Recognition-using-GMM,"Assam, India"
Speech-to-text-English-Marathi-,Speech to Text is simple project to convert Speech through Microphone to text by Using PyAudio Library.Here I am using Google Speech recognition API for conversion.,ajaynthakur,[],https://github.com/ajaynthakur/Speech-to-text-English-Marathi-,https://api.github.com/users/ajaynthakur,https://api.github.com/repos/ajaynthakur/Speech-to-text-English-Marathi-,Bengaluru(INDIA)
iterative-feature-normalisation-ICASSP-2011,"This repository contains a Python implementation of the paper ""Iterative Feature Normalisation for Emotional Speech Recognition"" by Busso et.al published at ICASSP 2011",brihijoshi,"['emotion-recognition', 'feature-engineering', 'machine-learning', 'speech-recognition']",https://github.com/brihijoshi/iterative-feature-normalisation-ICASSP-2011,https://api.github.com/users/brihijoshi,https://api.github.com/repos/brihijoshi/iterative-feature-normalisation-ICASSP-2011,"Los Angeles, CA"
Attention-based-speech-recognition,"This is a attention based speech recognition model based on LAS (Listener, Attention and Speller) architecture",senhcmu,[],https://github.com/senhcmu/Attention-based-speech-recognition,https://api.github.com/users/senhcmu,https://api.github.com/repos/senhcmu/Attention-based-speech-recognition,"Pittsburgh, PA"
Python-Speech-Recognition-System,Python Speech Recognition using MFCC and melfb and Neural Networks Training.,vaaiibhav,[],https://github.com/vaaiibhav/Python-Speech-Recognition-System,https://api.github.com/users/vaaiibhav,https://api.github.com/repos/vaaiibhav/Python-Speech-Recognition-System,Aurangabad
Speak-and-Guess-Number, Number guessing game where you speak your guess into the microphone using the speech recognition API,duhbhavesh,[],https://github.com/duhbhavesh/Speak-and-Guess-Number,https://api.github.com/users/duhbhavesh,https://api.github.com/repos/duhbhavesh/Speak-and-Guess-Number,Mumbai
kth-speech-and-speaker-recognition,Assignments of the Speech and Speaker Recognition course (DT2119) at KTH,franco-ruggeri,['speech-recognition'],https://github.com/franco-ruggeri/kth-speech-and-speaker-recognition,https://api.github.com/users/franco-ruggeri,https://api.github.com/repos/franco-ruggeri/kth-speech-and-speaker-recognition,Turin
spacy-grpc,spaCy part-of-speech tagging and named entity recognition as a gRPC service,turbolent,[],https://github.com/turbolent/spacy-grpc,https://api.github.com/users/turbolent,https://api.github.com/repos/turbolent/spacy-grpc,"Vancouver, Canada, Earth"
tomayto_tomahto,Speech Recognition using Convolutional Neural Network; Running Flask demo serving Tensorflow model hosted on Heroku,tchleung,[],https://github.com/tchleung/tomayto_tomahto,https://api.github.com/users/tchleung,https://api.github.com/repos/tchleung/tomayto_tomahto,"San Francisco Bay Area, US"
Tetra_List,"A ToDo web app which uses webSpeech API for Speech synthesis & recognition, and windows local storage.",ChahatKumar,[],https://github.com/ChahatKumar/Tetra_List,https://api.github.com/users/ChahatKumar,https://api.github.com/repos/ChahatKumar/Tetra_List,"Delhi,India"
GoogleMapsMultimodalInterface,Multimodal Interface using Google Maps API using Voice Recognition and Speech Synthesis,AlexMLourenco,[],https://github.com/AlexMLourenco/GoogleMapsMultimodalInterface,https://api.github.com/users/AlexMLourenco,https://api.github.com/repos/AlexMLourenco/GoogleMapsMultimodalInterface,"Coimbra, Portugal"
play-the-radio,Speech recognition for playing the radio in 12 lines of code,do-me,[],https://github.com/do-me/play-the-radio,https://api.github.com/users/do-me,https://api.github.com/repos/do-me/play-the-radio,Germany
Jarvis-A-voice-Assistant,The basic idea behind the project titled “Voice Assistant” implements the concepts of Speech Recognition.,ganesharmaa,[],https://github.com/ganesharmaa/Jarvis-A-voice-Assistant,https://api.github.com/users/ganesharmaa,https://api.github.com/repos/ganesharmaa/Jarvis-A-voice-Assistant,"chennai ,India"
sam-the-virtual-assistant,"Simple virtual assistant. Using Google Calendar API, Python, speech_recognition, gtts.",quynhhgoogoo,[],https://github.com/quynhhgoogoo/sam-the-virtual-assistant,https://api.github.com/users/quynhhgoogoo,https://api.github.com/repos/quynhhgoogoo/sam-the-virtual-assistant,"Helsinki, Finland"
caption-maker,small tkinter GUI for automatically generating subtitles for .mp4 files (based on autosub and speech-recognition),pfontana96,[],https://github.com/pfontana96/caption-maker,https://api.github.com/users/pfontana96,https://api.github.com/repos/pfontana96/caption-maker,"Mendoza, Argentina"
Voice-AI,A Speech Recognition AI I made as my final project for my Nanodegree,antonecg,[],https://github.com/antonecg/Voice-AI,https://api.github.com/users/antonecg,https://api.github.com/repos/antonecg/Voice-AI,Nashville
learn-n-play-frontend,"Educational platform with web speech recognition to help children practice basic reading, spelling and math skills!",josephscha,[],https://github.com/josephscha/learn-n-play-frontend,https://api.github.com/users/josephscha,https://api.github.com/repos/josephscha/learn-n-play-frontend,NYC
pyspeechkit,Library for working with a range of technologies for speech recognition and synthesis from Yandex (SpeechKit).,pystorage,"['python', 'python-library', 'speechkit', 'synthesis', 'text-to-speech', 'voice', 'yandex', 'yandex-api']",https://github.com/pystorage/pyspeechkit,https://api.github.com/users/pystorage,https://api.github.com/repos/pystorage/pyspeechkit,Russia
speech-recognition,This is an amazing mini project about speech recognition with pure javascript. ,muchirijane,[],https://github.com/muchirijane/speech-recognition,https://api.github.com/users/muchirijane,https://api.github.com/repos/muchirijane/speech-recognition,Dubai 
Cloudmersive.APIClient.NET.Speech,.NET Framework API Client for Cloudmersive Voice Recognition and Speech API,Cloudmersive,[],https://github.com/Cloudmersive/Cloudmersive.APIClient.NET.Speech,https://api.github.com/users/Cloudmersive,https://api.github.com/repos/Cloudmersive/Cloudmersive.APIClient.NET.Speech,"Walnut Creek, California, United States"
Home-Automation-System,A simple home automation system using Arduino and Android with Speech Recognition,AP-Atul,"['android', 'arduino', 'home-automation-system', 'speech-recognition']",https://github.com/AP-Atul/Home-Automation-System,https://api.github.com/users/AP-Atul,https://api.github.com/repos/AP-Atul/Home-Automation-System,"Pune, India"
EPs_emo,Speech emotion recognition based on Emotion Profiles (EPs) using Tensorflow 2.0,Maoshuiyang,"['cnn', 'emotion-profiles', 'speech-emotion-recognition', 'tensorflow2']",https://github.com/Maoshuiyang/EPs_emo,https://api.github.com/users/Maoshuiyang,https://api.github.com/repos/Maoshuiyang/EPs_emo,Hong Kong
Stock-Prediction,Scrape historical stock data using speech recognition and applying machine learning models for stock prediction.,10514801,[],https://github.com/10514801/Stock-Prediction,https://api.github.com/users/10514801,https://api.github.com/repos/10514801/Stock-Prediction,Dublin
Desktop_Assistant,Desktop Assistant that uses Speech Recognition and performs common tasks and also talk back to user.,snehalmastud,"['desktop-assistant', 'python']",https://github.com/snehalmastud/Desktop_Assistant,https://api.github.com/users/snehalmastud,https://api.github.com/repos/snehalmastud/Desktop_Assistant,Mumbai
Speak-Number-Guessing-Game,🎤 Number guessing game where you speak your guess into the microphone using the speech recognition API,devcass,[],https://github.com/devcass/Speak-Number-Guessing-Game,https://api.github.com/users/devcass,https://api.github.com/repos/devcass/Speak-Number-Guessing-Game,Universe
voice-search-carousel,Used speech recognition API and built a small carousel using web components.,pmenichelli,[],https://github.com/pmenichelli/voice-search-carousel,https://api.github.com/users/pmenichelli,https://api.github.com/repos/pmenichelli/voice-search-carousel,Netherlands
dser_with_text,Repository for paper: Using Text Feature to Improve Valence Prediction in Dimensional Speech Emotion Recognition,bagustris,[],https://github.com/bagustris/dser_with_text,https://api.github.com/users/bagustris,https://api.github.com/repos/bagustris/dser_with_text,Tsukuba
ng-speech-grid,AG-Grid Community Implementation on Angular Application with Speech Command Recognition,AndrewRedican,[],https://github.com/AndrewRedican/ng-speech-grid,https://api.github.com/users/AndrewRedican,https://api.github.com/repos/AndrewRedican/ng-speech-grid,"Cork, Ireland"
speech-emotion-recognition-with-residual-phase,Speech emotion recognition using convolutional neural network trained on residual phase cepstral coefficients.,aleromualdi,[],https://github.com/aleromualdi/speech-emotion-recognition-with-residual-phase,https://api.github.com/users/aleromualdi,https://api.github.com/repos/aleromualdi/speech-emotion-recognition-with-residual-phase,"Berlin, Germany"
AutomaticSpeechRecognitionResearch,Research tools on Automatic Speech Recognition from CNR and University of Naples Federico II,gianpaolocoro,[],https://github.com/gianpaolocoro/AutomaticSpeechRecognitionResearch,https://api.github.com/users/gianpaolocoro,https://api.github.com/repos/gianpaolocoro/AutomaticSpeechRecognitionResearch,Pisa
Chatbot,Machine learning based chat bot using chatter bot library with speech recognition and many other features  ,harjotscs,[],https://github.com/harjotscs/Chatbot,https://api.github.com/users/harjotscs,https://api.github.com/repos/harjotscs/Chatbot,Lovely professional University
identify_reciter,Reciter identification (Speech recognition) using Machine Learning - Capstone project for Udacity Machine Learning Nanodegree,chughtaigit,[],https://github.com/chughtaigit/identify_reciter,https://api.github.com/users/chughtaigit,https://api.github.com/repos/chughtaigit/identify_reciter,"San Jose, CA"
Digital-Assistant,A speech recognition application for linux operating system as my final year project.,try-catch-me,[],https://github.com/try-catch-me/Digital-Assistant,https://api.github.com/users/try-catch-me,https://api.github.com/repos/try-catch-me/Digital-Assistant,Pakistan
Sinhala-Speech-Recognition-Module,This contains Sinhala speech recognition module implementation using a deep neural network,Jayanie,[],https://github.com/Jayanie/Sinhala-Speech-Recognition-Module,https://api.github.com/users/Jayanie,https://api.github.com/repos/Jayanie/Sinhala-Speech-Recognition-Module,Sri Lanka
magic-spells,Magic Spells is a game to practice Spelling Words using Speech Recognition,detain,"['game', 'learning', 'school', 'school-education', 'speech', 'speech-recognition', 'speech-to-text', 'speechrecognition', 'spelling', 'spelling-checker', 'spelling-practice', 'study', 'studying']",https://github.com/detain/magic-spells,https://api.github.com/users/detain,https://api.github.com/repos/detain/magic-spells,"Ephrata, PA"
COM1005-Word-Lattice,First Year Machines and Itelligence. The program replicates the processes in speech recognition.,bobbyjameswilliams,[],https://github.com/bobbyjameswilliams/COM1005-Word-Lattice,https://api.github.com/users/bobbyjameswilliams,https://api.github.com/repos/bobbyjameswilliams/COM1005-Word-Lattice,"Havering, Greater London"
workout_dj,Youtube voice controller built using Speech Recognition for Python by Google and Selenium,adrianlee0118,"['pyaudio', 'python', 'selenium', 'speechrecognition', 'youtube']",https://github.com/adrianlee0118/workout_dj,https://api.github.com/users/adrianlee0118,https://api.github.com/repos/adrianlee0118/workout_dj,"Vancouver, Canada"
segment-ser,"Official code for A Segment Level Approach to Speech Emotion Recognition using Transfer Learning, ACPR 2019",sourav22899,"['paper', 'segment-level', 'speech-emotion-recognition']",https://github.com/sourav22899/segment-ser,https://api.github.com/users/sourav22899,https://api.github.com/repos/sourav22899/segment-ser,"Chennai, India"
Guessing-Game-w-Speech-Recogniton,I built a guessing game built with a Speech Recognition web API,alonsocastilleja,[],https://github.com/alonsocastilleja/Guessing-Game-w-Speech-Recogniton,https://api.github.com/users/alonsocastilleja,https://api.github.com/repos/alonsocastilleja/Guessing-Game-w-Speech-Recogniton,"Charlotte, NC"
STARK,"STARK (Smart Talktative Assistant - Reasonable, Knowledgeble) is a digital query solver assistant with speech recognition feature.",alankarartist,[],https://github.com/alankarartist/STARK,https://api.github.com/users/alankarartist,https://api.github.com/repos/alankarartist/STARK,"Kurukshetra, Haryana, India"
Automated-Youtube-Search,This will search your query on youtube using speech recognition module of python  ,rsinghal57,[],https://github.com/rsinghal57/Automated-Youtube-Search,https://api.github.com/users/rsinghal57,https://api.github.com/repos/rsinghal57/Automated-Youtube-Search,Chandigarh
VOSK-recognize-system,A recognition system for Russian speech using VOSK-API based on Kaldi.,pikabol88,[],https://github.com/pikabol88/VOSK-recognize-system,https://api.github.com/users/pikabol88,https://api.github.com/repos/pikabol88/VOSK-recognize-system,Saint Petersburg
fb-chat-stt,Uses fbchat and the GCP to perform speech recognition on audio messages,CrispyBaguette,[],https://github.com/CrispyBaguette/fb-chat-stt,https://api.github.com/users/CrispyBaguette,https://api.github.com/repos/CrispyBaguette/fb-chat-stt,"Strasbourg, France"
dser_with_sil,"Repo for paper ""Contribution of silent pause feature in dimensional speech emotion recognition""",bagustris,[],https://github.com/bagustris/dser_with_sil,https://api.github.com/users/bagustris,https://api.github.com/repos/bagustris/dser_with_sil,Tsukuba
tensorflow-speech-recognition,"Speech recognition using the tensorflow deep learning framework, sequence-to-sequence neural networks",krantirk,[],https://github.com/krantirk/tensorflow-speech-recognition,https://api.github.com/users/krantirk,https://api.github.com/repos/krantirk/tensorflow-speech-recognition,India
SERaaS-Web-Platform,React.js based Data Dashboard for Speech Emotion Recognition as a Service.,SERaaS,"['nodejs', 'reactjs', 'speech-emotion-recognition']",https://github.com/SERaaS/SERaaS-Web-Platform,https://api.github.com/users/SERaaS,https://api.github.com/repos/SERaaS/SERaaS-Web-Platform,Ireland
Speech-Recognition-Using-Multiple-APIs-And-GTA-5-using-Voice-Command,"Google cloud, IBM watson and google non cloud api for speech recognition. ",UmerTariq1,[],https://github.com/UmerTariq1/Speech-Recognition-Using-Multiple-APIs-And-GTA-5-using-Voice-Command,https://api.github.com/users/UmerTariq1,https://api.github.com/repos/UmerTariq1/Speech-Recognition-Using-Multiple-APIs-And-GTA-5-using-Voice-Command,"Saarbrucken, Germany"
AMMI-Speech-Lig-Aikuma,"AMMI course on Speech Recognition, given by Gabriel Synnaeve, Neil Zeghidour, Laurent Besacier and Emmanuel Dupoux",Kabongosalomon,[],https://github.com/Kabongosalomon/AMMI-Speech-Lig-Aikuma,https://api.github.com/users/Kabongosalomon,https://api.github.com/repos/Kabongosalomon/AMMI-Speech-Lig-Aikuma,"Hannover, Germany"
daily-check-in-frontend,React-redux group project using sentiment library package and speech recognition. Styled with Material-UI.,nmegrant,[],https://github.com/nmegrant/daily-check-in-frontend,https://api.github.com/users/nmegrant,https://api.github.com/repos/nmegrant/daily-check-in-frontend,"Haarlem, Netherlands"
voice-connect-four,Voice controlled connect four using CMU's Sphinx speech recognition engine and Java 7,atharvanaik10,[],https://github.com/atharvanaik10/voice-connect-four,https://api.github.com/users/atharvanaik10,https://api.github.com/repos/atharvanaik10/voice-connect-four,Singapore
Python-Speech-Assistant,Using Google Speech Recognition Library. Searches the web and finds location.,kushagra219,[],https://github.com/kushagra219/Python-Speech-Assistant,https://api.github.com/users/kushagra219,https://api.github.com/repos/kushagra219/Python-Speech-Assistant,"Gurgaon, India"
room-designer,A multimodal interface for basic interior design. Uses Leap Motion Controller and speech recognition.,jsarchibald,[],https://github.com/jsarchibald/room-designer,https://api.github.com/users/jsarchibald,https://api.github.com/repos/jsarchibald/room-designer,"Cambridge, MA"
Speech-Recognition-Sprint,A small repo containing my speech recognition using deep learning adventures.,rohanath123,[],https://github.com/rohanath123/Speech-Recognition-Sprint,https://api.github.com/users/rohanath123,https://api.github.com/repos/rohanath123/Speech-Recognition-Sprint,"Mumbai, Maharashtra"
Speech-Emotion-Recognition-using-sklearn,"Speech emotion recognition specially used in call centers to recognize customer's emotion, developed in python. ",Tekraj15,[],https://github.com/Tekraj15/Speech-Emotion-Recognition-using-sklearn,https://api.github.com/users/Tekraj15,https://api.github.com/repos/Tekraj15/Speech-Emotion-Recognition-using-sklearn,"New Delhi, India"
IMDB-and-Speech-Recognition-App,This ia javascript and imdb api with window speech recognition app,shashikunal,[],https://github.com/shashikunal/IMDB-and-Speech-Recognition-App,https://api.github.com/users/shashikunal,https://api.github.com/repos/shashikunal/IMDB-and-Speech-Recognition-App,Bangalore 
Annice-Brain-App,"Android app with OpenCV image detection, CMUPocketSphinx speech recognition, and Bluetooth communication with Arduino microcontrollers.",michaellu2019,[],https://github.com/michaellu2019/Annice-Brain-App,https://api.github.com/users/michaellu2019,https://api.github.com/repos/michaellu2019/Annice-Brain-App,"Cambridge, Massachusetts"
Face-and-speech-recognition,Systems for face and speech recognition using various forms of classification,tiborkubik,[],https://github.com/tiborkubik/Face-and-speech-recognition,https://api.github.com/users/tiborkubik,https://api.github.com/repos/tiborkubik/Face-and-speech-recognition,"Brno, CZ"
dhwoni-app,[Incomplete] A crowd sourcing app for Dhwoni - project on Speech to text recognition. Made with flutter.,sammelanyogi,[],https://github.com/sammelanyogi/dhwoni-app,https://api.github.com/users/sammelanyogi,https://api.github.com/repos/sammelanyogi/dhwoni-app,Nepal
Virtual-Assistant,A virtual assisstant for Windows 10 using Google Speech Recognition API.,YashKesarwani,['python3'],https://github.com/YashKesarwani/Virtual-Assistant,https://api.github.com/users/YashKesarwani,https://api.github.com/repos/YashKesarwani/Virtual-Assistant,Prayagraj
DT2119,"Computer Lab assignments for the course Speech and Speaker Recognition (DT2119) at KTH, spring semester 2020.",MariaBjelikj,[],https://github.com/MariaBjelikj/DT2119,https://api.github.com/users/MariaBjelikj,https://api.github.com/repos/MariaBjelikj/DT2119,"Stockholm, Sweden"
Online-Shopping-Website,"online shopping website using speech recognition Api for voice search, Node.JS and MongoDB for Backend.",sanasaleem1999,[],https://github.com/sanasaleem1999/Online-Shopping-Website,https://api.github.com/users/sanasaleem1999,https://api.github.com/repos/sanasaleem1999/Online-Shopping-Website,"Karachi, PAKISTAN"
GoogleMapsVoiceSpeachTouch,"Multimodal Interface using Google Maps API using Voice Recognition, Speech Synthesis and Touch",AlexMLourenco,[],https://github.com/AlexMLourenco/GoogleMapsVoiceSpeachTouch,https://api.github.com/users/AlexMLourenco,https://api.github.com/repos/AlexMLourenco/GoogleMapsVoiceSpeachTouch,"Coimbra, Portugal"
ASR-for-GPS,The Hidden Markov Model Toolkit (HTK) - Automated Speech Recognition Model for GPS,rachelhox,"['asr', 'hidden-markov-model', 'hmm', 'hmm-viterbi-algorithm']",https://github.com/rachelhox/ASR-for-GPS,https://api.github.com/users/rachelhox,https://api.github.com/repos/rachelhox/ASR-for-GPS,Hong Kong; San Francisco Bay Area
tablemultiplication_synthesis,multiplication table generation with sound synthesis and speech recognition (experimenting the idea),acherm,[],https://github.com/acherm/tablemultiplication_synthesis,https://api.github.com/users/acherm,https://api.github.com/repos/acherm/tablemultiplication_synthesis,Rennes
IMDB-and-Speech-Recognition-App,This is JavaScript and IMDB APi and with window Speech Recognition app,divyansh-shukla,[],https://github.com/divyansh-shukla/IMDB-and-Speech-Recognition-App,https://api.github.com/users/divyansh-shukla,https://api.github.com/repos/divyansh-shukla/IMDB-and-Speech-Recognition-App,"Bangalore, India"
speech-recognition-game,Use speech recognition to guess the right number between 1 and 100,asher-miti,[],https://github.com/asher-miti/speech-recognition-game,https://api.github.com/users/asher-miti,https://api.github.com/repos/asher-miti/speech-recognition-game,London
gedionapp,Gideon app is a browser voice recognition and speech synthesis application with some set commands.,Kevinmuriuki,[],https://github.com/Kevinmuriuki/gedionapp,https://api.github.com/users/Kevinmuriuki,https://api.github.com/repos/Kevinmuriuki/gedionapp,"Nyeri, Kenya"
Speech-recognition-and-NLP,Assignments for the course Speech recognition and NLP (E.Dupoux and B.Sagot),moallafatma,[],https://github.com/moallafatma/Speech-recognition-and-NLP,https://api.github.com/users/moallafatma,https://api.github.com/repos/moallafatma/Speech-recognition-and-NLP,"Paris, France"
female-jarvis-mai-in-c-,This is a simple speech recognition and synthesis AI application using c#,richardnwonah,[],https://github.com/richardnwonah/female-jarvis-mai-in-c-,https://api.github.com/users/richardnwonah,https://api.github.com/repos/richardnwonah/female-jarvis-mai-in-c-,Lagos 
speech_recognition_handle_fix,Python speech_recognition & pyinstaller --noconsole integration [WinError 6 : The handle is invalid] (Fix),amartya4256,[],https://github.com/amartya4256/speech_recognition_handle_fix,https://api.github.com/users/amartya4256,https://api.github.com/repos/amartya4256/speech_recognition_handle_fix,Gurugram
Emotion_Recognition_From_Speech,The task was to create a classifier for emotion recognition from speech,MalteEbner,[],https://github.com/MalteEbner/Emotion_Recognition_From_Speech,https://api.github.com/users/MalteEbner,https://api.github.com/repos/MalteEbner/Emotion_Recognition_From_Speech,Zurich
VoiceCodingPy,A simple GUI based text editor made in tkinter with speech recognition capabilities.  ,djroxx2000,[],https://github.com/djroxx2000/VoiceCodingPy,https://api.github.com/users/djroxx2000,https://api.github.com/repos/djroxx2000/VoiceCodingPy,Mumbai
Domain-specific-ESPnet,A deep learning project for automatic speech recognition in Spanish (for Gong.io),bstanie,[],https://github.com/bstanie/Domain-specific-ESPnet,https://api.github.com/users/bstanie,https://api.github.com/repos/bstanie/Domain-specific-ESPnet,"Tel Aviv, Israel"
chromium-windows-sr,"Chrom(ium)/Brave extension to do speech recognition through the Windows API, no Google involved (WIP)",ethanbb,[],https://github.com/ethanbb/chromium-windows-sr,https://api.github.com/users/ethanbb,https://api.github.com/repos/ethanbb/chromium-windows-sr,"Philadelphia, PA"
Keyword-spoting-in-STM32F4xx,This project demonstrates how run TensorFlow Speech recognition model in stm32 microcontroller,shaileshbakshi,[],https://github.com/shaileshbakshi/Keyword-spoting-in-STM32F4xx,https://api.github.com/users/shaileshbakshi,https://api.github.com/repos/shaileshbakshi/Keyword-spoting-in-STM32F4xx,India
Speech-recognition-NLP,This repository contains my labs and finale project of my speech recognition class at AMMI.,134130U,[],https://github.com/134130U/Speech-recognition-NLP,https://api.github.com/users/134130U,https://api.github.com/repos/134130U/Speech-recognition-NLP,Dakar Senegal
regexspeech,POC of a tool designed to help building regexes via speech recognition,QLaille,[],https://github.com/QLaille/regexspeech,https://api.github.com/users/QLaille,https://api.github.com/repos/QLaille/regexspeech,"Montpellier, France"
Final_Capstone_NLP_Deeplearning_SpeechRecognition,Final Capstone Project on identifying Speech Recognition Errors using NLP and Deeplearning ,abhishek-verma-26,[],https://github.com/abhishek-verma-26/Final_Capstone_NLP_Deeplearning_SpeechRecognition,https://api.github.com/users/abhishek-verma-26,https://api.github.com/repos/abhishek-verma-26/Final_Capstone_NLP_Deeplearning_SpeechRecognition,Houston
speak-number-guess-html-css-js,Number guessing game where you speak your guess into the microphone using the speech recognition API,alvar91,"['guessing-game', 'speech-recognition']",https://github.com/alvar91/speak-number-guess-html-css-js,https://api.github.com/users/alvar91,https://api.github.com/repos/alvar91/speak-number-guess-html-css-js,Moscow
Assistant-14,"Python app that uses speech recognition and text-to-speech This app initially used the Google text-to-speech API, but has been updated to use offline text-to-speech with pyttsx3",Administrator859,[],https://github.com/Administrator859/Assistant-14,https://api.github.com/users/Administrator859,https://api.github.com/repos/Administrator859/Assistant-14,Philippines
Speech-To-Text-and-Text-to-Speech-Conversion,Speech recognition is an interdisciplinary sub field of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers,shreya12-hash,['speech-recognition'],https://github.com/shreya12-hash/Speech-To-Text-and-Text-to-Speech-Conversion,https://api.github.com/users/shreya12-hash,https://api.github.com/repos/shreya12-hash/Speech-To-Text-and-Text-to-Speech-Conversion,"Nadia , West Bengal"
unsupervised-speech-representation-learning,This is a intuitive explanation of Representation Learning with Contrastive Predictive Coding  using code provided by jefflai108 that uses CPC to learn representations of sound files for the purpose of speech recognition,clam004,[],https://github.com/clam004/unsupervised-speech-representation-learning,https://api.github.com/users/clam004,https://api.github.com/repos/clam004/unsupervised-speech-representation-learning,San Francisco 
speechRecognition,speechRecognition: Implementation of a speech recognition system through the Google Speech API. Network audio source reception via YARP. Broadcast of recognized text over the network via YARP.,davidvelascogarcia,"['google-speech-recognition', 'speechrecognition', 'yarp']",https://github.com/davidvelascogarcia/speechRecognition,https://api.github.com/users/davidvelascogarcia,https://api.github.com/repos/davidvelascogarcia/speechRecognition,Spain
seek-and-speak,Word search game similar to Boggle but with speech recognition gameplay. Built for iOS in Swift 5 using the Speech framework.,sajedian,[],https://github.com/sajedian/seek-and-speak,https://api.github.com/users/sajedian,https://api.github.com/repos/sajedian/seek-and-speak,Boston
Speech-Denoising-Conv1D-Conv2D,"Designed three speech denoising networks using 1-D CNN, 2-D CNNarchitectures to reduce the problem of noise in speech recognition ",mkraunak,[],https://github.com/mkraunak/Speech-Denoising-Conv1D-Conv2D,https://api.github.com/users/mkraunak,https://api.github.com/repos/mkraunak/Speech-Denoising-Conv1D-Conv2D,Bloomington
Speech_recognition-Sytem,I just created a speech recognition system with the help of speech_recognition API with python . It simply first ask you to enter your name manually the speak your name if that matches then it will show the required output.,Ajiteshrock,[],https://github.com/Ajiteshrock/Speech_recognition-Sytem,https://api.github.com/users/Ajiteshrock,https://api.github.com/repos/Ajiteshrock/Speech_recognition-Sytem,"Bareilly,U.P(243503)"
Mycroft-Personal-Assistant,"A repository for my Mycroft AI Assistant. (OpenCV for facial recognition, .NET Rec_Engine for speech recognition, Agility Pack for scripting))",keivanipchihagh,[],https://github.com/keivanipchihagh/Mycroft-Personal-Assistant,https://api.github.com/users/keivanipchihagh,https://api.github.com/repos/keivanipchihagh/Mycroft-Personal-Assistant,"Iran, Tehran"
Speech-Recognition-in-Python,Speech recognition is an interdisciplinary subfield of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers.,tanaymukherjee,[],https://github.com/tanaymukherjee/Speech-Recognition-in-Python,https://api.github.com/users/tanaymukherjee,https://api.github.com/repos/tanaymukherjee/Speech-Recognition-in-Python,New York
SpokenWord-Persistence-Edit,An extension of Apple's SpokenWord example project that resets speech recognition behind the scenes so that recognition appears near-persistent to the user.,travis-mendoza,[],https://github.com/travis-mendoza/SpokenWord-Persistence-Edit,https://api.github.com/users/travis-mendoza,https://api.github.com/repos/travis-mendoza/SpokenWord-Persistence-Edit,"Berkeley, CA"
morse-code-masters,Captain Morse is a little word-guessing game using Morse Code. Uses speech recognition and sound/animation to signal morse.,tdijkmans,"['nodejs', 'reactjs', 'speech-to-text']",https://github.com/tdijkmans/morse-code-masters,https://api.github.com/users/tdijkmans,https://api.github.com/repos/tdijkmans/morse-code-masters,"Leiden, Netherlands"
nlp-asr_with_neural_networks,Deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline,nitin26gupta,[],https://github.com/nitin26gupta/nlp-asr_with_neural_networks,https://api.github.com/users/nitin26gupta,https://api.github.com/repos/nitin26gupta/nlp-asr_with_neural_networks,Gurgaon
Virtual-Voice-Assistant-,A virtual voice assistant made by using python speech recognition module which will perform various task by taking voice commands.,AkshayUpadhyay2162,[],https://github.com/AkshayUpadhyay2162/Virtual-Voice-Assistant-,https://api.github.com/users/AkshayUpadhyay2162,https://api.github.com/repos/AkshayUpadhyay2162/Virtual-Voice-Assistant-,"20, sharda vihar, city centre, Gwalior(m.p)"
NarratorApp,A Windows Universal App that uses Azure Cognitive Services to do speech to text and speaker recognition,arfontai,[],https://github.com/arfontai/NarratorApp,https://api.github.com/users/arfontai,https://api.github.com/repos/arfontai/NarratorApp,"Paris, France"
English-to-Hindi-Dictionary,Here a code for English to Hindi Dictionary using Python with speech recognition and voice output form,ar2000jun,[],https://github.com/ar2000jun/English-to-Hindi-Dictionary,https://api.github.com/users/ar2000jun,https://api.github.com/repos/ar2000jun/English-to-Hindi-Dictionary,"Lucknow,Uttar Pradesh"
learn-n-play-backend,"Educational platform with web speech recognition to help children practice basic reading, spelling and math skills! Rails API DB",josephscha,[],https://github.com/josephscha/learn-n-play-backend,https://api.github.com/users/josephscha,https://api.github.com/repos/josephscha/learn-n-play-backend,NYC
VUI-Speech-Recognizer,Built a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline.,manish8917,[],https://github.com/manish8917/VUI-Speech-Recognizer,https://api.github.com/users/manish8917,https://api.github.com/repos/manish8917/VUI-Speech-Recognizer,kolkata India
soundbird,A full-stack virtual soundboard platform with voice activation functionality. Uses the Web Speech Recognition API supported by Google Chrome.,DOORM4T,[],https://github.com/DOORM4T/soundbird,https://api.github.com/users/DOORM4T,https://api.github.com/repos/DOORM4T/soundbird,"Bay Area, California"
hackathon-IMA,"Implementation of a solution using Speech-To-Text, Named Entity Recognition (NER), Detection of emotions and feelings, ...",SinaArdehali,[],https://github.com/SinaArdehali/hackathon-IMA,https://api.github.com/users/SinaArdehali,https://api.github.com/repos/SinaArdehali/hackathon-IMA,France
masr,mASR ( m-Automatic Speech Recognition ) Thử nghiệm nhận dạng tiếng nói của những người limited về giọng nói.,phanxuanphucnd,[],https://github.com/phanxuanphucnd/masr,https://api.github.com/users/phanxuanphucnd,https://api.github.com/repos/phanxuanphucnd/masr,Hà Nội
English-to-English-dictionary,Here a code for english to english dictionary using python with speech recognition and voice output form,ar2000jun,[],https://github.com/ar2000jun/English-to-English-dictionary,https://api.github.com/users/ar2000jun,https://api.github.com/repos/ar2000jun/English-to-English-dictionary,"Lucknow,Uttar Pradesh"
Speech-Recognition,A test project for using speech recognition in large audio files due to limitations in the majority of SR frameworks.,markmelnic,"['audio-processing', 'speech-recognition', 'speech-to-text']",https://github.com/markmelnic/Speech-Recognition,https://api.github.com/users/markmelnic,https://api.github.com/repos/markmelnic/Speech-Recognition,"Amsterdam, NL | Chisinau, MD"
Deep-Neural-Network-DNN-Speech-Recognizer,Building a deep neural network (DNN) that functions as part of an end-to-end automatic speech recognition pipeline.,bahgat-ahmed,[],https://github.com/bahgat-ahmed/Deep-Neural-Network-DNN-Speech-Recognizer,https://api.github.com/users/bahgat-ahmed,https://api.github.com/repos/bahgat-ahmed/Deep-Neural-Network-DNN-Speech-Recognizer,"Mokattam, Cairo, Egypt"
Text_to_speech-bot,speech recognition software that will create files in directories and hopefully will allow you to write code as you talk,NiallBermin,[],https://github.com/NiallBermin/Text_to_speech-bot,https://api.github.com/users/NiallBermin,https://api.github.com/repos/NiallBermin/Text_to_speech-bot,Ireland
COVIDCensor,Use speech recognition to stop yourself from constantly speaking about the pandemic. For a minute. Inspiration: @kylemcdonald's COVIDPause,m3h0w,[],https://github.com/m3h0w/COVIDCensor,https://api.github.com/users/m3h0w,https://api.github.com/repos/m3h0w/COVIDCensor,Copenhagen
Speech-Recognition-with-Neural-Networks,Voice User Interface - Deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline,Akshat2127,[],https://github.com/Akshat2127/Speech-Recognition-with-Neural-Networks,https://api.github.com/users/Akshat2127,https://api.github.com/repos/Akshat2127/Speech-Recognition-with-Neural-Networks,New Hampshire
AI_assistant,It is the a speech recognition desktop assistant which will do tasks that are set by the user,rajprasad12,[],https://github.com/rajprasad12/AI_assistant,https://api.github.com/users/rajprasad12,https://api.github.com/repos/rajprasad12/AI_assistant,"West Bengal, India"
Jarvis,Simple python's AI project using Speech recognition and Pyaudio. It can do various work according to what you speak.,Mustafiz04,[],https://github.com/Mustafiz04/Jarvis,https://api.github.com/users/Mustafiz04,https://api.github.com/repos/Mustafiz04/Jarvis,"Mumbai, India"
textacles-server,Speech Recognition for Subtitle Glasses. The server side application that will read from the textacles-mobile application. ,the-sides,[],https://github.com/the-sides/textacles-server,https://api.github.com/users/the-sides,https://api.github.com/repos/the-sides/textacles-server,United States
voice-recogntition,This repo contains a voice-recogntion using google's speech recognition API and is written in python,luna215,[],https://github.com/luna215/voice-recogntition,https://api.github.com/users/luna215,https://api.github.com/repos/luna215/voice-recogntition,"Los Angeles, CA"
F22-novalogic-voice-commands,This is a project that demonstrates the use of python speech recognition to help control any sort of game.,Hamas-ur-Rehman,"['air', 'novalogic-games', 'python', 'python-files', 'speaker-recognition', 'voice-commands']",https://github.com/Hamas-ur-Rehman/F22-novalogic-voice-commands,https://api.github.com/users/Hamas-ur-Rehman,https://api.github.com/repos/Hamas-ur-Rehman/F22-novalogic-voice-commands,"Peshawar, Pakistan"
HumanDataAnalitycs,This is the repo to manage the HDA course project. The project will be about Automatic Speech Recognition,Fisher4537,[],https://github.com/Fisher4537/HumanDataAnalitycs,https://api.github.com/users/Fisher4537,https://api.github.com/repos/Fisher4537/HumanDataAnalitycs,"Padua, PD, Italy"
Automatic-Speech-Recognition,An end to end automatic speech recognition built as a part of Udacity Nanodegree on Natural Language Processing.,enfageorge,"['asr', 'cnn', 'deep-learning', 'keras', 'natural-language-processing', 'rnn', 'udacity-nanodegree']",https://github.com/enfageorge/Automatic-Speech-Recognition,https://api.github.com/users/enfageorge,https://api.github.com/repos/enfageorge/Automatic-Speech-Recognition,"Kochi,India"
recognitionTest,This is a test application  which uses the   C++ programming   to  converts  speech  to  text  with  a recognition  algorithmn.,donovan680,[],https://github.com/donovan680/recognitionTest,https://api.github.com/users/donovan680,https://api.github.com/repos/donovan680/recognitionTest,São  Paulo -Brazil
voiceControlledcalculator,"web based calculator designed to solve arithmetic operations using voice recognition, with the help of google text-to-speech API",neelstrongarm,[],https://github.com/neelstrongarm/voiceControlledcalculator,https://api.github.com/users/neelstrongarm,https://api.github.com/repos/neelstrongarm/voiceControlledcalculator,Bangalore
asr-notes,"Notes for the 4th year Automatic Speech Recognition course at the School of Informatics, University of Edinburgh.",eonu,[],https://github.com/eonu/asr-notes,https://api.github.com/users/eonu,https://api.github.com/repos/eonu/asr-notes,"Edinburgh, United Kingdom"
Transcriber,"Transcribes MP3 Files with Times using Google Cloud Speech Recognition, and types to keyboard at song pace",amahesh98,[],https://github.com/amahesh98/Transcriber,https://api.github.com/users/amahesh98,https://api.github.com/repos/amahesh98/Transcriber,"San Jose, CA"
voiceRecognition,"This is a voice recognition program to open web browsers with a simple speech like ""google, youtube, facebook, and etc"".",rxYoungho,[],https://github.com/rxYoungho/voiceRecognition,https://api.github.com/users/rxYoungho,https://api.github.com/repos/rxYoungho/voiceRecognition,"Songdo, Incheon, South Korea"
Speech-Recognition-AI,"Speech Recognition & AI related to The Complete Python 3 Course: Beginner to Advanced!  Created by Joseph Delgadillo, Nick Germaineameters.",hosseinhgp,[],https://github.com/hosseinhgp/Speech-Recognition-AI,https://api.github.com/users/hosseinhgp,https://api.github.com/repos/hosseinhgp/Speech-Recognition-AI,Palo Alto
JARVIS---Speech-Recognition-Assistant,This is an Speech Recognition Assistant named JARVIS made using Python's speechrecognition API with a lot cool automated stuffs,sarwar1227,[],https://github.com/sarwar1227/JARVIS---Speech-Recognition-Assistant,https://api.github.com/users/sarwar1227,https://api.github.com/repos/sarwar1227/JARVIS---Speech-Recognition-Assistant,"Delhi,India"
Speech-Recognizer,I built a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline,iDataist,[],https://github.com/iDataist/Speech-Recognizer,https://api.github.com/users/iDataist,https://api.github.com/repos/iDataist/Speech-Recognizer,"Houston, Texas"
SpeechRecognition,console application which uses the Windows speech recognition with the .net c# API to create a text-adventure type game,BahuMan,[],https://github.com/BahuMan/SpeechRecognition,https://api.github.com/users/BahuMan,https://api.github.com/repos/BahuMan/SpeechRecognition,Antwerpen
Stacked-LSTM-for-Covid-19-Outbreak-Prediction,"Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).  It was first identified in December 2019 in Wuhan, China, and has since spread globally, resulting in an ongoing pandemic. Long Short Term Memories(LSTMs) can solve numerous tasks not solvable by previous learning algorithms for recurrent neural networks (RNNs). LSTM is applicable to tasks such as unsegmented, connected handwriting recognition, speech recognition and anomaly detection in network traffic or IDS's (intrusion detection systems). LSTMs can also be efficiently applied for time-series predictions. In this project, its shows a four stacked LSTM network for early prediction  new Coronavirus dissease infections in some of the mentioned  affected countries (India, USA, Czech Republic and Russia) , which is based on real world data sets which are analyzed using various perspectives like day-wise number of confirmed cases, number of Cured cases, death cases. This attempt has been done to help the concerned authorities to get some early insights into the probable devastation likely to be effected by the deadly pandemic.",aparajitad60,"['artificial-neural-networks', 'covid-19', 'covid-19-czech', 'covid-19-india', 'covid-19-russia', 'covid-19-usa', 'covid19-data', 'data-visualization', 'deep-neural-networks', 'keras-tensorflow', 'lstm', 'recurrent-neural-networks', 'rnn-tensorflow', 'stacked-lstm', 'time-series-forecasting', 'time-series-prediction']",https://github.com/aparajitad60/Stacked-LSTM-for-Covid-19-Outbreak-Prediction,https://api.github.com/users/aparajitad60,https://api.github.com/repos/aparajitad60/Stacked-LSTM-for-Covid-19-Outbreak-Prediction,India
P1-Part-of-Speech-Tagging,"In this project, I'll use the Pomegranate library to build a hidden Markov model for part of speech tagging with a universal tagset. Hidden Markov models have been able to achieve >96% tag accuracy with larger tagsets on realistic text corpora. Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision, and more.",YousefKJM,[],https://github.com/YousefKJM/P1-Part-of-Speech-Tagging,https://api.github.com/users/YousefKJM,https://api.github.com/repos/YousefKJM/P1-Part-of-Speech-Tagging,Saudi Arabia
AI-Assistant-with-Python,"This a AI Assistant using Python Programming language, with text-to-speech output and speech recognition. It can do simple tasks in daily life like greetings to the user, playing music, sending email opening various applications etc. ",ri5h46h,[],https://github.com/ri5h46h/AI-Assistant-with-Python,https://api.github.com/users/ri5h46h,https://api.github.com/repos/ri5h46h/AI-Assistant-with-Python,"Gandhinagar, Gujarat, India"
Speakulator,A speech recognition based calculator which performs calculations spoken in sophisticated and lay man terms in English or Hindi to give results in speech based output. Designed to overcome the shortcoming out google assistant and help blinds.,vishalstark,[],https://github.com/vishalstark/Speakulator,https://api.github.com/users/vishalstark,https://api.github.com/repos/vishalstark/Speakulator,Boston
elements-Voice-Image-Editor,"Elements is an image editing desktop app where the user can use voice commands to edit images. The base development tools are tkinter, google speech recognition,pyttsx3(offline text to speech).",11dmj,[],https://github.com/11dmj/elements-Voice-Image-Editor,https://api.github.com/users/11dmj,https://api.github.com/repos/11dmj/elements-Voice-Image-Editor,"Kottayam(dist.), India"
Voice-enabled-chabot,This Project presents a multi-lingual voice assisted chatbot for answering admission queries using tensorflow. Created a website for user interface using Django while speech recognition and speech synthesis done in javascript.,Valentine9594,[],https://github.com/Valentine9594/Voice-enabled-chabot,https://api.github.com/users/Valentine9594,https://api.github.com/repos/Valentine9594/Voice-enabled-chabot,"Mumbai, Maharahstra"
voskSpeechRecognition,voskSpeechRecognition: Implementation of an offline speech recognition system using the vosk API in Python. Network audio source reception via YARP. Broadcast of voice recognition results over the network. via YARP.,davidvelascogarcia,"['language-table', 'selected-language', 'speech-recognition', 'vosk-models', 'yarp']",https://github.com/davidvelascogarcia/voskSpeechRecognition,https://api.github.com/users/davidvelascogarcia,https://api.github.com/repos/davidvelascogarcia/voskSpeechRecognition,Spain
speech_to_text_via_microphone, This is a python script that gets the audio from the microphone with PyAudio library and by using the SpeechRecognition library and google speech recognition converts the audio into text.,chriskaravel,[],https://github.com/chriskaravel/speech_to_text_via_microphone,https://api.github.com/users/chriskaravel,https://api.github.com/repos/chriskaravel/speech_to_text_via_microphone,"London, UK"
practice_listening_tool,This is a web-based listening practice tool using Google Speech Recognition API to help nonnative English speakers practice English listening.,yukeyang32,[],https://github.com/yukeyang32/practice_listening_tool,https://api.github.com/users/yukeyang32,https://api.github.com/repos/yukeyang32/practice_listening_tool,"Ithaca, New York"
Google_Speech_Recognition,This is a project that analyzes how accurate Google's speech recognition is of English from a native speaker compared to English from a native Chinese person.,justingirgis,[],https://github.com/justingirgis/Google_Speech_Recognition,https://api.github.com/users/justingirgis,https://api.github.com/repos/justingirgis/Google_Speech_Recognition,Orange County
MVA_NLP_Projects,Two projects consisting of classifying voice commands and building a parser from scratch for the course Speech Recognition and NLP (Master MVA).,ganshofp,[],https://github.com/ganshofp/MVA_NLP_Projects,https://api.github.com/users/ganshofp,https://api.github.com/repos/ganshofp/MVA_NLP_Projects,Paris
Login-Register-OCR-TTS,"An app with the functionalities of Optical Character Recognition and Text-to-Speech Conversion, along with the User Login and Registration using SQLite Database.",ActuallySam,"['android-app', 'login-registration-app', 'ocr-recognition', 'optical-character-recognition', 'sqlite', 'text-to-speech']",https://github.com/ActuallySam/Login-Register-OCR-TTS,https://api.github.com/users/ActuallySam,https://api.github.com/repos/ActuallySam/Login-Register-OCR-TTS,Pune
P3-DNN-Speech-Recognizer,"In this notebook, I will build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline!",YousefKJM,"['asr', 'deep-neural-network', 'librispeech-dataset', 'nlp', 'notebook']",https://github.com/YousefKJM/P3-DNN-Speech-Recognizer,https://api.github.com/users/YousefKJM,https://api.github.com/repos/YousefKJM/P3-DNN-Speech-Recognizer,Saudi Arabia
NLP-DNN-Speech-Recognizer,"In this project, we will build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline.",NomanNasirMinhas,[],https://github.com/NomanNasirMinhas/NLP-DNN-Speech-Recognizer,https://api.github.com/users/NomanNasirMinhas,https://api.github.com/repos/NomanNasirMinhas/NLP-DNN-Speech-Recognizer,"Islamabad,Pakistan"
Deep-Neural-Network-Speech-Recognizer,"In this repo, I have built a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline.",amanjeetsahu,[],https://github.com/amanjeetsahu/Deep-Neural-Network-Speech-Recognizer,https://api.github.com/users/amanjeetsahu,https://api.github.com/repos/amanjeetsahu/Deep-Neural-Network-Speech-Recognizer,"Bengaluru, India"
python-speechprocessing-example,"This is sample python code to help understanding steps of Mel Cepstral feature extraction, as used in Automatic Speech Recognition (ASR), Automatic Speaker Verification and Machine Learning.",footfish,[],https://github.com/footfish/python-speechprocessing-example,https://api.github.com/users/footfish,https://api.github.com/repos/footfish/python-speechprocessing-example,Ireland
STAN-Guess-The-Song,An interactive Song Quiz created using Google Speech Recognition in which a user can play quiz to guess different songs using voice assistant.,anonymerd,[],https://github.com/anonymerd/STAN-Guess-The-Song,https://api.github.com/users/anonymerd,https://api.github.com/repos/anonymerd/STAN-Guess-The-Song,"Meerut, Uttar Pradesh, India"
speech_to_text_via_audiofile, This is a python script that reads an audio transcript and by using the SpeechRecognition library and google speech recognition converts the audio into text.,chriskaravel,[],https://github.com/chriskaravel/speech_to_text_via_audiofile,https://api.github.com/users/chriskaravel,https://api.github.com/repos/chriskaravel/speech_to_text_via_audiofile,"London, UK"
Speech-to-Text-App-in-Python,"This is a very simple voice input app for Windows (tested on Windows 10), written in Python (tested on Python 3.4)  Dependencies:   - pygame - speech_recognition - pyperclip ",Nouman945,[],https://github.com/Nouman945/Speech-to-Text-App-in-Python,https://api.github.com/users/Nouman945,https://api.github.com/repos/Nouman945/Speech-to-Text-App-in-Python,"Pakistan, Kashmir"
Desktop-Assistant-64Bit,A simple Desktop Assistant that makes your work easy. This software is coded using Python and Speech Recognition module is used to take Command.,Arshad272,[],https://github.com/Arshad272/Desktop-Assistant-64Bit,https://api.github.com/users/Arshad272,https://api.github.com/repos/Arshad272/Desktop-Assistant-64Bit,"Puttur, Andhra Pradesh, India "
cs230_ASR-CLD,"Term project for Stanford CS230, Deep Learning.  Project is an implementation of Deep Learning for Automatic Speech Recognition as an interactive tool for language development in children",dan-ryan21,[],https://github.com/dan-ryan21/cs230_ASR-CLD,https://api.github.com/users/dan-ryan21,https://api.github.com/repos/dan-ryan21/cs230_ASR-CLD,"Charleston, SC"
BSMR,"This app is a tribute to Bangabandhu Sheikh Mujibur Rahman on his 100th year of birth . In this simple app we can see his speech , recognitions ,photo archive .",Toufiqulhaquemamun,[],https://github.com/Toufiqulhaquemamun/BSMR,https://api.github.com/users/Toufiqulhaquemamun,https://api.github.com/repos/Toufiqulhaquemamun/BSMR,"Banani, Dhaka ,Bangladesh"
Alexa-coinflip,A fun experiment with Alexa using speech recognition to do statistical analysis on the Alexa's in built coin flip probability,sandipde,[],https://github.com/sandipde/Alexa-coinflip,https://api.github.com/users/sandipde,https://api.github.com/repos/sandipde/Alexa-coinflip,Ludwigshafen
personal_assistant,An android app which has speech recognition feature to collect data and send them to a remote server (generally your laptop :)).,EmreOzkose,"['basic', 'english', 'personal-assistant', 'speech-recognition', 'speech-to-text', 'turkish']",https://github.com/EmreOzkose/personal_assistant,https://api.github.com/users/EmreOzkose,https://api.github.com/repos/EmreOzkose/personal_assistant,Ankara/Turkey
Typify,Typify is a tool built on speech recognition and qt using python and compiled to native code. It takes audio data and starts typing it automatically,he-man3110,[],https://github.com/he-man3110/Typify,https://api.github.com/users/he-man3110,https://api.github.com/repos/he-man3110/Typify,"Karnataka,India."
AI-Music-Player-Android-Application,That is android application bases on the java and device speech recognition system and now you can tell and play your favorite songs by voice commands.  ,SamilaChanu95,[],https://github.com/SamilaChanu95/AI-Music-Player-Android-Application,https://api.github.com/users/SamilaChanu95,https://api.github.com/repos/SamilaChanu95/AI-Music-Player-Android-Application,Colombo
BrianTheBombBot,Brian the Bomb Bot is a speech recognition app written in Python to solve all the puzzles in the game 'Keep Talking and Nobody Explodes',EuanMorgan,[],https://github.com/EuanMorgan/BrianTheBombBot,https://api.github.com/users/EuanMorgan,https://api.github.com/repos/EuanMorgan/BrianTheBombBot,"Cardiff, UK"
Signify,A cross model translation system from Speech to Indian Sign Language along with an emotion recognition system for real-time user input.,theDeepanshuMourya,"['asl-translator', 'python', 'real-time', 'sign-language', 'speech-emotion-recognition', 'translation']",https://github.com/theDeepanshuMourya/Signify,https://api.github.com/users/theDeepanshuMourya,https://api.github.com/repos/theDeepanshuMourya/Signify,"New Delhi , India"
Sign_language_alphabet_recognizer,Sign Language Alphabet Recognition System that automatically detects American Sign Language and convert gestures from live webcam into text and speech.,parakh-gupta,"['asl-recognizer', 'convolutional-neural-network', 'deep-learning', 'hand-gesture-recognition', 'machine-learning', 'sign-language-recognizer']",https://github.com/parakh-gupta/Sign_language_alphabet_recognizer,https://api.github.com/users/parakh-gupta,https://api.github.com/repos/parakh-gupta/Sign_language_alphabet_recognizer,"Delhi , India"
posner,"A toolkit implementing state-of-art models in Chinese word segmentation(CWS), part-of-speech (POS), and Name Entity Recognition(NER).",LeeKLTW,"['bert', 'crf', 'ner', 'segmentation', 'wwm']",https://github.com/LeeKLTW/posner,https://api.github.com/users/LeeKLTW,https://api.github.com/repos/LeeKLTW/posner,"Taipei, Taiwan"
Desktop-Assistant-32Bit,A simple Desktop Assistant that makes your work easy. This software is coded using Python and Speech Recognition module is used to take Command. ,Arshad272,[],https://github.com/Arshad272/Desktop-Assistant-32Bit,https://api.github.com/users/Arshad272,https://api.github.com/repos/Arshad272/Desktop-Assistant-32Bit,"Puttur, Andhra Pradesh, India "
JARVIS_2017_CODE,"worked on Development of a voice output based virtual Assistant that could be interface external Hardware control , Based on Speech Recognition (Google Speech API), Text to voice speech and with the capabilities of internally communicate with other APIs to give information about weather, NEWS etc. ",Adityavj2699,[],https://github.com/Adityavj2699/JARVIS_2017_CODE,https://api.github.com/users/Adityavj2699,https://api.github.com/repos/Adityavj2699/JARVIS_2017_CODE,"Ahmedbad,Gujrat,India"
lac_tools_benchment,中文分词、词性标注、实体识别的工具整理；相关数据集整理与预处理；通用评测脚本脚本【Benchmark of Chinese Word Segment (CWS)、Part of Speech Tagging(PosTag)、Name Entity Recognition (NER) 】,Bond-H,[],https://github.com/Bond-H/lac_tools_benchment,https://api.github.com/users/Bond-H,https://api.github.com/repos/Bond-H/lac_tools_benchment,"Shenzhen, China"
JG.Speech.Robot,"It is a simple interactive robot created using the technologies: C# + Speech.Recognition. It was created to tell some stories and to have fun my own kids, there isn't a commercial purposes.",juninhograo,[],https://github.com/juninhograo/JG.Speech.Robot,https://api.github.com/users/juninhograo,https://api.github.com/repos/juninhograo/JG.Speech.Robot,USA
VoiceNative,"React Native Demo for Voice to Text with @react-native-community/voice (https://github.com/react-native-community/voice), from Blog https://medium.com/jeremy-gottfrieds-tech-blog/tutorial-react-native-speech-recognition-d9ae54960565",hersharan,[],https://github.com/hersharan/VoiceNative,https://api.github.com/users/hersharan,https://api.github.com/repos/hersharan/VoiceNative,"New Delhi, India"
Ibrahim_Virtual_Assistant,"A Virtual Assistant that communicates with you and performs specific tasks built with Speech recognition, Wikipedia, Webbrowser, Pyttsx3 modules, and also imports real time data from a Google Sheet. ",ibrahimshittu,[],https://github.com/ibrahimshittu/Ibrahim_Virtual_Assistant,https://api.github.com/users/ibrahimshittu,https://api.github.com/repos/ibrahimshittu/Ibrahim_Virtual_Assistant,Remote
Meeting-Summarizer,"Holistic solution to help companies convert meeting conversations audio into a single-page summary using Python libraries such as NLTK, docx, Speech Recognition, Glove Algorithm, Text Embeddings, Page Rank, Networkx",vibhavps,[],https://github.com/vibhavps/Meeting-Summarizer,https://api.github.com/users/vibhavps,https://api.github.com/repos/vibhavps/Meeting-Summarizer,"Minneapolis, MN, USA"
Notepad-with-Sentiment-Analysis,"Notepad with Sentiment Analysis is a  Desktop Application built upon the idea of Accessibility , Security and Minimalism. Dependencies : API-Google Speech Recognition ; Libraries-PyPi ; GUI-Tkinter. Architecture :- MVC(Model View Controller).",prakharindoria,[],https://github.com/prakharindoria/Notepad-with-Sentiment-Analysis,https://api.github.com/users/prakharindoria,https://api.github.com/repos/prakharindoria/Notepad-with-Sentiment-Analysis,"Bhopal,India"
pythonMachineLearnExamples,"What is NLP and its applications, NLP basics Touring Python NLP libraries, Tokenization Part-of-speech, tagging Named entities, recognition Stemming and lemmatization, Getting and exploring the newsgroups data.",GIGA-Money,[],https://github.com/GIGA-Money/pythonMachineLearnExamples,https://api.github.com/users/GIGA-Money,https://api.github.com/repos/GIGA-Money/pythonMachineLearnExamples,"Atlanta, GA"
Artificial-Intelligence-CS-404,"In this course, various topics in AI (agents, problem solving by searching, logic and reasoning, planning, probability and utility theories, learning, etc.) are covered in depth, and various application areas are introduced briefly (speech recognition, natural language understanding, robotics,...).",BaturGultekin,[],https://github.com/BaturGultekin/Artificial-Intelligence-CS-404,https://api.github.com/users/BaturGultekin,https://api.github.com/repos/BaturGultekin/Artificial-Intelligence-CS-404,"Orta Mahallesi, Sabancı Üniversitesi, 34956 Tuzla/İstanbul, Turkey"
COVID19_Web_Scraper,"Scrapes COVID-19 data from the site worldometers.info and allows users to ask about country-wise live statistics of the development of COVID-19 in the country. Uses speech recognition to detect, understand and reply to the user. ",jash-05,[],https://github.com/jash-05/COVID19_Web_Scraper,https://api.github.com/users/jash-05,https://api.github.com/repos/jash-05/COVID19_Web_Scraper,"San Jose, CA"
David-Voice-Assistant,"Developed using Google speech recognition support for python. It controls the basic tasks of sending emails, opening Spotify, searching Google and Youtube for the user, and playing videos, opening URLs using voice commands. Opening basic applications like Code IDE etc.",chitrank0614,[],https://github.com/chitrank0614/David-Voice-Assistant,https://api.github.com/users/chitrank0614,https://api.github.com/repos/chitrank0614/David-Voice-Assistant,"Noida, New Delhi"
pythonSpeechRecognition,Cron jobs for speech recognition. THe user uses a GUI to upload a recorded audio of his or her voice and then its save it in a server and stream it in the GUI,nemesis1346,[],https://github.com/nemesis1346/pythonSpeechRecognition,https://api.github.com/users/nemesis1346,https://api.github.com/repos/nemesis1346/pythonSpeechRecognition,Canada
OCULUS,"Simple command line app to help blind people read textual information by using camera, Optical character recognition and speech synthesis , This project is was tested in Linux operating system",Kalebu,[],https://github.com/Kalebu/OCULUS,https://api.github.com/users/Kalebu,https://api.github.com/repos/Kalebu/OCULUS,"Dar es Salaam , Tanzania"
DeepSpeech-Neural-Network-Recognition,Developed an end-to-end automatic speech recognition (ASR) pipeline Machine Translation System which takes user voice as input and converts the input into a an english Sentence of 2 primary Machine Learning Models using Keras Framework,aakash26,[],https://github.com/aakash26/DeepSpeech-Neural-Network-Recognition,https://api.github.com/users/aakash26,https://api.github.com/repos/aakash26/DeepSpeech-Neural-Network-Recognition,"Saarland,Germany"
ccProject2,"A Flask-based Web App designed to exemplify the power of PaasS platform by deploying this scalable application on Google App Engine. It uses GAE, Microsoft Speaker Recognition API, Google Speech-to-Text API and Cloud Firestore.",harshaltrivedi10,[],https://github.com/harshaltrivedi10/ccProject2,https://api.github.com/users/harshaltrivedi10,https://api.github.com/repos/harshaltrivedi10/ccProject2,"Tempe, Arizona"
NewyorktimesbestsellerApp,This application allows for a user to use a picker view or speech recognition to filter out and present a custom collection view of The New York Times' best sellers lists based by category,tseringlamanyc,[],https://github.com/tseringlamanyc/NewyorktimesbestsellerApp,https://api.github.com/users/tseringlamanyc,https://api.github.com/repos/tseringlamanyc/NewyorktimesbestsellerApp,New York 
AdvanceSiteScraper,this is a site scrapper who can scrape data from wikipedia and stackoverflow website. It is build with TTS and Speech Recognition so it can speak the scrape data and we can give command by voice,NitishBhatt07,[],https://github.com/NitishBhatt07/AdvanceSiteScraper,https://api.github.com/users/NitishBhatt07,https://api.github.com/repos/NitishBhatt07/AdvanceSiteScraper,India
Video-Speech-Recognition-Tools,"(WiP) A toolkit for transcription of speech from videos. Basis for this is the Speech-Recognition python package, via which I utilised common APIs from Google, IBM, and other. Additionally, I included a tool which uses ffmpeg for video-to-audio conversion.",oliso,[],https://github.com/oliso/Video-Speech-Recognition-Tools,https://api.github.com/users/oliso,https://api.github.com/repos/oliso/Video-Speech-Recognition-Tools,"Bratislava, Slovakia"
speech-recognition-convolutional-nn,"Experiment in Speech Recognition on Google's Speech Command Dataset using Tensorflow/Keras. 88%-89% validation accuracy achieved classifying between spoken digits (zero through nine) using MFCC transformation and a deep CNN.  Work in progress, a couple preprocessing functions disclaimed as borrowed in the code.",michaelznidarsic,[],https://github.com/michaelznidarsic/speech-recognition-convolutional-nn,https://api.github.com/users/michaelznidarsic,https://api.github.com/repos/michaelznidarsic/speech-recognition-convolutional-nn,SF Bay Area
DeltaHacksFrontEnd,"User interface of the full-stack website my group and I created during Delta Hacks VI using React.JS. Using React's speech recognition, we were able to connect the front end with a Python back end, where we implemented Natural Language Processing to detect tone of a users speech, provide feedback, etc. Similar to Grammarly.",noopta,[],https://github.com/noopta/DeltaHacksFrontEnd,https://api.github.com/users/noopta,https://api.github.com/repos/noopta/DeltaHacksFrontEnd,"Guelph, Ontario CA"
auntemma,"Aunt Emma is a cross platform speech 2 text software using google android's offline speech recognition api. Pleeease use Aunt Emma ONLY to translate Bibles for this insane world, and not for other unimportant rubbish.... And don't steal from the poor. If you don't, your Grandma will stop praying for you!",simonegli8,[],https://github.com/simonegli8/auntemma,https://api.github.com/users/simonegli8,https://api.github.com/repos/simonegli8/auntemma,"Granada, Nicaragua"
Voice-Assistant-For-Laptop,"Objective: To make a voice assistant for a windows laptop which can entertain, open applications and websites and send emails for you. The code is written in python and is an application of Natural language processing concepts like Speech Recognition & Speech Synthesis. ",prachi-mate,"['jarvis', 'natural-language-processing', 'speech-recognition', 'speech-synthesis', 'voice-assistant']",https://github.com/prachi-mate/Voice-Assistant-For-Laptop,https://api.github.com/users/prachi-mate,https://api.github.com/repos/prachi-mate/Voice-Assistant-For-Laptop,Mumbai
liri-bot,"LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a Language Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",edwardphill,[],https://github.com/edwardphill/liri-bot,https://api.github.com/users/edwardphill,https://api.github.com/repos/edwardphill/liri-bot,"Brooklyn, NY"
liri-node-app,"IRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a Language Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",r-andrew-dev,[],https://github.com/r-andrew-dev/liri-node-app,https://api.github.com/users/r-andrew-dev,https://api.github.com/repos/r-andrew-dev/liri-node-app,WI 
LIRI-Bot,"LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface,  LIRI is a _Language_ Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",jaswhitehead,[],https://github.com/jaswhitehead/LIRI-Bot,https://api.github.com/users/jaswhitehead,https://api.github.com/repos/jaswhitehead/LIRI-Bot,"Nashville, TN"
liri-node-app," LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a _Language_ Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",noctuakitty,[],https://github.com/noctuakitty/liri-node-app,https://api.github.com/users/noctuakitty,https://api.github.com/repos/noctuakitty/liri-node-app,"Rifle, Colorado"
Hw9-Liribot,"In this assignment, you will make LIRI. LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a Language Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",christianlMaldonado,[],https://github.com/christianlMaldonado/Hw9-Liribot,https://api.github.com/users/christianlMaldonado,https://api.github.com/repos/christianlMaldonado/Hw9-Liribot,"Salinas, CA"
LIRI-Bot,"LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a _Language_ Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",YPangilinan,[],https://github.com/YPangilinan/LIRI-Bot,https://api.github.com/users/YPangilinan,https://api.github.com/repos/YPangilinan/LIRI-Bot,"San Jose, California"
liri-node-app,"LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a Language Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",semicolinc,[],https://github.com/semicolinc/liri-node-app,https://api.github.com/users/semicolinc,https://api.github.com/repos/semicolinc/liri-node-app,California
Liri-Node-App,"LIRI is like iPhone's SIRI. However, while SIRI is a Speech Interpretation and Recognition Interface, LIRI is a _Language_ Interpretation and Recognition Interface. LIRI will be a command line node app that takes in parameters and gives you back data.",yuriyhorbatenko,['node-js'],https://github.com/yuriyhorbatenko/Liri-Node-App,https://api.github.com/users/yuriyhorbatenko,https://api.github.com/repos/yuriyhorbatenko/Liri-Node-App,"Philadelphia, PA"
audio2srt,"The WebRTC-based Vad audio cutting algorithm cuts the audio, and then converts the speech to srt subtitles through Alibaba Cloud / Baidu Cloud's speech recognition cloud services.（基于 WebRTC 的 Vad 音频切割算法对音频进行切割，然后通过阿里云/百度云的语音识别云服务将语音转为 srt 字幕，本程序无日使用时长限制）",GanymedeNil,[],https://github.com/GanymedeNil/audio2srt,https://api.github.com/users/GanymedeNil,https://api.github.com/repos/GanymedeNil/audio2srt,"China,Beijing"
Audio-Enabled-Chatbot,Developed web based application in which users ask the questions to the Bot and the Bot fetch the appropriate response from the database and provide to the users in appropriate manner. It Included with parsing of speech to string which can be easily embedded in query and can be fired to fetch relatable response from the database. Used the open-source Anaconda platform to run Python script and Google speech recognition API to convert speech to text. Used CGI (Common Gateway Interface) program for transferring answers to the website.,Smit-Kakadiya,"['cgi', 'css3', 'html5', 'javascript', 'mysql', 'php', 'python']",https://github.com/Smit-Kakadiya/Audio-Enabled-Chatbot,https://api.github.com/users/Smit-Kakadiya,https://api.github.com/repos/Smit-Kakadiya/Audio-Enabled-Chatbot,"West Haven, CT"
Automatic-Speech-Recognition-with-Hidden-Markov-model,"This project attempts to train a Continuous Density Hidden Markov Model (CD-HMM) for speech recognition, and is developed with Matlab software. This objective is reached using the Expectation-Maximization approach using the Baum-Welch equations. The training process uses two steps which are computing the Expectations (E-step) and Maximizing those expectations by re-estimation of the parameters (M-step). The methodology and results are discussed to provide a clear understanding of the motivations and limits of this project.",maxboels,[],https://github.com/maxboels/Automatic-Speech-Recognition-with-Hidden-Markov-model,https://api.github.com/users/maxboels,https://api.github.com/repos/maxboels/Automatic-Speech-Recognition-with-Hidden-Markov-model,"London, UK"
personal-linux-voice-assistant,"Our system is an intelligent virtual assistant (IVA) or intelligent personal assistant (IPA).Our system  is a software agent that can perform tasks or services for an individual based on commands or questions. It is completely made for the usage of this system in Linux operating systems. This system is programmed in python 3 and it uses speech recognition library in python 3. Our software features many advanced features such as voice commanded operations such as Event Remainders, Weather forecasting, You-tube search, Google search, Wikipedia search, Opening of Applications, Voice typing and keyboard controls. Our system uses python speech recognition library to extract data from the user speech data. The personal Linux voice assistant ease out the use of Linux system by making the operating system more user friendly.",Surya2709,[],https://github.com/Surya2709/personal-linux-voice-assistant,https://api.github.com/users/Surya2709,https://api.github.com/repos/Surya2709/personal-linux-voice-assistant,Tirupur
Smart-Reviewer,"Problem identified:   In places such as cafes, shops, movie theatre, it's very difficult to collect review to know the performance quality by making them fill the form, it's very time consuming and sometimes confusing. According to recent research, 84% of people fill out at least one web form per week. Which supports our stance that most of the people prefer to review by saying it rather than filling any form.     Solution:  So to solve this problem and enhance communication, we have made this project that collects people’s review by asking them personally, and analyze whether the review is positive, negative or neutral and hence bridges the communication gap.     So, in order to achieve this, we have used technologies such as speech-to-text and text-to-speech conversion. On starting the program, a page designed using Tkinter (pythons GUI), opens up. On the click of the button, the program starts talking to the user, which makes it easier for the user to understand what to do, using text to speech. The person can then speak and record its review. The speech and text conversion were achieved using the libraries namely speech_recognition, pyttsx3, and gTTS.     Note:   You need to have these packages on your computer in order to run the program.  Execute the following lines of code in your command prompt to install the packages.  pip install speech_recognition  pip install pyttsx3 (if this dows noot get installed, kindly install the .whl file for the corresponding library.)  pip install gTTS        speech_recognition: Recognizing speech requires audio input, and SpeechRecognition makes retrieving this input really easy. Instead of having to build scripts for accessing microphones and processing audio files from scratch, SpeechRecognition will have you up and running in just a few minutes.     pyttsx3:  is a text-to-speech conversion library in Python.     gTTS (Google Text-to-Speech):  a Python library and CLI tool to interface with Google Translate's text-to-speech API  textblob- Textblob and its NLPTK libraries.     After recording the review from a customer, it analyses whether the review given is positive or negative or neutral, and to do this we have used textblob and its NLPTK libraries. And all the reviews are stored in a database called db.txt file for future reference.   Recommendation: Run the code using the Visual Studio Code.   Project Done By: Divya Mahur (18BCE106)  Gaurav Vinod Bhambhani (18BCE072)  ",Divs-2606,[],https://github.com/Divs-2606/Smart-Reviewer,https://api.github.com/users/Divs-2606,https://api.github.com/repos/Divs-2606/Smart-Reviewer,Ahmedabad
Virtual-Police-Station,"• Aiming to interact with victim to take all the detail using Speech Recognition System, for the victim        Authentication used digital signature, after information submitted by the victim then make it into FIR format Automatically. This FIR would routed to CCTNS System (State Centre Server) and then this FIR send to nearest police  station.Authentication based on aadhar number. ",shubhamwagh84,[],https://github.com/shubhamwagh84/Virtual-Police-Station,https://api.github.com/users/shubhamwagh84,https://api.github.com/repos/shubhamwagh84/Virtual-Police-Station,Mumbai
deep-speech-vis,This work applies one of the recent visualization techniques used in computer vision domain ‘layer-wise relevance propagation’ algorithm for kernels and deep neural networks in automatic speech recognition task. It attempts to make the hidden layers in deep learning systems more interpretable by adding another visualization tool.,anondo1969,"['automatic-speech-recognition', 'ddeep-neural-networks', 'deep-learning', 'natural-language-processing', 'visualization']",https://github.com/anondo1969/deep-speech-vis,https://api.github.com/users/anondo1969,https://api.github.com/repos/anondo1969/deep-speech-vis,"Stockholm, Sweden"
instrumental-music-translation,"Course Project for Automatic Speech Recognition(CS 753), Autumn 2019, CSE, IIT Bombay. Implemented music translation from one instrument to another using two approaches, a WaveNet autoencoder heavily based on a Facebook AI research paper and codebase and the other using different LSTM encoder-decoder based architectures.",ajd12342,[],https://github.com/ajd12342/instrumental-music-translation,https://api.github.com/users/ajd12342,https://api.github.com/repos/ajd12342/instrumental-music-translation,"Austin, Texas"
Data-Science-Professional-Certificate-by-Harvard-University,"Perhaps the most popular data science methodologies come from machine learning. What distinguishes machine learning from other computer guided decision processes is that it builds prediction algorithms using data. Some of the most popular products that use machine learning include the handwriting readers implemented by the postal service, speech recognition, movie recommendation.",vishwasbasotra,[],https://github.com/vishwasbasotra/Data-Science-Professional-Certificate-by-Harvard-University,https://api.github.com/users/vishwasbasotra,https://api.github.com/repos/vishwasbasotra/Data-Science-Professional-Certificate-by-Harvard-University,Chennai
Project-Humanoid-Bot,"WANG REDA, A Humanoid Robot for society during initial days of post COVID-19 situation. This robot spreads awareness among human species to know about physical distancing, by monitoring the same and speech recognition based Q&A. Click the link to view the ppt :",asv0018,"['bot', 'humanoid', 'humanoid-robot', 'jeevasamrakshak-hackathon', 'opencv', 'physical-distancing', 'reva', 'speech']",https://github.com/asv0018/Project-Humanoid-Bot,https://api.github.com/users/asv0018,https://api.github.com/repos/asv0018/Project-Humanoid-Bot,Bengaluru
Speech-Recognition-with-Python,"This repository contains resources from The  Guide to Speech Recognition with  Python.  Audio files for the examples in the Working With Audio Files section of the post can be found in the audio_files directory. To download them, use the green ""Clone or download"" button at the top right corner of this page.  The guessing_game.py file contains the full source code for the ""Guess a Word"" game example.      NOTE: You will need to install the SpeechRecognition and PyAudio packages in order to run the example.   You can test your SpeechRecognition and PyAudio installation by downloading guessing_game.py and typing the following into a Python REPL session:  >>> import speech_recognition as sr >>> from guessing_game.py import recognize_speech_from_mic >>> r = sr.Recognizer() >>> m = sr.Microphone() >>> recognize_speech_from_mic(r, m)  # speak after running this line {'success': True, 'error': None, 'transcription': 'hello'}  Of course, your output will vary depending on what you said after running recognize_speech_from_mic(r, m).",Abhishesh123,[],https://github.com/Abhishesh123/Speech-Recognition-with-Python,https://api.github.com/users/Abhishesh123,https://api.github.com/repos/Abhishesh123/Speech-Recognition-with-Python,"Delhi ,india"
EPL-Analysis,"Machine Learning is basically an application of Artificial Intelligence (AI) that provides a computer system, the ability to automatically learn and improve from its experience, without any human intervention or explicit coding. Machine Learning is being used these days in many walks of our daily life such as: Facebook face recognition, Motion Sensing in Video Games, VR headsets, Text to speech and vice versa, Space Technology, Recommendations on Amazon, etc.",satsin06,[],https://github.com/satsin06/EPL-Analysis,https://api.github.com/users/satsin06,https://api.github.com/repos/satsin06/EPL-Analysis,New Delhi
NLP-TwitterDataAnalysis,"In this project, Twitter Data has been analysed and sentiment analysis is done over each tweet. Apart from it, using LDA, topic modelling has been done and topic row has been attached to the final data output. The output data is supported by visualizations done using seaborn and matplotlib. Apart from these, Parts of Speech and Named Entity Recognition has been applied over the data.",sr3srijan,[],https://github.com/sr3srijan/NLP-TwitterDataAnalysis,https://api.github.com/users/sr3srijan,https://api.github.com/repos/sr3srijan/NLP-TwitterDataAnalysis,Bangalore
#NAME?,"-->PCA-for dimensionality reduction. -->LBP- it's efficient in the illumination, rotation, and grayscale variance -->WHT- Walsh-Hadamard Transform(WHT) for orthogonal transformation is used for feature extraction. Before applying LBP here I applied the first Walsh-Hadamard Transform (WHT) for orthogonal transformation. -->link of the paper for whole process flow: https://www.researchgate.net/profile/Priyanka_Patel8/publication/315892151_Investigate_Age_Invariant_Face_Recognition_Using_PCA_LBP_Walsh_Hadamard_Transform_with_Neural_Network/links/58ec89e40f7e9b6b274bb17c/Investigate-Age-Invariant-Face-Recognition-Using-PCA-LBP-Walsh-Hadamard-Transform-with-Neural-Network.pdf  To learn more about the background of the dataset, and the AIFR  you must visit the : https://scholar.google.com/scholar?cluster=3626589220394005192&hl=en&as_sdt=2005 You must cite this paper if you use: Patel, P., and A. Ganatra. ""Investigate age invariant face recognition using PCA, LBP, Walsh Hadamard transform with a neural network."" International Conference on Signal and Speech Processing (ICSSP-14). 2014.",Priyanka154,[],https://github.com/Priyanka154/-Age-Invariant-Face-Recognition,https://api.github.com/users/Priyanka154,https://api.github.com/repos/Priyanka154/-Age-Invariant-Face-Recognition,"ANAND,GUJARAT,INDIA"
Bangla-Sign-Language-Recognition-Using-Leap-Motion-Sensor,"Sign language is used by hearing and speech impaired people to transmit their messages to other people but it is difficult for a regular people to understand this gesture based language. Instantaneous responses on sign language can significantly enhance the understanding of sign language. In this paper, we propose a system that detects Bangla Sign Language using a digital motion sensor called Leap Motion Controller. It is a sensor or device which can detect 3D motion of hands, fingers and finger like objects without any contact. A Sign Language Recognition system has to be designed to recognize a hand gesture. In sign language system, gestures are defined as some specific patterns or movement of the hands to give an expression. There has to be a library which includes all the datasets to match with the user given gestures. We have to compare the sequences of data we get from Leap Motion and our datasets to get an optimal result which is basically the output. It will then show the output as text in the display. For our system, we choose to use $P Point-Cloud Recognizer algorithm to match the input data with our datasets. This recognition algorithm was designed for rapid prototyping of gesture-based UI and can deliver an average over 99% accuracy in user-dependent testing. Our proposed model is designed in a way so that the hearing and speech impaired people can communicate easily and efficiently with common people.",Nawal095,[],https://github.com/Nawal095/Bangla-Sign-Language-Recognition-Using-Leap-Motion-Sensor,https://api.github.com/users/Nawal095,https://api.github.com/repos/Nawal095/Bangla-Sign-Language-Recognition-Using-Leap-Motion-Sensor,"Dhaka, Bangladesh"
Chatbot-Alexa-and-NLTK,"This repository is about creating a skill called Pet Match that matches the user with a pet.  When launched, this Alexa Skill will prompt the user for the information it needs to determine a match.  Once all of the required information is collected, it will send the data to an external  web service which processes the data and returns the match.we will learn how to use advanced Alexa Skills Kit features to  create and configure an Alexa Skill and AWS Lambda.  The features you'll learn to use are Dialog Management and Entity Resolution.  These features leverage Alexa's Automatic Speech Recognition (ASR),  Natural Language Understanding (NLU), and Machine Learning (ML),  which makes your life easier because you don't have to write code.  You only need to provide training data to the Alexa engines via your interaction model.  The skill builder makes it easy to do so.",psbhargava,[],https://github.com/psbhargava/Chatbot-Alexa-and-NLTK,https://api.github.com/users/psbhargava,https://api.github.com/repos/psbhargava/Chatbot-Alexa-and-NLTK,Hyderabad
FPGA-based-Image-Recognition,"In this Project, our main aim is to accelerate the image recognition of CNN (Convolution Neural Network) with the help of a platform deployable on FPGA. CNN focuses on image classification, speech recognition, and video analysis. CNN is accelerated by using GPU (Graphical Processing Unit), which is relatively slow and consumes a high amount of power as CNN requires 20 GFLOPS/image. Also, the CPU acceleration being cheaper as it is readily available on most x86 machines is proportional to power. The modern Application-Specific Chips(ASICS) and the capability of a Field Programmable Gate Array( FPGA ) have power efficiency and faster computation rate over the GPU. With FPGA as a reconfigurable base and parallel architecture, we decided to target the CNN acceleration with an FPGA using Pipe CNN- an algorithm that gets synthesized via HLS (Hardware Level Synthesis Tools) like Intel's Quartus, and Open CL toolkit. Modern Large scale FPGA's like Stratix 10 and Arria 10 have shown a 10 percent less power consumption than GPU's, and it has an added advantage of pipeline parallel architecture and dedicated DSP for faster and efficient computations. The main goal of the Project is to design an OpenCL accelerator that is generic and yet powerful means of improving throughput in inference computations",HemantaIngle,[],https://github.com/HemantaIngle/FPGA-based-Image-Recognition,https://api.github.com/users/HemantaIngle,https://api.github.com/repos/HemantaIngle/FPGA-based-Image-Recognition,"San Jose, California, USA"
A-Simple-Method-of-Solution-For-Multi-label-Feature-Selection,"Multi-label learning has been a topic of research interest in multimedia, text & speech recognitions, music, image processing, information retrieval etc. In Multi-label classification (MLC) each instance is associated with a set of multiple class labels. Like other machine learning algorithms, data preprocessing plays an key role in MLC. Feature selection is an important preprocessing step in MLC, due to high dimensionality of datasets and associated computational costs. Extracting the most informative features considerably reduces the computational loads of MLC. Most of the Multi-label feature selection algorithms available in literature involve conversions to multiple single labeled feature selection problems. We proposed an efficient modification of a recent multi-label feature selection algorithm [1] available in literature. Our algorithm consists of two steps: in the first step we decompose the output label space into lower dimensions using simple matrix factorization method; subsequently we employ feature selection process in the decoupled reduced space. Our simulations with real world datasets reveal the efficiency of proposed framework.",prasadovhal,[],https://github.com/prasadovhal/A-Simple-Method-of-Solution-For-Multi-label-Feature-Selection,https://api.github.com/users/prasadovhal,https://api.github.com/repos/prasadovhal/A-Simple-Method-of-Solution-For-Multi-label-Feature-Selection,Pune
GolashBoy-Virtual-Assistant,"It is my python-based private desktop assistant project named- “MALGO” which helps me to send Email, Play Music, Open Google, YouTube, LinkedIn, GitHub, Tell me about the current time, etc. It can search for anything from Wikipedia through voice commands. It can greet me according to time if time is in between 12 noon to 6 p.m. then it says Good Afternoon Sir Have Your Lunch or not, in Microsoft Agent voice [API used-sapi5]. It can also send WhatsApp messages through voice command to any phone number which you enter in the code. I am also using energy and pause threshold concepts to minimize the surrounding noise so that it can easily recognize our voice within that range. Have you ever wondered how cool it would be to have your own A.I. assistant? Imagine how easier it would be to send emails without typing a single word, doing Wikipedia searches without opening web browsers, and performing many other daily tasks like playing music with the help of a single voice command. I can take a screenshot of my screen through voice command and save it to my local storage as well. I can also use as many modules using pip install command in the future. Using Libraries: - pyttsx3, Speech-recognition, Date Time, Wikipedia, smtplib, Pywhatkit (For WhatsApp Messaging Automation), web browser, datetime, etc. So, it is very much helpful in the tasks which we all are doing or performing on a regular basis.",golashboy,"['assistant', 'pause-threshold-concepts', 'sapi5', 'voice-command', 'whatsapp-messages', 'wikipedia']",https://github.com/golashboy/GolashBoy-Virtual-Assistant,https://api.github.com/users/golashboy,https://api.github.com/repos/golashboy/GolashBoy-Virtual-Assistant,Chandigarh
LibreASR,":speech_balloon: An On-Premises, Streaming Speech Recognition System ",iceychris,"['asr', 'deep-learning', 'esp32-lyrat', 'fastai', 'python', 'pytorch', 'rnn-transducer', 'speech-recognition']",https://github.com/iceychris/LibreASR,https://api.github.com/users/iceychris,https://api.github.com/repos/iceychris/LibreASR,"Augsburg, Germany"
wenet,Production First and Production Ready End-to-End Speech Recognition Toolkit,wenet-e2e,"['asr', 'automatic-speech-recognition', 'conformer', 'e2e-models', 'production-ready', 'pytorch', 'speech-recognition', 'transformer']",https://github.com/wenet-e2e/wenet,https://api.github.com/users/wenet-e2e,https://api.github.com/repos/wenet-e2e/wenet,"Beijing & Xian, China"
speech-recognition-papers,Towards hot directions in industrial end to end speech recognition,wenet-e2e,[],https://github.com/wenet-e2e/speech-recognition-papers,https://api.github.com/users/wenet-e2e,https://api.github.com/repos/wenet-e2e/speech-recognition-papers,"Beijing & Xian, China"
SpeechRecgnition,Audio Signal Processing & Speech Recognition,hccho2,[],https://github.com/hccho2/SpeechRecgnition,https://api.github.com/users/hccho2,https://api.github.com/repos/hccho2/SpeechRecgnition,"Seoul, Korea"
QuantumSpeech-QCNN,IEEE ICASSP 21 - Quantum Convolution Neural Networks for Speech Processing and Automatic Speech Recognition ,huckiyang,"['colab-notebook', 'ctc-model', 'pennylane', 'quantum-machine-learning', 'speech-processing', 'speech-recognition', 'tensorflow2']",https://github.com/huckiyang/QuantumSpeech-QCNN,https://api.github.com/users/huckiyang,https://api.github.com/repos/huckiyang/QuantumSpeech-QCNN,Earth
speech-recognition-in-javascript,Final Code for Speech Recognition in JavaScript tutorial.,zolomohan,"['javascript', 'speech-recognition', 'webspeech-api']",https://github.com/zolomohan/speech-recognition-in-javascript,https://api.github.com/users/zolomohan,https://api.github.com/repos/zolomohan/speech-recognition-in-javascript,"Chennai,  Tamil Nadu, India"
LocalSTT,Android Speech Recognition Service using Vosk/Kaldi and Mozilla DeepSpeech,ccoreilly,"['android', 'deepspeech', 'speech-recognition', 'vosk']",https://github.com/ccoreilly/LocalSTT,https://api.github.com/users/ccoreilly,https://api.github.com/repos/ccoreilly/LocalSTT,Berlin
Python-Speech-Recognition-,This consist of basic examples of performing Speech Recognition in Python using Google Speech Recognition Engine ,Kalebu,"['artificial-intelligence', 'machine-learning', 'natural-language-processing', 'python', 'python-nlp', 'python-project', 'python-project-beginner', 'python-speech', 'python-speech-to-text', 'python-speechrecognition']",https://github.com/Kalebu/Python-Speech-Recognition-,https://api.github.com/users/Kalebu,https://api.github.com/repos/Kalebu/Python-Speech-Recognition-,"Dar es Salaam , Tanzania"
narration.studio,Automatic in-browser audiobook editing using speech recognition,stevenwaterman,[],https://github.com/stevenwaterman/narration.studio,https://api.github.com/users/stevenwaterman,https://api.github.com/repos/stevenwaterman/narration.studio,"Durham, UK"
End-to-End-Speech-Recognition-Models,PyTorch implementation of automatic speech recognition models. ,sooftware,"['acoustic-model', 'asr', 'deepspeech2', 'e2e', 'end-to-end', 'las', 'listen-attend-and-spell', 'pytorch', 'transformer', 'vad', 'voice-activity-detection']",https://github.com/sooftware/End-to-End-Speech-Recognition-Models,https://api.github.com/users/sooftware,https://api.github.com/repos/sooftware/End-to-End-Speech-Recognition-Models,"Yong-in, Republic of Korea"
speech-recognition-papers,Awesome Automatic Speech Recognition (ASR) paper collection,sooftware,[],https://github.com/sooftware/speech-recognition-papers,https://api.github.com/users/sooftware,https://api.github.com/repos/sooftware/speech-recognition-papers,"Yong-in, Republic of Korea"
Updated_Virtual_Assistant,I have made a virtual assistant with Python using Google Speech Recognition API and many different modules.,srivastava10,[],https://github.com/srivastava10/Updated_Virtual_Assistant,https://api.github.com/users/srivastava10,https://api.github.com/repos/srivastava10/Updated_Virtual_Assistant,India
asr-rescoring,Rescoring methods for end-to-end Automatic Speech Recognition,diego-fustes,[],https://github.com/diego-fustes/asr-rescoring,https://api.github.com/users/diego-fustes,https://api.github.com/repos/diego-fustes/asr-rescoring,Spain
RobinASR,Romanian Automatic Speech Recognition from the ROBIN project,racai-ai,"['asr', 'automatic-speech-recognition', 'deepspeech', 'kenlm', 'pytorch', 'romanian', 'text-to-speech']",https://github.com/racai-ai/RobinASR,https://api.github.com/users/racai-ai,https://api.github.com/repos/racai-ai/RobinASR,"Bucharest, Romania"
AI-Grand-Challenge-2020,AI grand challenge 2020 Repo (Speech Recognition Track),NeuroAI-PI,[],https://github.com/NeuroAI-PI/AI-Grand-Challenge-2020,https://api.github.com/users/NeuroAI-PI,https://api.github.com/repos/NeuroAI-PI/AI-Grand-Challenge-2020,"Seoul, Republic of Korea"
PhoNLP,"PhoNLP: A BERT-based multi-task learning model for part-of-speech tagging, named entity recognition and dependency parsing (NAACL 2021)",VinAIResearch,"['dependency-parsing', 'language-model', 'multi-task-learning', 'named-entity-recognition', 'ner', 'pos-tagging', 'vietnamese-nlp']",https://github.com/VinAIResearch/PhoNLP,https://api.github.com/users/VinAIResearch,https://api.github.com/repos/VinAIResearch/PhoNLP,"Hanoi, Vietnam"
Speech-Recognition-A-Z-with-Hands-on,"Speech Recognition A-Z with Hands-on [Video], published by Packt",PacktPublishing,[],https://github.com/PacktPublishing/Speech-Recognition-A-Z-with-Hands-on,https://api.github.com/users/PacktPublishing,https://api.github.com/repos/PacktPublishing/Speech-Recognition-A-Z-with-Hands-on,"Birmingham, UK"
quizdom,🧠 A Quiz Management App for both teachers and students with speech recognition for blind students too.,justEhmadSaeed,"['firebase-auth', 'hacktoberfest', 'mern', 'mern-project', 'mern-stack', 'quiz-generator']",https://github.com/justEhmadSaeed/quizdom,https://api.github.com/users/justEhmadSaeed,https://api.github.com/repos/justEhmadSaeed/quizdom,"Lahore, Pakistan"
Speech-Recognition,speech_recognition,aayushkumarmishra,[],https://github.com/aayushkumarmishra/Speech-Recognition,https://api.github.com/users/aayushkumarmishra,https://api.github.com/repos/aayushkumarmishra/Speech-Recognition,Varanasi
ContextNet,"Tensorflow2 based implementation of ContextNet, an improved convolutional rnn-transducer-based architecture for end-to-end speech recognition using global context",ishine,[],https://github.com/ishine/ContextNet,https://api.github.com/users/ishine,https://api.github.com/repos/ishine/ContextNet,shanghai
kaldi_vosk_win_cmake,cmake based kaldi + vosk + microphone speech recognition example,Smorodov,"['kaldi', 'speaker-recognition', 'speech-recognition', 'speech-to-text', 'voice-recognition', 'vosk']",https://github.com/Smorodov/kaldi_vosk_win_cmake,https://api.github.com/users/Smorodov,https://api.github.com/repos/Smorodov/kaldi_vosk_win_cmake,Russian Federation
speech-transformer,Transformer framework speciaized in speech recognition tasks using Pytorch.  ,sooftware,"['asr', 'attention-is-all-you-need', 'end-to-end', 'pytorch', 'speech', 'transformer']",https://github.com/sooftware/speech-transformer,https://api.github.com/users/sooftware,https://api.github.com/repos/sooftware/speech-transformer,"Yong-in, Republic of Korea"
uyghur-asr-ctc,Speech Recognition for Uyghur using deep learning,gheyret,"['asr', 'automatic-speech-recognition', 'ctc', 'pytorch', 'uyghur']",https://github.com/gheyret/uyghur-asr-ctc,https://api.github.com/users/gheyret,https://api.github.com/repos/gheyret/uyghur-asr-ctc,Japan
online-hate-speech-recog,An online hate speech recognition system.,neerajvashistha,[],https://github.com/neerajvashistha/online-hate-speech-recog,https://api.github.com/users/neerajvashistha,https://api.github.com/repos/neerajvashistha/online-hate-speech-recog,"London, UK"
samromur-asr,Automatic Speech Recognition (ASR) system for the Samrómur speech corpus using Kaldi,cadia-lvl,"['automatic-speech-recognition', 'kaldi-asr', 'samromur']",https://github.com/cadia-lvl/samromur-asr,https://api.github.com/users/cadia-lvl,https://api.github.com/repos/cadia-lvl/samromur-asr,"Reykjavik, Iceland"
offline_speech_recognition,A WIP Flutter Plugin designed for continuous speech recognition with Vosk. Currently only for Android.,ethan-ou,[],https://github.com/ethan-ou/offline_speech_recognition,https://api.github.com/users/ethan-ou,https://api.github.com/repos/ethan-ou/offline_speech_recognition,"Sydney, Australia"
End-to-end-ASR-Pytorch-DLHLP,Joint CTC-Attention End-to-end Speech Recognition - PyTorch Implementation (Deep Learning for Human Language Processing Special Project),vectominist,"['asr', 'pytorch', 'speech-recognition']",https://github.com/vectominist/End-to-end-ASR-Pytorch-DLHLP,https://api.github.com/users/vectominist,https://api.github.com/repos/vectominist/End-to-end-ASR-Pytorch-DLHLP,"Taipei, Taiwan"
Pyautogui-module-using-audio,"📌 This repo is all about how we implemented pyttsx3,speech_recognition,colored all three modules with pyautogui module.",Kushal997-das,"['colored', 'git', 'github', 'project', 'pyautogui', 'python3', 'pyttsx3', 'speechrecognition']",https://github.com/Kushal997-das/Pyautogui-module-using-audio,https://api.github.com/users/Kushal997-das,https://api.github.com/repos/Kushal997-das/Pyautogui-module-using-audio,India
K66F,Mbed demo for speech recognition,spartacoos,[],https://github.com/spartacoos/K66F,https://api.github.com/users/spartacoos,https://api.github.com/repos/spartacoos/K66F,"Sheffield, UK"
ASR-Adaption-Class-Similarity,"Code for the INTERSPEECH 2020 paper ""Domain Adaptation Using Class Similarity for Robust Speech Recognition""",zhu-han,[],https://github.com/zhu-han/ASR-Adaption-Class-Similarity,https://api.github.com/users/zhu-han,https://api.github.com/repos/zhu-han/ASR-Adaption-Class-Similarity,Beijing
Eliza,Speech recognition chatbot,Aryandotgit,[],https://github.com/Aryandotgit/Eliza,https://api.github.com/users/Aryandotgit,https://api.github.com/repos/Aryandotgit/Eliza,Kolkata
speech_spike_signatures,Spiking neural networks (SNNs) for speech recognition,NeelayS,"['computational-neuroscience', 'spiking-neural-networks']",https://github.com/NeelayS/speech_spike_signatures,https://api.github.com/users/NeelayS,https://api.github.com/repos/NeelayS/speech_spike_signatures,India
quartznet,QuartzNet implementation for Automatic Speech Recognition task,isadrtdinov,"['asr-model', 'deep-learning', 'ljspeech', 'pytorch']",https://github.com/isadrtdinov/quartznet,https://api.github.com/users/isadrtdinov,https://api.github.com/repos/isadrtdinov/quartznet,"Moscow, Russia"
wavenet-stt,An end-to-end speech recognition system with Wavenet. Built using C++ and python.,Narasimha1997,"['cplusplus-11', 'pybind', 'python', 'python3', 'speech-recognition', 'tensorflow', 'tensorflow2', 'tensorflowlite', 'wavenet']",https://github.com/Narasimha1997/wavenet-stt,https://api.github.com/users/Narasimha1997,https://api.github.com/repos/Narasimha1997/wavenet-stt,Earth
Speech-NART,An open-source non-autoregressive transformer toolkit for speech recognition.,ZhengkunTian,[],https://github.com/ZhengkunTian/Speech-NART,https://api.github.com/users/ZhengkunTian,https://api.github.com/repos/ZhengkunTian/Speech-NART,"beijing, China"
figma-speech-recognition,Let you insert a text from your voice to your design using speech recognition,sonnylazuardi,"['design', 'figma', 'recognition', 'speech']",https://github.com/sonnylazuardi/figma-speech-recognition,https://api.github.com/users/sonnylazuardi,https://api.github.com/repos/sonnylazuardi/figma-speech-recognition,Singapore
Speech-Recognition-Project,Speech recognition project using maps in Android,AdityaPrakash-26,[],https://github.com/AdityaPrakash-26/Speech-Recognition-Project,https://api.github.com/users/AdityaPrakash-26,https://api.github.com/repos/AdityaPrakash-26/Speech-Recognition-Project,Indore
speech-recognition,Web Speech API & speech recognition demo. Simple voice-notepad.,michalkortas,[],https://github.com/michalkortas/speech-recognition,https://api.github.com/users/michalkortas,https://api.github.com/repos/michalkortas/speech-recognition,"Plazowo, Poland"
speechrecognition,speech recognition using python,fakemoses,[],https://github.com/fakemoses/speechrecognition,https://api.github.com/users/fakemoses,https://api.github.com/repos/fakemoses/speechrecognition,Germany
Voice-Translation-Shakespeare-App,Translation using Speech Recognition.,PrakharV10,[],https://github.com/PrakharV10/Voice-Translation-Shakespeare-App,https://api.github.com/users/PrakharV10,https://api.github.com/repos/PrakharV10/Voice-Translation-Shakespeare-App,India
catalan-speech-recognition-benchmark,A benchmark of speech recognition solutions for the Catalan language,ccoreilly,"['asr', 'asr-model', 'catala', 'catalan', 'catalan-language', 'deepspeech', 'speech-recognition', 'speech-to-text', 'vosk']",https://github.com/ccoreilly/catalan-speech-recognition-benchmark,https://api.github.com/users/ccoreilly,https://api.github.com/repos/ccoreilly/catalan-speech-recognition-benchmark,Berlin
Speech-Recognition,Speech Recognition program written in python,arunism,[],https://github.com/arunism/Speech-Recognition,https://api.github.com/users/arunism,https://api.github.com/repos/arunism/Speech-Recognition,"Kathmandu, Nepal"
nepali_asr,Nepali Automatic Speech Recognition using pytorch,sammelanyogi,[],https://github.com/sammelanyogi/nepali_asr,https://api.github.com/users/sammelanyogi,https://api.github.com/repos/sammelanyogi/nepali_asr,Nepal
qoul,An experimental Automatic Speech Recognition system for Urdu built using the kaldi toolkit.,parkerqueen,[],https://github.com/parkerqueen/qoul,https://api.github.com/users/parkerqueen,https://api.github.com/repos/parkerqueen/qoul,"Islamabad, Pakistan"
OpenTransducer,An open-source transducer-based model toolkit for speech recognition.,ZhengkunTian,[],https://github.com/ZhengkunTian/OpenTransducer,https://api.github.com/users/ZhengkunTian,https://api.github.com/repos/ZhengkunTian/OpenTransducer,"beijing, China"
obs-transcript,Real-time subtitle generation by speech recognition for OBS Studio,akabe,"['captions', 'obs', 'obs-studio', 'speech-recognition', 'speech-to-text', 'subtitles', 'transcription']",https://github.com/akabe/obs-transcript,https://api.github.com/users/akabe,https://api.github.com/repos/akabe/obs-transcript,Japan
e2e-asr-and-disfluency-removal-evaluator,A new metric for evaluating end-to-end speech recognition and disfluency removal systems,pariajm,"['asr-evaluation', 'asr-with-disfluencies', 'disfluent-transcripts', 'e2e-asr-metric', 'e2e-metric', 'end2end-disfluency-metric', 'end2end-metric', 'end2end-speech-translation', 'evaluating-e2e-models', 'fluency-measure', 'joint-asr-and-disfluency-detection', 'levenshtein-distance', 'minimum-edit-distance', 'speech-machine-translation-metric', 'speech-translation-evaluator', 'spontaneous-speech-recognition']",https://github.com/pariajm/e2e-asr-and-disfluency-removal-evaluator,https://api.github.com/users/pariajm,https://api.github.com/repos/pariajm/e2e-asr-and-disfluency-removal-evaluator,"Sydney, Australia"
dhwoni-preprocessing,Pre-processing for Dhwoni - a nepali speech recognition system.,sammelanyogi,[],https://github.com/sammelanyogi/dhwoni-preprocessing,https://api.github.com/users/sammelanyogi,https://api.github.com/repos/sammelanyogi/dhwoni-preprocessing,Nepal
Speech-recognition-for-Japanese,"Speech recognition using Google Cloud Speech, specified for Japanese audio",tomoima525,[],https://github.com/tomoima525/Speech-recognition-for-Japanese,https://api.github.com/users/tomoima525,https://api.github.com/repos/tomoima525/Speech-recognition-for-Japanese,San francisco
remote-controller-with-speech-recognition,IR Remote Controller with Speech Recognition,kerikun11,[],https://github.com/kerikun11/remote-controller-with-speech-recognition,https://api.github.com/users/kerikun11,https://api.github.com/repos/kerikun11/remote-controller-with-speech-recognition,Japan
Speech-Recognition-Google-,Speech Recognition using Google Speech Recognition,ayushvrma,[],https://github.com/ayushvrma/Speech-Recognition-Google-,https://api.github.com/users/ayushvrma,https://api.github.com/repos/ayushvrma/Speech-Recognition-Google-,"Lucknow, India"
speech-recognition-quartznet,Speech recognition for English using Pytorch,tabisheva,['quartznet'],https://github.com/tabisheva/speech-recognition-quartznet,https://api.github.com/users/tabisheva,https://api.github.com/repos/tabisheva/speech-recognition-quartznet,Moscow
deep-face-vsr,"Visual speech recognition with face inputs: code and models for F&G 2020 paper ""Can We Read Speech Beyond the Lips? Rethinking RoI Selection for Deep Visual Speech Recognition""",sailordiary,"['computer-vision', 'lip-reading', 'pytorch', 'speech-reading', 'visual-speech-recognition']",https://github.com/sailordiary/deep-face-vsr,https://api.github.com/users/sailordiary,https://api.github.com/repos/sailordiary/deep-face-vsr,"Beijing, China"
HOW-TO-EXTRACT-TEXT-FROM-SPEECH-speech-recognition-using-python,HOW TO EXTRACT TEXT FROM SPEECH (speech to text ) || speech recognition using python,kagaya25,[],https://github.com/kagaya25/HOW-TO-EXTRACT-TEXT-FROM-SPEECH-speech-recognition-using-python,https://api.github.com/users/kagaya25,https://api.github.com/repos/kagaya25/HOW-TO-EXTRACT-TEXT-FROM-SPEECH-speech-recognition-using-python,japan
ojsp_adaptation_review_2020,Auxiliary data and scripts for our OJSP review on speaker adaptation for speech recognition,pswietojanski,[],https://github.com/pswietojanski/ojsp_adaptation_review_2020,https://api.github.com/users/pswietojanski,https://api.github.com/repos/pswietojanski/ojsp_adaptation_review_2020,"Sydney, Aystralia"
Speech-Recognition,Speech Recognition,Ashitha97,[],https://github.com/Ashitha97/Speech-Recognition,https://api.github.com/users/Ashitha97,https://api.github.com/repos/Ashitha97/Speech-Recognition,Bangalore
ProjectRaven,Speech recognition ,hariprakashs,[],https://github.com/hariprakashs/ProjectRaven,https://api.github.com/users/hariprakashs,https://api.github.com/repos/hariprakashs/ProjectRaven,Chennai
speech-recognition,Speech recognition,kinga1996,[],https://github.com/kinga1996/speech-recognition,https://api.github.com/users/kinga1996,https://api.github.com/repos/kinga1996/speech-recognition,"Warsaw, Poland"
Speech-Recognition,Speech Recognition,roopeshn28,[],https://github.com/roopeshn28/Speech-Recognition,https://api.github.com/users/roopeshn28,https://api.github.com/repos/roopeshn28/Speech-Recognition,Bangalore
Speech_To_Text,ASR (Automatic Speech Recognition System ) based on Short - Time Energy Processing and Zero Crossing Rate,gazdimi,"['asr', 'matlab']",https://github.com/gazdimi/Speech_To_Text,https://api.github.com/users/gazdimi,https://api.github.com/repos/gazdimi/Speech_To_Text,Greece
QuartzNet-ASR-pytorch,Automatic Speech Recognition (ASR) model QuartzNet trained on English CommonVoice. In PyTroch with CTC loss and beam search.,Kirili4ik,"['asr', 'asr-model', 'beam-search', 'ctc-loss', 'pytorch', 'pytorch-implementation', 'quartznet', 'quartznet-pytorch']",https://github.com/Kirili4ik/QuartzNet-ASR-pytorch,https://api.github.com/users/Kirili4ik,https://api.github.com/repos/Kirili4ik/QuartzNet-ASR-pytorch,"Moscow, Russia"
iago,[MODULE - PY] Iago is a python speaking assistant - Speech Recognition + Text to Speech made easy,lollococce,[],https://github.com/lollococce/iago,https://api.github.com/users/lollococce,https://api.github.com/repos/lollococce/iago,New York
react_ok_jason,Speech recognition and Text to speech app,jasonkim7288,[],https://github.com/jasonkim7288/react_ok_jason,https://api.github.com/users/jasonkim7288,https://api.github.com/repos/jasonkim7288/react_ok_jason,Brisbane
type-listen,Web Speech API and Speech Recognition API,berkayalatas,[],https://github.com/berkayalatas/type-listen,https://api.github.com/users/berkayalatas,https://api.github.com/repos/berkayalatas/type-listen,Turkey
End_2_End_Automatic_Speech_Recognition_For_Gujarati,"[ICON 2020] TensorFlow Code for ""End-to-End Automatic Speech Recognition System for Gujarati""",01-vyom,"['asr', 'bilstm', 'cnn-1d', 'ctc-loss', 'greedy-decoding', 'gujarati-language', 'language-model', 'prefix-decoding', 'spell-corrector-bert', 'system-analysis', 'wikipedia']",https://github.com/01-vyom/End_2_End_Automatic_Speech_Recognition_For_Gujarati,https://api.github.com/users/01-vyom,https://api.github.com/repos/01-vyom/End_2_End_Automatic_Speech_Recognition_For_Gujarati,"Pleasanton, California, USA"
SpeechRecog_Azure,Speech recognition build with Azure speech services,RayuduAdabala,[],https://github.com/RayuduAdabala/SpeechRecog_Azure,https://api.github.com/users/RayuduAdabala,https://api.github.com/repos/RayuduAdabala/SpeechRecog_Azure,Hyderabad
speechrecog,speech Recognition using ibm speech to text,prathyusak,[],https://github.com/prathyusak/speechrecog,https://api.github.com/users/prathyusak,https://api.github.com/repos/prathyusak/speechrecog,"Phoenix, Arizona"
pyassistant,speech recognition using python,igrishi,[],https://github.com/igrishi/pyassistant,https://api.github.com/users/igrishi,https://api.github.com/repos/igrishi/pyassistant,Patna Bihar
sprech,Speech Recognition Chrome App,caviri,[],https://github.com/caviri/sprech,https://api.github.com/users/caviri,https://api.github.com/repos/caviri/sprech,Lausanne
Hackoberfest-2020,HacktoberFest  Speech Recognition System,SuyogKumawat,[],https://github.com/SuyogKumawat/Hackoberfest-2020,https://api.github.com/users/SuyogKumawat,https://api.github.com/repos/SuyogKumawat/Hackoberfest-2020,India
jarvis,jarvis/speech recognition,akash-123-svg,"['hacktoberfest', 'hacktoberfest-accepted', 'hacktoberfest2020']",https://github.com/akash-123-svg/jarvis,https://api.github.com/users/akash-123-svg,https://api.github.com/repos/akash-123-svg/jarvis,"Ara,bihar"
python-vosk-trial,Vosk Speech Recognition Trial,smivv,"['speech', 'speech-processing', 'speech-recognition', 'speech-to-text', 'vosk', 'websockets']",https://github.com/smivv/python-vosk-trial,https://api.github.com/users/smivv,https://api.github.com/repos/smivv/python-vosk-trial,Saint Petersburg
HAZEL,speech recognition using Python,somya51p,[],https://github.com/somya51p/HAZEL,https://api.github.com/users/somya51p,https://api.github.com/repos/somya51p/HAZEL,"Kanpur,UP"
alphabet_recognizer,Speech Recognition using Tensorflow,ihpolash,[],https://github.com/ihpolash/alphabet_recognizer,https://api.github.com/users/ihpolash,https://api.github.com/repos/ihpolash/alphabet_recognizer,"Dhaka, Bangladesh"
Speech-to-Text,Speech Recognition in Python,Gokuljokul,[],https://github.com/Gokuljokul/Speech-to-Text,https://api.github.com/users/Gokuljokul,https://api.github.com/repos/Gokuljokul/Speech-to-Text,"Chennai, India"
Voice-to-voice,Voice recognition to Speech,wncjs96,[],https://github.com/wncjs96/Voice-to-voice,https://api.github.com/users/wncjs96,https://api.github.com/repos/wncjs96/Voice-to-voice,SC
E25_speech_recognition,E25_speech_recognition,YesicaKim,[],https://github.com/YesicaKim/E25_speech_recognition,https://api.github.com/users/YesicaKim,https://api.github.com/repos/YesicaKim/E25_speech_recognition,Seoul
speechRecognition,Browser speech recognition,Vuurvos1,[],https://github.com/Vuurvos1/speechRecognition,https://api.github.com/users/Vuurvos1,https://api.github.com/repos/Vuurvos1/speechRecognition,The Netherlands
speech-recognition,speech recognition in python,ali-moments,[],https://github.com/ali-moments/speech-recognition,https://api.github.com/users/ali-moments,https://api.github.com/repos/ali-moments/speech-recognition,somewhere middle of venus and mars
speech-essence,Offline speech recognition app.,aectaan,"['rust', 'speech-recognition', 'speech-to-text', 'stt']",https://github.com/aectaan/speech-essence,https://api.github.com/users/aectaan,https://api.github.com/repos/aectaan/speech-essence,"Saint-Petersburg, Russia"
Python-mini-project,Speech recognition phonebook,data-charya,[],https://github.com/data-charya/Python-mini-project,https://api.github.com/users/data-charya,https://api.github.com/repos/data-charya/Python-mini-project,mangalore
Speechrecognition,Speech recognition script python,divyanshbhojane,[],https://github.com/divyanshbhojane/Speechrecognition,https://api.github.com/users/divyanshbhojane,https://api.github.com/repos/divyanshbhojane/Speechrecognition,"Indore , Madhya Pradesh ,India"
simple-speech-recognition-sample,Simple speech recognition sample,shinshin86,[],https://github.com/shinshin86/simple-speech-recognition-sample,https://api.github.com/users/shinshin86,https://api.github.com/repos/shinshin86/simple-speech-recognition-sample,Japan
js30-day-20,native speech recognition,ericerodgers,[],https://github.com/ericerodgers/js30-day-20,https://api.github.com/users/ericerodgers,https://api.github.com/repos/ericerodgers/js30-day-20,"Brooklyn, NY"
Speech_Recognition18,Speech Recognition App,anand-1809,[],https://github.com/anand-1809/Speech_Recognition18,https://api.github.com/users/anand-1809,https://api.github.com/repos/anand-1809/Speech_Recognition18,Bokaro Steel City
university-project,Speech recognition program,PiwkoO,[],https://github.com/PiwkoO/university-project,https://api.github.com/users/PiwkoO,https://api.github.com/repos/PiwkoO/university-project,Poland
speechrecognition-python3,Speech Recognition System,rachitch78,[],https://github.com/rachitch78/speechrecognition-python3,https://api.github.com/users/rachitch78,https://api.github.com/repos/rachitch78/speechrecognition-python3,Banglore
LSTM-Based-Speech-Recognition,LSTM Based Speech Recognition,Jamesedwar,[],https://github.com/Jamesedwar/LSTM-Based-Speech-Recognition,https://api.github.com/users/Jamesedwar,https://api.github.com/repos/Jamesedwar/LSTM-Based-Speech-Recognition,Trichy
tensorflow-speech-recognition,TensorFlow Speech Recognition Challenge,abidaks,[],https://github.com/abidaks/tensorflow-speech-recognition,https://api.github.com/users/abidaks,https://api.github.com/repos/abidaks/tensorflow-speech-recognition,Dubai
python_speech_recognition,python speech recognition,rajpatel2619,[],https://github.com/rajpatel2619/python_speech_recognition,https://api.github.com/users/rajpatel2619,https://api.github.com/repos/rajpatel2619/python_speech_recognition,Central University of Haryana
speech-recognition-demo,Speech recognition demo.,remarkablemark,"['python', 'python3', 'speech-recognition', 'speech-to-text', 'transcription']",https://github.com/remarkablemark/speech-recognition-demo,https://api.github.com/users/remarkablemark,https://api.github.com/repos/remarkablemark/speech-recognition-demo,New York
Speech-Recognition,Various Speech Recognition Projects,Jamesedwar,[],https://github.com/Jamesedwar/Speech-Recognition,https://api.github.com/users/Jamesedwar,https://api.github.com/repos/Jamesedwar/Speech-Recognition,Trichy
SpeechRecognition,JavaScript Speech Recognition ,Tausif282,[],https://github.com/Tausif282/SpeechRecognition,https://api.github.com/users/Tausif282,https://api.github.com/repos/Tausif282/SpeechRecognition,Bangalore
kshabbir-guessing-game,Speech Recognition guessing game,Kazim786,"['api', 'javascript']",https://github.com/Kazim786/kshabbir-guessing-game,https://api.github.com/users/Kazim786,https://api.github.com/repos/Kazim786/kshabbir-guessing-game,"Houston, Texas"
js-speech,Speech recognition for browser,alextanhongpin,[],https://github.com/alextanhongpin/js-speech,https://api.github.com/users/alextanhongpin,https://api.github.com/repos/alextanhongpin/js-speech,"Malaysia, Singapore, Berlin & Japan"
Speech_Emotion_Recognition,Speech Emotion Recognition,joycechettiar,[],https://github.com/joycechettiar/Speech_Emotion_Recognition,https://api.github.com/users/joycechettiar,https://api.github.com/repos/joycechettiar/Speech_Emotion_Recognition,"New Jersey, USA"
Virtual-Talking-Audiobook,Speech Recognition using Python,ramimhossain12,[],https://github.com/ramimhossain12/Virtual-Talking-Audiobook,https://api.github.com/users/ramimhossain12,https://api.github.com/repos/ramimhossain12/Virtual-Talking-Audiobook,"Dhaka,Bangladesh"
python-speech,Speech recognition guessing game,Nirmalya24,[],https://github.com/Nirmalya24/python-speech,https://api.github.com/users/Nirmalya24,https://api.github.com/repos/Nirmalya24/python-speech,Seattle
speech-server-client-qt,A qt client for the potaris speech recognition server/gateway.,FAUSheppy,[],https://github.com/FAUSheppy/speech-server-client-qt,https://api.github.com/users/FAUSheppy,https://api.github.com/repos/FAUSheppy/speech-server-client-qt,Erlangen
Voice-Assistant,Desktop speech assistant that uses speech recognition and Google Text-to-Speech to execute helpful commands and talk back to the user.,stefanostsolos,"['gtts', 'python', 'speech-assistant', 'speech-recognition', 'voice-assistant', 'voice-recognition']",https://github.com/stefanostsolos/Voice-Assistant,https://api.github.com/users/stefanostsolos,https://api.github.com/repos/stefanostsolos/Voice-Assistant,"Athens, Greece"
J.A.R.V.I.S.,"J.A.R.V.I.S. is a voice activated desktop assistant which is built in Python using libraries such as Google text-to speech, speech recognition etc.",harshita130602,[],https://github.com/harshita130602/J.A.R.V.I.S.,https://api.github.com/users/harshita130602,https://api.github.com/repos/harshita130602/J.A.R.V.I.S.,Hyderabad
speech-to-age-gender,Recognition of Age and Gender based on speech,Stsh4lson,[],https://github.com/Stsh4lson/speech-to-age-gender,https://api.github.com/users/Stsh4lson,https://api.github.com/repos/Stsh4lson/speech-to-age-gender,Poland
Speech-Recognition-,speech speech recognition using pyttsx3 module and speech recognition for Speech Translation using Google Translate API for Python,raniaarinta,[],https://github.com/raniaarinta/Speech-Recognition-,https://api.github.com/users/raniaarinta,https://api.github.com/repos/raniaarinta/Speech-Recognition-,indonesia
Spikey---A-mini-Virtual-Assistance,"This is my first project made using python and PHP, in which i  gave natural language processing and speech recognition with the help of PyAudio. You can download this code and implement some more functionalties to it for better performance.",SP2224,[],https://github.com/SP2224/Spikey---A-mini-Virtual-Assistance,https://api.github.com/users/SP2224,https://api.github.com/repos/SP2224/Spikey---A-mini-Virtual-Assistance,"Bhubaneswar, Odisha"
slgE2E,end to end speech recognition,slegroux,[],https://github.com/slegroux/slgE2E,https://api.github.com/users/slegroux,https://api.github.com/repos/slegroux/slgE2E,San Francisco
Speak-Colors,A Web Speech Recognition Project,philona123,[],https://github.com/philona123/Speak-Colors,https://api.github.com/users/philona123,https://api.github.com/repos/philona123/Speak-Colors,Kochi
speech_recognition,speech recognition using google API,brandynbrandz,[],https://github.com/brandynbrandz/speech_recognition,https://api.github.com/users/brandynbrandz,https://api.github.com/repos/brandynbrandz/speech_recognition,"Nairobi, Kenya"
Brownie,Post processing for speech recognition,mcw519,"['asr', 'kaldi', 'named-entities', 'post-processing', 'pynini', 'speech-recognition', 'wfst']",https://github.com/mcw519/Brownie,https://api.github.com/users/mcw519,https://api.github.com/repos/mcw519/Brownie,Taiwan
asr,provide Automatic Speech Recognition service,ShawnGoethe,[],https://github.com/ShawnGoethe/asr,https://api.github.com/users/ShawnGoethe,https://api.github.com/repos/ShawnGoethe/asr,Peking
speechJavascript,Speech recognition with native JS,iRetray,[],https://github.com/iRetray/speechJavascript,https://api.github.com/users/iRetray,https://api.github.com/repos/iRetray/speechJavascript,Bogotá
speechHMM,Simple speech recognition using HTK,tancos02,[],https://github.com/tancos02/speechHMM,https://api.github.com/users/tancos02,https://api.github.com/repos/tancos02/speechHMM,Bandung
Amharic-ASR-Dataset,speech recognition for Amharic language,IsraelAbebe,[],https://github.com/IsraelAbebe/Amharic-ASR-Dataset,https://api.github.com/users/IsraelAbebe,https://api.github.com/repos/IsraelAbebe/Amharic-ASR-Dataset,Ethiopia
yoruba-asr,Yoruba Automatic Speech Recognition (ASR),Alikerin,[],https://github.com/Alikerin/yoruba-asr,https://api.github.com/users/Alikerin,https://api.github.com/repos/Alikerin/yoruba-asr,"Zaria, Nigeria"
voicebot,Use deepspeech to recognition speech,khanh41,"['speech-recognition', 'speech-to-text']",https://github.com/khanh41/voicebot,https://api.github.com/users/khanh41,https://api.github.com/repos/khanh41/voicebot,Đà Nẵng
Speech-Recognition-API,Usage of Speech Recognition API,babul101,[],https://github.com/babul101/Speech-Recognition-API,https://api.github.com/users/babul101,https://api.github.com/repos/babul101/Speech-Recognition-API,Remote
speech-test,Testing WebAPI speech synthesis / recognition,BrenMurrell,[],https://github.com/BrenMurrell/speech-test,https://api.github.com/users/BrenMurrell,https://api.github.com/repos/BrenMurrell/speech-test,"Wellington, New Zealand"
Speech-Recognition_mod,My mod of Speech-Recognition,weimingtom,[],https://github.com/weimingtom/Speech-Recognition_mod,https://api.github.com/users/weimingtom,https://api.github.com/repos/weimingtom/Speech-Recognition_mod,"Guangdong, China"
Jarvis-1.0,"Self made Jarvis using Speech Recognition in python and NLP. Existing functionalities - Date, Time, Chatbot features and Wikipedia searching on speech command. Upcoming Functionalities are mailing on speech command, texting texts on Whatsapp and many more.",Shreyansh-Gupta,[],https://github.com/Shreyansh-Gupta/Jarvis-1.0,https://api.github.com/users/Shreyansh-Gupta,https://api.github.com/repos/Shreyansh-Gupta/Jarvis-1.0,"Maharashtra, India"
Speech-CommandRecognition,TensorFlow Lite Speech Command Recognition,silexcorp,[],https://github.com/silexcorp/Speech-CommandRecognition,https://api.github.com/users/silexcorp,https://api.github.com/repos/silexcorp/Speech-CommandRecognition,Guatemala
attentive-machines,My experiments with speech recognition,souserge,[],https://github.com/souserge/attentive-machines,https://api.github.com/users/souserge,https://api.github.com/repos/souserge/attentive-machines,3rd Stone from the Sun
DaVinci-Speech,E2E speech recognition from scratch.,pkufool,[],https://github.com/pkufool/DaVinci-Speech,https://api.github.com/users/pkufool,https://api.github.com/repos/pkufool/DaVinci-Speech,"Beijing, China"
speech-recognition,Automatic Speech Recognition in pytorch,SylvainVerdy,[],https://github.com/SylvainVerdy/speech-recognition,https://api.github.com/users/SylvainVerdy,https://api.github.com/repos/SylvainVerdy/speech-recognition,Avignon
speech-recognition,Simple speech recognition using Python,cotraak,[],https://github.com/cotraak/speech-recognition,https://api.github.com/users/cotraak,https://api.github.com/repos/cotraak/speech-recognition,"Cincinnati, OH"
audio-to-CSV,Speech Recognition for creating Datasets,Yashdew,[],https://github.com/Yashdew/audio-to-CSV,https://api.github.com/users/Yashdew,https://api.github.com/repos/Yashdew/audio-to-CSV,"Pune,Maharashtra,India"
ostis-speech-recognition-module,Speech recognition module for OSTIS,Flombik,[],https://github.com/Flombik/ostis-speech-recognition-module,https://api.github.com/users/Flombik,https://api.github.com/repos/Flombik/ostis-speech-recognition-module,"Minsk, Belarus"
NLP,"Natural language processing including Datasets,Farsi NLP, Automated Essay Scoring, Automatic Speech Recognition and etc.",ArmanBehnam,"['dataset', 'farsi', 'language-model', 'language-modeling', 'natural-language-generation', 'natural-language-inference', 'natural-language-processing', 'nlp', 'nlp-datasets', 'nlp-machine-learning', 'nlp-resources', 'persian', 'tutorial']",https://github.com/ArmanBehnam/NLP,https://api.github.com/users/ArmanBehnam,https://api.github.com/repos/ArmanBehnam/NLP,Tehran
Fuse.Speech,Speech Recognition and Text To Speech package for Fuse Open,ichan-mb,[],https://github.com/ichan-mb/Fuse.Speech,https://api.github.com/users/ichan-mb,https://api.github.com/repos/ichan-mb/Fuse.Speech,"Bandung, Indonesia"
speech_to_text,Automatic speech recognition (speech-to-text) in English,Stoops-ML,[],https://github.com/Stoops-ML/speech_to_text,https://api.github.com/users/Stoops-ML,https://api.github.com/repos/Stoops-ML/speech_to_text,Israel
Python_Virtual_assistant,Practice Python application using speech recognition and speech synthesis ,Bubblezdb,[],https://github.com/Bubblezdb/Python_Virtual_assistant,https://api.github.com/users/Bubblezdb,https://api.github.com/repos/Bubblezdb/Python_Virtual_assistant,"Havelock, NC"
ASR,Automatic speech recognition based on Deep Speech 2,Stoops-ML,[],https://github.com/Stoops-ML/ASR,https://api.github.com/users/Stoops-ML,https://api.github.com/repos/Stoops-ML/ASR,Israel
Speech-Recognition-App,Speech Recognition App Using JavaScript web speech API,AdrianGeorgeM,[],https://github.com/AdrianGeorgeM/Speech-Recognition-App,https://api.github.com/users/AdrianGeorgeM,https://api.github.com/repos/AdrianGeorgeM/Speech-Recognition-App,London Uk
SpeechAPI-Number-Guessing-Game,My Speech Number Guessing Game with Speech Recognition API,YusmenKadir,[],https://github.com/YusmenKadir/SpeechAPI-Number-Guessing-Game,https://api.github.com/users/YusmenKadir,https://api.github.com/repos/YusmenKadir/SpeechAPI-Number-Guessing-Game,"Eindhoven ,The Netherlands "
speech-to-text,python based speech recognition (model used: google speech engine).,bharatchitara,[],https://github.com/bharatchitara/speech-to-text,https://api.github.com/users/bharatchitara,https://api.github.com/repos/bharatchitara/speech-to-text,Bangalore
K6nele-service,"Kõnele service is an Android app that offers a speech-to-text service to other apps, in particular to Kõnele. It implements SpeechRecognizer, backed by an open source speech recognition server software https://github.com/alumae/kaldi-gstreamer-server.",Kaljurand,"['speech-recognition', 'speech-to-text']",https://github.com/Kaljurand/K6nele-service,https://api.github.com/users/Kaljurand,https://api.github.com/repos/Kaljurand/K6nele-service,"Vienna, Austria"
chat-bot,Voice recognition chat-bot using Google's speech recognition library,aldrinbrillante,[],https://github.com/aldrinbrillante/chat-bot,https://api.github.com/users/aldrinbrillante,https://api.github.com/repos/aldrinbrillante/chat-bot,"San Jose, CA"
sentiment_detector_microservice,This Sentiment recognition API with speech recognition feature,ahmedmahm,[],https://github.com/ahmedmahm/sentiment_detector_microservice,https://api.github.com/users/ahmedmahm,https://api.github.com/repos/ahmedmahm/sentiment_detector_microservice,berlin
assistant_with_python,"basic sample with python3, pyttsx3, speech_recognition",hakanmarthidir,[],https://github.com/hakanmarthidir/assistant_with_python,https://api.github.com/users/hakanmarthidir,https://api.github.com/repos/hakanmarthidir/assistant_with_python,"Stuttgart, Germany"
Speech-Recognition,Speech Recognition using Deep Neural Networks,Jerome-Michael,"['deep-learning', 'juypter-notebook', 'natural-language-processing', 'python']",https://github.com/Jerome-Michael/Speech-Recognition,https://api.github.com/users/Jerome-Michael,https://api.github.com/repos/Jerome-Michael/Speech-Recognition,Germany
Speech-Recognition-using-Googel-API,Simple Speech recognition and printing the text,Govindan-2412,[],https://github.com/Govindan-2412/Speech-Recognition-using-Googel-API,https://api.github.com/users/Govindan-2412,https://api.github.com/repos/Govindan-2412/Speech-Recognition-using-Googel-API,"Tamil Nadu,Vellore,Katpadi"
Recognition_miem,Educational project for video and speech recognition,egorka13,"['speech-recognition', 'speech-to-text', 'video-recognition']",https://github.com/egorka13/Recognition_miem,https://api.github.com/users/egorka13,https://api.github.com/repos/egorka13/Recognition_miem,"Russia, Moscow"
Speech-Recognition-Data-Collection,Data collection for Tigrinya speech Recognition,lkidane,[],https://github.com/lkidane/Speech-Recognition-Data-Collection,https://api.github.com/users/lkidane,https://api.github.com/repos/lkidane/Speech-Recognition-Data-Collection,"Kigali,Rwanda"
20-speech-recognition,List words recognized by speech recognition,yaseminertan,[],https://github.com/yaseminertan/20-speech-recognition,https://api.github.com/users/yaseminertan,https://api.github.com/repos/yaseminertan/20-speech-recognition,"İstanbul, Turkey"
google-assistant-recognition,Google speech recognition junto a google assistant,Tatuck,[],https://github.com/Tatuck/google-assistant-recognition,https://api.github.com/users/Tatuck,https://api.github.com/repos/Tatuck/google-assistant-recognition,"Spain, Madrid"
speech-numbers-game,using speech recognition api to play game.,ed-f-jones,[],https://github.com/ed-f-jones/speech-numbers-game,https://api.github.com/users/ed-f-jones,https://api.github.com/repos/ed-f-jones/speech-numbers-game,Philadelphia
MARK-II,MARK II is a speech recognition program.,anurag-compile,[],https://github.com/anurag-compile/MARK-II,https://api.github.com/users/anurag-compile,https://api.github.com/repos/anurag-compile/MARK-II,India
pytorch-reconocimiento-voz,End to End Speech Recognition in Spanish,JLuisRojas,[],https://github.com/JLuisRojas/pytorch-reconocimiento-voz,https://api.github.com/users/JLuisRojas,https://api.github.com/repos/JLuisRojas/pytorch-reconocimiento-voz,"San Luis Potosí, México "
Learning-Speech-Recognition,Simple speech recognition using python library,AsifSyeed,[],https://github.com/AsifSyeed/Learning-Speech-Recognition,https://api.github.com/users/AsifSyeed,https://api.github.com/repos/AsifSyeed/Learning-Speech-Recognition,Dhaka
Speech-Recognition-Program-,Speech recognition program in python named Queen,ygaurav722,[],https://github.com/ygaurav722/Speech-Recognition-Program-,https://api.github.com/users/ygaurav722,https://api.github.com/repos/ygaurav722/Speech-Recognition-Program-,Kurukshetra
Voice-Controlled-Robot,A voice driven robot using Speech recognition.,Shreyansh-Gupta,[],https://github.com/Shreyansh-Gupta/Voice-Controlled-Robot,https://api.github.com/users/Shreyansh-Gupta,https://api.github.com/repos/Shreyansh-Gupta/Voice-Controlled-Robot,"Maharashtra, India"
Speech_recognition_AMMI,Speech  Recognition for Low Resource Language(Twi),Agbeli,[],https://github.com/Agbeli/Speech_recognition_AMMI,https://api.github.com/users/Agbeli,https://api.github.com/repos/Agbeli/Speech_recognition_AMMI,Kigali
Speech-Recognition,"Automated Speech Recognition, Manifold Learning & Agglomerative Clustering",akshayjoshii,"['clustering', 'cosine-similarity', 'embedded-vectors', 'grapheme-to-phoneme', 'pca-analysis', 'speech-recognition']",https://github.com/akshayjoshii/Speech-Recognition,https://api.github.com/users/akshayjoshii,https://api.github.com/repos/akshayjoshii/Speech-Recognition,Saarbrücken
pxt-speech,Speech recognition module SX-ASR-A,zhengyangliu,[],https://github.com/zhengyangliu/pxt-speech,https://api.github.com/users/zhengyangliu,https://api.github.com/repos/zhengyangliu/pxt-speech,China
speech_recognition,Playing around with speech recognition in python,mmcdevitt1997,[],https://github.com/mmcdevitt1997/speech_recognition,https://api.github.com/users/mmcdevitt1997,https://api.github.com/repos/mmcdevitt1997/speech_recognition,Nashville TN 
speech-recognition-ios,Sample quick implementation of iOS speech recognition,glennposadas,[],https://github.com/glennposadas/speech-recognition-ios,https://api.github.com/users/glennposadas,https://api.github.com/repos/glennposadas/speech-recognition-ios,Philippines
VUI_Speech_Recognition,end-to-end speech recognition with DNNs,shahzina,[],https://github.com/shahzina/VUI_Speech_Recognition,https://api.github.com/users/shahzina,https://api.github.com/repos/shahzina/VUI_Speech_Recognition,Toronto
VoiceRecognition,The project using speech recognition python module,rukavishnikovmihail00,[],https://github.com/rukavishnikovmihail00/VoiceRecognition,https://api.github.com/users/rukavishnikovmihail00,https://api.github.com/repos/rukavishnikovmihail00/VoiceRecognition,"Nizhny Novgorod, Russia"
SpeechRecognitionChat-ApplicationAspNetSignalR,Speech Recognition Chat Application | Asp.Net | SignalR,edsonstudio,[],https://github.com/edsonstudio/SpeechRecognitionChat-ApplicationAspNetSignalR,https://api.github.com/users/edsonstudio,https://api.github.com/repos/edsonstudio/SpeechRecognitionChat-ApplicationAspNetSignalR,Recife-PE
todo-app,To Do app with speech recognition,Andriuslima,[],https://github.com/Andriuslima/todo-app,https://api.github.com/users/Andriuslima,https://api.github.com/repos/Andriuslima/todo-app,"Porto Alegre, Brazil"
voice_recognito,speech recognition messing around using python libraries,mikedinhnguyen,[],https://github.com/mikedinhnguyen/voice_recognito,https://api.github.com/users/mikedinhnguyen,https://api.github.com/repos/mikedinhnguyen/voice_recognito,"California, United States"
Speech-Recognition,Speech recognition web app using Javascript,puru-001,[],https://github.com/puru-001/Speech-Recognition,https://api.github.com/users/puru-001,https://api.github.com/repos/puru-001/Speech-Recognition,Banglore 
proyect_topicos_mobile,Ecommerce app with speech recognition assistant.,toborochi,"['dart', 'dialogflow', 'firebase', 'firestore', 'flutter', 'nlp']",https://github.com/toborochi/proyect_topicos_mobile,https://api.github.com/users/toborochi,https://api.github.com/repos/toborochi/proyect_topicos_mobile,"Santa Cruz de la Sierra, BO"
speech-recognition-course,exercises from a udemy speech recognition course ,nirmorgo,[],https://github.com/nirmorgo/speech-recognition-course,https://api.github.com/users/nirmorgo,https://api.github.com/repos/nirmorgo/speech-recognition-course,"Tel Aviv, Israel"
Google-STT-Implementation,Classes utilizing Google API for speech recognition,JesperMjornman,[],https://github.com/JesperMjornman/Google-STT-Implementation,https://api.github.com/users/JesperMjornman,https://api.github.com/repos/JesperMjornman/Google-STT-Implementation,Sweden
automatic-speech-recognition,Automatic Speech Recognition for some letters.,vatozZ,[],https://github.com/vatozZ/automatic-speech-recognition,https://api.github.com/users/vatozZ,https://api.github.com/repos/vatozZ/automatic-speech-recognition,Matmata
markov-recognition,Speech text recognition utilizing markov model,colebryant,[],https://github.com/colebryant/markov-recognition,https://api.github.com/users/colebryant,https://api.github.com/repos/colebryant/markov-recognition,"Chicago, IL"
Jutasu,Jarvis a speech recognition with acess mode,TusharJaiswal7,[],https://github.com/TusharJaiswal7/Jutasu,https://api.github.com/users/TusharJaiswal7,https://api.github.com/repos/TusharJaiswal7/Jutasu,Mumbai
ChatBot_Codes,Basic NLP algorithms for speech recognition. ,00mhk00,[],https://github.com/00mhk00/ChatBot_Codes,https://api.github.com/users/00mhk00,https://api.github.com/repos/00mhk00/ChatBot_Codes,Gurgaon
emotion-recognition,Emotion Recognition from Speech Using Wavelet Features,carankt,[],https://github.com/carankt/emotion-recognition,https://api.github.com/users/carankt,https://api.github.com/repos/carankt/emotion-recognition,India
Speech-Recognition-,This program provides real time speech recognition ,vyasrudra,[],https://github.com/vyasrudra/Speech-Recognition-,https://api.github.com/users/vyasrudra,https://api.github.com/repos/vyasrudra/Speech-Recognition-,"Ahmedabad, Gujarat"
NLP-Project,Recognition of Emotion from Speech directly,Debapriya-Tula,"['emotion', 'mfcc-features', 'nlp', 'random-forest', 'speech', 'speech-emotion-recognition']",https://github.com/Debapriya-Tula/NLP-Project,https://api.github.com/users/Debapriya-Tula,https://api.github.com/repos/Debapriya-Tula/NLP-Project,"Andhra Pradesh, India"
maix_speech_recognition,maix_speech_recognition for C or MaixPy,junhuanchen,[],https://github.com/junhuanchen/maix_speech_recognition,https://api.github.com/users/junhuanchen,https://api.github.com/repos/junhuanchen/maix_speech_recognition,"Dongguan, Guangdong, China"
Speech-Recognition-20-30,JavaScript Speech Recognition #JavaScript30 20-30,Hazmid,[],https://github.com/Hazmid/Speech-Recognition-20-30,https://api.github.com/users/Hazmid,https://api.github.com/repos/Hazmid/Speech-Recognition-20-30,abuja
SpeechRecognition,Speech Recognition System with Kivy Framework.,mohitnamde,[],https://github.com/mohitnamde/SpeechRecognition,https://api.github.com/users/mohitnamde,https://api.github.com/repos/mohitnamde/SpeechRecognition,Indore (MP) 452015
speech-assistant,Speech assistant app using the speech recognition library and Google's text-to-speech API.,AliE99,[],https://github.com/AliE99/speech-assistant,https://api.github.com/users/AliE99,https://api.github.com/repos/AliE99/speech-assistant,"Tehran, Iran"
Speech_Analysis,Speech dictation using GCP Speech Recognition api and analyze speech for pitch detection and answer.,bjpark0805,"['audio-clips', 'beep-sound', 'crepe', 'gcp-cloud-functions', 'speech-analysis']",https://github.com/bjpark0805/Speech_Analysis,https://api.github.com/users/bjpark0805,https://api.github.com/repos/bjpark0805/Speech_Analysis,"Seoul, Jeju island"
audio2text,Converts mp3 audio to text using Google Speech to Text recognition,yashbeer,[],https://github.com/yashbeer/audio2text,https://api.github.com/users/yashbeer,https://api.github.com/repos/yashbeer/audio2text,Mumbai
Speech-Recognition-App,This Speech Recognition app will convert your voice into text form.,wajeehamushtaq,[],https://github.com/wajeehamushtaq/Speech-Recognition-App,https://api.github.com/users/wajeehamushtaq,https://api.github.com/repos/wajeehamushtaq/Speech-Recognition-App,"Lahore, Pakistan"
PyAudi,An audio analyzer in flask using google speech recognition api that transcribes an audio file into text.,chiraag-kakar,"['flask-application', 'googlespeechapi', 'jinja2-templates', 'transcriber']",https://github.com/chiraag-kakar/PyAudi,https://api.github.com/users/chiraag-kakar,https://api.github.com/repos/chiraag-kakar/PyAudi,India
voiceBot-watson,"Speech recognition, also known as automatic speech recognition (ASR), computer speech recognition, or speech-to-text, is a capability which enables a program to process human speech into a written format. While it’s commonly confused with voice recognition, speech recognition focuses on the translation of speech from a verbal format to a text one whereas voice recognition just seeks to identify an individual user’s voice.",tarunawahyudi,[],https://github.com/tarunawahyudi/voiceBot-watson,https://api.github.com/users/tarunawahyudi,https://api.github.com/repos/tarunawahyudi/voiceBot-watson,Indonesia
speech-recognition_using_google_api,It convert speech to text using goole speech_recognition module written in python,AranyaKumarTripathy,[],https://github.com/AranyaKumarTripathy/speech-recognition_using_google_api,https://api.github.com/users/AranyaKumarTripathy,https://api.github.com/repos/AranyaKumarTripathy/speech-recognition_using_google_api,"Odhisha, Angul"
Speech-to-text,Speech to text recognition using Google speech to text and socket.io,kunjesh1,[],https://github.com/kunjesh1/Speech-to-text,https://api.github.com/users/kunjesh1,https://api.github.com/repos/kunjesh1/Speech-to-text,Mumbai India
python_voice_assistant,Python app that uses speech recognition and gTTS to answer speech commands,sidbhanushali,[],https://github.com/sidbhanushali/python_voice_assistant,https://api.github.com/users/sidbhanushali,https://api.github.com/repos/sidbhanushali/python_voice_assistant,San Francisco
speech-recognition-project,This repository contains the speech dataset and some files concerned with the speech recognition class project. ,csikasote,[],https://github.com/csikasote/speech-recognition-project,https://api.github.com/users/csikasote,https://api.github.com/repos/csikasote/speech-recognition-project,"Lusaka, Zambia"
Speech-to-text-Python-program-using-Kivy-library-and-Google-speech-recognition-Arabic-English-.,"Speech to text Python program using Kivy library and Google speech recognition (Arabic, English).",Malakmud,[],https://github.com/Malakmud/Speech-to-text-Python-program-using-Kivy-library-and-Google-speech-recognition-Arabic-English-.,https://api.github.com/users/Malakmud,https://api.github.com/repos/Malakmud/Speech-to-text-Python-program-using-Kivy-library-and-Google-speech-recognition-Arabic-English-.,KSA
speech-recognition,Practice using the speech recognition API for accessibility purposes (speech-to-text),marissabellusci,"['accessibility', 'html-css-javascript', 'microphone', 'speech-recognition', 'speech-recognition-api', 'speech-to-text']",https://github.com/marissabellusci/speech-recognition,https://api.github.com/users/marissabellusci,https://api.github.com/repos/marissabellusci/speech-recognition,"Boulder, CO"
alpha_assistente,This is a speech assistant app using the speech recognition library and Googles text-to-speech API.,alessandroanjos,[],https://github.com/alessandroanjos/alpha_assistente,https://api.github.com/users/alessandroanjos,https://api.github.com/repos/alessandroanjos/alpha_assistente,"Natal, Brazil"
voice-automotive,"Voice-interactive vehicle collection dashboard in React using react-speech-recognition, Speechly, and TypeScript.",jsb7131,[],https://github.com/jsb7131/voice-automotive,https://api.github.com/users/jsb7131,https://api.github.com/repos/jsb7131/voice-automotive,New York City
Speech-To-Text,Simple python script to convert speech to text using Speech Recognition,GaurangGhadiya,[],https://github.com/GaurangGhadiya/Speech-To-Text,https://api.github.com/users/GaurangGhadiya,https://api.github.com/repos/GaurangGhadiya/Speech-To-Text,"Surat, Gujrat, India"
python-speech-assistant,A simple Speech Assistant designed with speech-recognition and gTTS libraries,abhisheksakibanda,[],https://github.com/abhisheksakibanda/python-speech-assistant,https://api.github.com/users/abhisheksakibanda,https://api.github.com/repos/abhisheksakibanda/python-speech-assistant,Hyderabad
github_Proj,GitHub search which  we are using for the speech recognition . ,Pinki-Lakshakar,[],https://github.com/Pinki-Lakshakar/github_Proj,https://api.github.com/users/Pinki-Lakshakar,https://api.github.com/repos/Pinki-Lakshakar/github_Proj,Bangalore
kaldi-egy-asr,A Kaldi-Recipe for  Egyptian Arabic Speech Recognition,maggieezzat,"['arabic', 'asr-model', 'egyptian', 'kaldi', 'kaldi-asr', 'nnet3', 'speech-recognition']",https://github.com/maggieezzat/kaldi-egy-asr,https://api.github.com/users/maggieezzat,https://api.github.com/repos/maggieezzat/kaldi-egy-asr,"Cairo, Egypt"
SpeechRecognitionExample,Very simple example for iOS(Swift) Speech Recognition.,TokyoYoshida,[],https://github.com/TokyoYoshida/SpeechRecognitionExample,https://api.github.com/users/TokyoYoshida,https://api.github.com/repos/TokyoYoshida/SpeechRecognitionExample,"Tokyo, Japan"
Wikipedia-Search-Assistant,wikipedia search assistant program which uses speech recognition,fennin3,[],https://github.com/fennin3/Wikipedia-Search-Assistant,https://api.github.com/users/fennin3,https://api.github.com/repos/fennin3/Wikipedia-Search-Assistant,Ghana
peso_pyvoice,Access few functionalities using speech recognition and text to sppech,peteruche21,[],https://github.com/peteruche21/peso_pyvoice,https://api.github.com/users/peteruche21,https://api.github.com/repos/peteruche21/peso_pyvoice,Nigeria
Speech-Recognition-app,A speech recognition web app which only supports chrome,Perezo99,[],https://github.com/Perezo99/Speech-Recognition-app,https://api.github.com/users/Perezo99,https://api.github.com/repos/Perezo99/Speech-Recognition-app,"Nigeria, Abuja"
speech-emotion-recognition,Emotion Recognition using Speech data trained using MLP classifier,harxish,[],https://github.com/harxish/speech-emotion-recognition,https://api.github.com/users/harxish,https://api.github.com/repos/harxish/speech-emotion-recognition,"Chennai, India"
cwhq-rovan-jarvis,Speech Recognition App I edited for a student,daniel-schroeder-dev,[],https://github.com/daniel-schroeder-dev/cwhq-rovan-jarvis,https://api.github.com/users/daniel-schroeder-dev,https://api.github.com/repos/daniel-schroeder-dev/cwhq-rovan-jarvis,"New Orleans, LA"
RemoteRecognition,"Speech recognition using nodejs, react and DialogFlow (google)",pedroGenio,[],https://github.com/pedroGenio/RemoteRecognition,https://api.github.com/users/pedroGenio,https://api.github.com/repos/pedroGenio/RemoteRecognition,"Auckland, NZ"
NumberGuessingApp,This application was made to showcase speech recognition technology,BenFlanders,[],https://github.com/BenFlanders/NumberGuessingApp,https://api.github.com/users/BenFlanders,https://api.github.com/repos/BenFlanders/NumberGuessingApp,North Carolina
Speech-Recognition-Arduino,Turn ON or OFF Lamp Using Speech Recognition Bluetooth,muhiqball,[],https://github.com/muhiqball/Speech-Recognition-Arduino,https://api.github.com/users/muhiqball,https://api.github.com/repos/muhiqball/Speech-Recognition-Arduino,Yogyakarta
dictator,A voice recognition app that converts your speech to text. ,vwvats,[],https://github.com/vwvats/dictator,https://api.github.com/users/vwvats,https://api.github.com/repos/vwvats/dictator,India
Add-Speech-Recognition-to-the-Website-JavaScript-and-PHP,Add Speech Recognition to the Website – JavaScript and PHP,zinmyoswe,[],https://github.com/zinmyoswe/Add-Speech-Recognition-to-the-Website-JavaScript-and-PHP,https://api.github.com/users/zinmyoswe,https://api.github.com/repos/zinmyoswe/Add-Speech-Recognition-to-the-Website-JavaScript-and-PHP,Yangon
Voice-control-calculator,Voice control calculator using speech recognition in python,Shiv1202,"['calculator-application', 'cli', 'python3', 'speech-recognition', 'speech-to-text']",https://github.com/Shiv1202/Voice-control-calculator,https://api.github.com/users/Shiv1202,https://api.github.com/repos/Shiv1202/Voice-control-calculator,Lucknow India
A-smarter-Siri, Commonly used text Input based on speech recognition,ShaneXiangH,[],https://github.com/ShaneXiangH/A-smarter-Siri,https://api.github.com/users/ShaneXiangH,https://api.github.com/repos/ShaneXiangH/A-smarter-Siri,"Davis, CA"
Speech-emotion-and-gender-recognition,Speech Emotion and Gender Recognition with Convolution Neural Network,tolgaaksoy,[],https://github.com/tolgaaksoy/Speech-emotion-and-gender-recognition,https://api.github.com/users/tolgaaksoy,https://api.github.com/repos/tolgaaksoy/Speech-emotion-and-gender-recognition,Bursa
nMapper,nMapper is an automated penetration testing tool. (speech recognition included!),badchars,[],https://github.com/badchars/nMapper,https://api.github.com/users/badchars,https://api.github.com/repos/badchars/nMapper,New York
NHS-Speech-Recognition-App,"This was a group project created remotely over 7 days using Java, Spring, JavaScript and React. It is a full-stack app that allows user to search an NHS api for information on different health conditions using Speech Recognition.",linseycurrie,"['agile', 'api-rest', 'java', 'javascript', 'nhs', 'nhs-health', 'react', 'speech', 'speech-recognition', 'spring']",https://github.com/linseycurrie/NHS-Speech-Recognition-App,https://api.github.com/users/linseycurrie,https://api.github.com/repos/linseycurrie/NHS-Speech-Recognition-App,Glasgow
speech_recognition_tutorial,Learning speech analytics and recognition to apply machine learning techniques.,neemiasbsilva,[],https://github.com/neemiasbsilva/speech_recognition_tutorial,https://api.github.com/users/neemiasbsilva,https://api.github.com/repos/neemiasbsilva/speech_recognition_tutorial,BRASIL
python-projects,personal assistant  by using speech recognition module in python,nishant998,[],https://github.com/nishant998/python-projects,https://api.github.com/users/nishant998,https://api.github.com/repos/nishant998/python-projects,Greater Noida
rf_nb_audio_data,Speech accent recognition using Mel Frequency Cepstral Coefficients (MFCCs),asarjou,[],https://github.com/asarjou/rf_nb_audio_data,https://api.github.com/users/asarjou,https://api.github.com/repos/asarjou/rf_nb_audio_data,London
speaky-notes,Manage and schedule notes with Speech recognition feature,punit3299,"['speech-processing', 'speech-recognition', 'speech-to-text']",https://github.com/punit3299/speaky-notes,https://api.github.com/users/punit3299,https://api.github.com/repos/punit3299/speaky-notes,"Mumbai, Maharashtra"
speakNumberGuessingGame,"Mini-project #20, a number guessing game using speech recognition.",BlakeACollins,[],https://github.com/BlakeACollins/speakNumberGuessingGame,https://api.github.com/users/BlakeACollins,https://api.github.com/repos/BlakeACollins/speakNumberGuessingGame,"Seattle,WA"
react-speech-recognition-example,Super basic create-react-app with speech recognition abilities!,princefishthrower,[],https://github.com/princefishthrower/react-speech-recognition-example,https://api.github.com/users/princefishthrower,https://api.github.com/repos/princefishthrower/react-speech-recognition-example,"Feldkirch, Austria"
Artificial-Intelligence-Fridge,This is a unique Fridge system software using Speech recognition ,JubairPabel,[],https://github.com/JubairPabel/Artificial-Intelligence-Fridge,https://api.github.com/users/JubairPabel,https://api.github.com/repos/JubairPabel/Artificial-Intelligence-Fridge,"Chittagong,Bangladesh"
SSL-ASR,Self Supervised Learning for Automatic Speech Recognition (R&D),ericpapain,[],https://github.com/ericpapain/SSL-ASR,https://api.github.com/users/ericpapain,https://api.github.com/repos/ericpapain/SSL-ASR,Troyes
speech-prototype,A prototype for offline speech recognition for my capstone project,CalvinGolas,[],https://github.com/CalvinGolas/speech-prototype,https://api.github.com/users/CalvinGolas,https://api.github.com/repos/CalvinGolas/speech-prototype,"Detroit, MI"
Artificial-Intelligence-Fridge,This is a unique Fridge system software using Speech recognition ,JubairPabel,[],https://github.com/JubairPabel/Artificial-Intelligence-Fridge,https://api.github.com/users/JubairPabel,https://api.github.com/repos/JubairPabel/Artificial-Intelligence-Fridge,"Chittagong,Bangladesh"
parot,python simple voice assistant. Built with google speech recognition package,Rigelabs,[],https://github.com/Rigelabs/parot,https://api.github.com/users/Rigelabs,https://api.github.com/repos/Rigelabs/parot,"Nairobi,Westlands"
textSummarization,Emotion detection project using  the Google Speech Recognition.,lelameram23,[],https://github.com/lelameram23/textSummarization,https://api.github.com/users/lelameram23,https://api.github.com/repos/lelameram23/textSummarization,İstanbul
Automatic-Speech-Recognition,Speaker Independent Automatic Speech Recognition for continuous audio.,iambankaratharva,"['convolutional-neural-networks', 'neural-networks', 'pydub', 'silencedetect', 'speech-processing', 'speech-recognition', 'speech-synthesis', 'speech-to-text']",https://github.com/iambankaratharva/Automatic-Speech-Recognition,https://api.github.com/users/iambankaratharva,https://api.github.com/repos/iambankaratharva/Automatic-Speech-Recognition,Pune
FRAINE-RICICLA,An easy implementation of the HTML5 speech recognition API. ,VincenzoMarcovecchio,"['html5', 'javascript', 'speech-recognition', 'speech-to-text', 'waste-management']",https://github.com/VincenzoMarcovecchio/FRAINE-RICICLA,https://api.github.com/users/VincenzoMarcovecchio,https://api.github.com/repos/VincenzoMarcovecchio/FRAINE-RICICLA,Italy
ASR_Speaker_Recognition,Project in the Aalto University course ELEC-E5510 Speech Recognition,timroelofs123,[],https://github.com/timroelofs123/ASR_Speaker_Recognition,https://api.github.com/users/timroelofs123,https://api.github.com/repos/timroelofs123/ASR_Speaker_Recognition,"Espoo, Finland"
Speech-And-Speaker-Recognition-DT2119,Speech and Speaker Recognition course (DT2119) at KTH,deepchatterjeevns,[],https://github.com/deepchatterjeevns/Speech-And-Speaker-Recognition-DT2119,https://api.github.com/users/deepchatterjeevns,https://api.github.com/repos/deepchatterjeevns/Speech-And-Speaker-Recognition-DT2119,"Pune, Maharashtra, India"
cv-builder,Python script CV builder and text-to-speech recognition.,Terieyenike,"['python', 'python-docx', 'pyttsx3']",https://github.com/Terieyenike/cv-builder,https://api.github.com/users/Terieyenike,https://api.github.com/repos/Terieyenike/cv-builder,Lagos
vosk-ASR-app,Simple Automatic Speech Recognition App deployed to Heroku,giraycoskun,[],https://github.com/giraycoskun/vosk-ASR-app,https://api.github.com/users/giraycoskun,https://api.github.com/repos/giraycoskun/vosk-ASR-app,İstanbul
benchmark-speech-emotion-recognition,Benchmark created to evaluate Speech Emotion Recognition Models,luisbch9,[],https://github.com/luisbch9/benchmark-speech-emotion-recognition,https://api.github.com/users/luisbch9,https://api.github.com/repos/luisbch9/benchmark-speech-emotion-recognition,Arequipa
python-speech-recognition,Speech recognition using Python and SpeechRecognition with Google Cloud,caiodearaujo,[],https://github.com/caiodearaujo/python-speech-recognition,https://api.github.com/users/caiodearaujo,https://api.github.com/repos/caiodearaujo/python-speech-recognition,Brazil
Expense-Tracker,Expense Tracker React App with speech recognition feature,Akshh057,[],https://github.com/Akshh057/Expense-Tracker,https://api.github.com/users/Akshh057,https://api.github.com/repos/Akshh057/Expense-Tracker,Jaipur
spoken_digit_recognition,Speech Recognition using DNNs to recognize spoken digits. ,Lohith-muppala,[],https://github.com/Lohith-muppala/spoken_digit_recognition,https://api.github.com/users/Lohith-muppala,https://api.github.com/repos/Lohith-muppala/spoken_digit_recognition,"Chicago, IL"
kaldi-msa-asr,A kaldi recipe for modern standard arabic speech recognition,maggieezzat,"['arabic', 'asr', 'kaldi', 'kaldi-asr', 'nnet3', 'speech-recognition']",https://github.com/maggieezzat/kaldi-msa-asr,https://api.github.com/users/maggieezzat,https://api.github.com/repos/maggieezzat/kaldi-msa-asr,"Cairo, Egypt"
machine-learning2020,Speech emotion recognition using various machine learning algorithms,n-minhhai,"['audio', 'data-science', 'machine-learning', 'python', 'speech']",https://github.com/n-minhhai/machine-learning2020,https://api.github.com/users/n-minhhai,https://api.github.com/repos/n-minhhai/machine-learning2020,"London, United Kingdom"
my-SER,My contribution to improve the Speech Emotion Recognition research,matheusjv11,[],https://github.com/matheusjv11/my-SER,https://api.github.com/users/matheusjv11,https://api.github.com/repos/matheusjv11/my-SER,"Palmas, Tocantins - Brazil"
SpeechRecognitionAPIJS,20/20: Speech Recognition API - 20 VanillaJS Projects,Sampatankar,[],https://github.com/Sampatankar/SpeechRecognitionAPIJS,https://api.github.com/users/Sampatankar,https://api.github.com/repos/Sampatankar/SpeechRecognitionAPIJS,Lancashire & Manchester
Emotion-Detection,Emotion detection project using  the Google Speech Recognition.,lelameram23,[],https://github.com/lelameram23/Emotion-Detection,https://api.github.com/users/lelameram23,https://api.github.com/repos/lelameram23/Emotion-Detection,İstanbul
speech_recognition,"Basic speech recognition app written in Python named ""Freya""",devin-baxter,[],https://github.com/devin-baxter/speech_recognition,https://api.github.com/users/devin-baxter,https://api.github.com/repos/devin-baxter/speech_recognition,"Santa Cruz, CA"
audio-transcriber,📝 Audio Transcription Web App using Django and Speech recognition Module,aminekha,[],https://github.com/aminekha/audio-transcriber,https://api.github.com/users/aminekha,https://api.github.com/repos/aminekha/audio-transcriber,Tunisia
transcript-from-audiofiles,use browser speech recognition for getting transcripts from audio files,tEErohr,[],https://github.com/tEErohr/transcript-from-audiofiles,https://api.github.com/users/tEErohr,https://api.github.com/repos/tEErohr/transcript-from-audiofiles,Berlin
Speech-Recognition,Real time Speech-Recognition Project to search & play youtube video.,vishvpatel-97,[],https://github.com/vishvpatel-97/Speech-Recognition,https://api.github.com/users/vishvpatel-97,https://api.github.com/repos/vishvpatel-97/Speech-Recognition,Bangalore
VCP200,dumping the code out of the VCP200 speech recognition chip,abzman,[],https://github.com/abzman/VCP200,https://api.github.com/users/abzman,https://api.github.com/repos/abzman/VCP200,"Detroit, MI"
SpeechRecognitionDeepLearning,Leveraging the Power of Deep learning in NLP-Speech Recognition,Bunny3363,[],https://github.com/Bunny3363/SpeechRecognitionDeepLearning,https://api.github.com/users/Bunny3363,https://api.github.com/repos/Bunny3363/SpeechRecognitionDeepLearning,Chennai
mr-hommy,Home assistant services. Voice synthesis and speech recognition.,asidko,[],https://github.com/asidko/mr-hommy,https://api.github.com/users/asidko,https://api.github.com/repos/asidko/mr-hommy,"Kyiv, Ukraine"
Listener,Speech recognition from the microphone or speaker output,Cabbache,[],https://github.com/Cabbache/Listener,https://api.github.com/users/Cabbache,https://api.github.com/repos/Cabbache/Listener,TON 618
Python-Voice-Command-Calculator,Voice Command Calculator in Python using speech recognition and PyAudio,haiderrizvi92,[],https://github.com/haiderrizvi92/Python-Voice-Command-Calculator,https://api.github.com/users/haiderrizvi92,https://api.github.com/repos/haiderrizvi92/Python-Voice-Command-Calculator,Islamabad
Automatic-Speech-Recognition,End-to-End Automatic Speech Recognition Using Connectionist Temporal Classification,2016bgeyer,[],https://github.com/2016bgeyer/Automatic-Speech-Recognition,https://api.github.com/users/2016bgeyer,https://api.github.com/repos/2016bgeyer/Automatic-Speech-Recognition,"Chantilly, VA"
speech-recognition-in-javascript-starter,Starter Code for Speech Recognition in JavaScript tutorial.,zolomohan,"['javascript', 'speech-recognition', 'webspeech-api']",https://github.com/zolomohan/speech-recognition-in-javascript-starter,https://api.github.com/users/zolomohan,https://api.github.com/repos/zolomohan/speech-recognition-in-javascript-starter,"Chennai,  Tamil Nadu, India"
Speech_Recognition,AMMI Speech Recognition  project for low-resource language(Arabic),Safa1Mohamed,[],https://github.com/Safa1Mohamed/Speech_Recognition,https://api.github.com/users/Safa1Mohamed,https://api.github.com/repos/Safa1Mohamed/Speech_Recognition,"Kigali, Rwanda"
digit-tutor,"Digit Tutor is a simple online game for kids in Svelte, which uses speech recognition engine to train pronunciation of digits: from ""0"" to ""9"".",Rulikkk,"['internationalization', 'kids', 'kids-learn', 'speech-recognition', 'svelte']",https://github.com/Rulikkk/digit-tutor,https://api.github.com/users/Rulikkk,https://api.github.com/repos/Rulikkk/digit-tutor,"Kazan, Russia"
Adversarial_Attacks_for_SER,"Code of the paper ""Generating and Protecting Against Adversarial Attacks for Deep Speech-based Emotion Recognition Models""",EIHW,[],https://github.com/EIHW/Adversarial_Attacks_for_SER,https://api.github.com/users/EIHW,https://api.github.com/repos/EIHW/Adversarial_Attacks_for_SER,"Augsburg, Germany"
Recorder-STT, Web audio recorder🎙. Using Recorder.js and speech_recognition packages. Records Audio 🔈 in web and convert it to Text📄,frontend-engineer,[],https://github.com/frontend-engineer/Recorder-STT,https://api.github.com/users/frontend-engineer,https://api.github.com/repos/frontend-engineer/Recorder-STT,"Chennai, India "
asr-wer-bench,Workbench for benchmarking Word Error Rate (WER) of Automatic Speech Recognition (ASR) systems on a given data set.,SlangLabs,"['speech-recognition', 'speech-to-text']",https://github.com/SlangLabs/asr-wer-bench,https://api.github.com/users/SlangLabs,https://api.github.com/repos/SlangLabs/asr-wer-bench,Bangalore
speech-recognition,A very useless speech recognition script written with python. Does nothing else other than speech-to-text.,ZephDaCodes,[],https://github.com/ZephDaCodes/speech-recognition,https://api.github.com/users/ZephDaCodes,https://api.github.com/repos/ZephDaCodes/speech-recognition,ur mom's bed
csharp-reconhece-e-sintetiza-voz,Utilizando reconhecimento e síntese de voz no C# com os namespaces Microsoft.Speech.Recognition e System.Speech.Synthesis.,RiquelmyArcanjo,[],https://github.com/RiquelmyArcanjo/csharp-reconhece-e-sintetiza-voz,https://api.github.com/users/RiquelmyArcanjo,https://api.github.com/repos/RiquelmyArcanjo/csharp-reconhece-e-sintetiza-voz,"São Vicente, SP - Brazil"
virtualAssistent-Python,"Virtual assistent using speech recognition by Google, gTTS (Google Text-to-speech) and pygame module to reproduce the sound",Diego-Dos-Santos,[],https://github.com/Diego-Dos-Santos/virtualAssistent-Python,https://api.github.com/users/Diego-Dos-Santos,https://api.github.com/repos/Diego-Dos-Santos/virtualAssistent-Python,"Madrid, España"
speech-processing,"A demo of Xelera's speech processing pipeline including speech-to-text, natural language processing, speaker recognition and speaker diarization",xelera-technologies,[],https://github.com/xelera-technologies/speech-processing,https://api.github.com/users/xelera-technologies,https://api.github.com/repos/xelera-technologies/speech-processing,"Darmstadt, Germany"
SpeechRecognition-Sample,This library is SpeechRecognition API (Web Speech API) compatible implementation for various cloud-based speech recognition engines.,kazuki,"['google-speech-recognition', 'ogg', 'opus', 'python', 'python-asyncio', 'python-asyncio-grpc', 'speech-recognition', 'typescript', 'webassembly', 'webaudio']",https://github.com/kazuki/SpeechRecognition-Sample,https://api.github.com/users/kazuki,https://api.github.com/repos/kazuki/SpeechRecognition-Sample,Japan
Todo-List-Speech-Generating,"A website to generates a todo-list dashboard with speech-generating (ReactJs, PostGres, HTML5 Speech Recognition API)",AriNguyen,"['html-css-javascript', 'postgresql', 'reactjs', 'speech-recognition', 'speech-to-text']",https://github.com/AriNguyen/Todo-List-Speech-Generating,https://api.github.com/users/AriNguyen,https://api.github.com/repos/AriNguyen/Todo-List-Speech-Generating,"Philadelphia, PA"
Speech-Emotion-Recognition,"Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech.",G-G-Thorat,[],https://github.com/G-G-Thorat/Speech-Emotion-Recognition,https://api.github.com/users/G-G-Thorat,https://api.github.com/repos/G-G-Thorat/Speech-Emotion-Recognition,Thane
Speech-Recognition-Python,Transcribes .wav audio speech files. UI rendered wit Flask and uses Google's Speech Recognition API to transcribe.,deeprony7,[],https://github.com/deeprony7/Speech-Recognition-Python,https://api.github.com/users/deeprony7,https://api.github.com/repos/deeprony7/Speech-Recognition-Python,"Bangalore, India"
In-Proteins,A multiplayer proteins interactive system is a platform that provides multiple communication and realises Speech Recognition and Phrase Recognition. ,QingLi77,[],https://github.com/QingLi77/In-Proteins,https://api.github.com/users/QingLi77,https://api.github.com/repos/QingLi77/In-Proteins,Cork
speech-text-speech,This Simple program uses gTTS library for Text to Speech and also this program uses Speech Recognition library for Speech to Text ,ajinkyah,[],https://github.com/ajinkyah/speech-text-speech,https://api.github.com/users/ajinkyah,https://api.github.com/repos/ajinkyah/speech-text-speech,Mumbai
Speech-synthesis,Speech synthesis is Web Speech API app for different rate of voices and other being the speech recognition API we dealt with earlier.,Brainketunze,[],https://github.com/Brainketunze/Speech-synthesis,https://api.github.com/users/Brainketunze,https://api.github.com/repos/Brainketunze/Speech-synthesis,Live in Landen Belgium
Keyword-Detection,"Keyword Detection/Spotting with pocketsphinx speech recognition engine, always listening with a trigger command: ""jarvis""",itechdivyanshu,"['keyword-spotting', 'pocketsphinx', 'pyaudio', 'python3']",https://github.com/itechdivyanshu/Keyword-Detection,https://api.github.com/users/itechdivyanshu,https://api.github.com/repos/itechdivyanshu/Keyword-Detection,"West Bengal, India"
AutoSrtSyncGUI,A version of my SrtSyncGUI program that will Sync subtitles automatically using Google speech recognition.,AnaCoda,[],https://github.com/AnaCoda/AutoSrtSyncGUI,https://api.github.com/users/AnaCoda,https://api.github.com/repos/AnaCoda/AutoSrtSyncGUI,Canada
asr-practice-m2,"schoolworks and personal practice about ""automatic speech recognition"" of M2-AI in 2020-2021",ZoeYou,[],https://github.com/ZoeYou/asr-practice-m2,https://api.github.com/users/ZoeYou,https://api.github.com/repos/ZoeYou/asr-practice-m2,"Massy, France"
AutoSubGen,A Command Line python package that generates SRT subtitles for a video using Google Speech Recognition,ckirby19,[],https://github.com/ckirby19/AutoSubGen,https://api.github.com/users/ckirby19,https://api.github.com/repos/ckirby19/AutoSubGen,London
python_voice_to_text,Program that processes audio file to retrieve a script. [speech recognition],robriu,[],https://github.com/robriu/python_voice_to_text,https://api.github.com/users/robriu,https://api.github.com/repos/robriu/python_voice_to_text,Europe/Asia
speech-extraction-python,"Extraction of text from audio clip using moviepy and speech_recognition library, python",Gicehajunior,"['librosa', 'speech', 'speech-recognition', 'speech-to-text']",https://github.com/Gicehajunior/speech-extraction-python,https://api.github.com/users/Gicehajunior,https://api.github.com/repos/Gicehajunior/speech-extraction-python,Nairobi
Xenator,A Speech recognition system that runs basic Programming commands and gives output,acousticclown,"['compiler', 'compiler-design', 'pyhton3', 'speech-recognition', 'speech-to-code', 'speech-to-text', 'voice-compiler', 'voice-to-code']",https://github.com/acousticclown/Xenator,https://api.github.com/users/acousticclown,https://api.github.com/repos/acousticclown/Xenator,"Indore, Madhya Pradesh, India "
voice-assistant,"Voice Assistant built with Python, speech recognition library, weather API and more. ",YD-Coding,[],https://github.com/YD-Coding/voice-assistant,https://api.github.com/users/YD-Coding,https://api.github.com/repos/YD-Coding/voice-assistant,Israel
asr-dynamic-wfst-decoder,Executive summary for a project on a WFST-based Decoder for Automatic Speech Recognition,orsdanilo,[],https://github.com/orsdanilo/asr-dynamic-wfst-decoder,https://api.github.com/users/orsdanilo,https://api.github.com/repos/orsdanilo/asr-dynamic-wfst-decoder,"São Paulo, Brazil"
noise-robust-acoustic-features,An i-vector based Non-Negative Matrix Factorization approach towards noise robust Automatic Speech Recognition,KunalDhawan,[],https://github.com/KunalDhawan/noise-robust-acoustic-features,https://api.github.com/users/KunalDhawan,https://api.github.com/repos/KunalDhawan/noise-robust-acoustic-features,"Pittsburgh, PA"
Speech-Tagging-and-Entity-Recognition,Basic Parts of Speech Tagging and Named Entity Recognition in Python using SpaCy,muhk01,"['spacy', 'spacy-nlp']",https://github.com/muhk01/Speech-Tagging-and-Entity-Recognition,https://api.github.com/users/muhk01,https://api.github.com/repos/muhk01/Speech-Tagging-and-Entity-Recognition,"Jakarta, Indonesia"
stopwatch_miniproject,This is a Speech Recognition Flutter application that operates a stopwatch using voice.,someshvk,"['android-application', 'flutter', 'speech-recognition', 'speech-to-text']",https://github.com/someshvk/stopwatch_miniproject,https://api.github.com/users/someshvk,https://api.github.com/repos/someshvk/stopwatch_miniproject,India
Notes-Taker,"A speech recognition application for taking notes built with js, HTML and bootstrap.",ealpha072,"['bootstrap4', 'html', 'js', 'speech-recognition']",https://github.com/ealpha072/Notes-Taker,https://api.github.com/users/ealpha072,https://api.github.com/repos/ealpha072/Notes-Taker,"Kisumu, Kenya"
Speech_AI,An easy extendable and customizable artificial intelligence made using speech recognition ,Amethyst69,[],https://github.com/Amethyst69/Speech_AI,https://api.github.com/users/Amethyst69,https://api.github.com/repos/Amethyst69/Speech_AI,"Rome, Italy"
clashCounter,A React companion application that uses speech recognition to win Clash Royale games,MatthiasLing,[],https://github.com/MatthiasLing/clashCounter,https://api.github.com/users/MatthiasLing,https://api.github.com/repos/MatthiasLing/clashCounter,Chicago
Speech-Recognition-Resuable-API,"A free to consume, re-usable component for speech recognition (python)",somilsharma8,[],https://github.com/somilsharma8/Speech-Recognition-Resuable-API,https://api.github.com/users/somilsharma8,https://api.github.com/repos/somilsharma8/Speech-Recognition-Resuable-API,Gurgaon
AMMI-Speech-Recognition-ArabicData,This data has been collected for purpose of working project in  AMMI -Speech Recognition course,abdalgader-a,[],https://github.com/abdalgader-a/AMMI-Speech-Recognition-ArabicData,https://api.github.com/users/abdalgader-a,https://api.github.com/repos/abdalgader-a/AMMI-Speech-Recognition-ArabicData,"London, United Kingdom"
voice-to-text,Use of built in speech recognition in the browser with JS,JanelleLesley,[],https://github.com/JanelleLesley/voice-to-text,https://api.github.com/users/JanelleLesley,https://api.github.com/repos/JanelleLesley/voice-to-text,"Austin, TX"
Speak-Solve,This was my project which includes speech recognition technique to convert and calculate value.,RiaYadav,[],https://github.com/RiaYadav/Speak-Solve,https://api.github.com/users/RiaYadav,https://api.github.com/repos/RiaYadav/Speak-Solve,Mumbai
VirtualVoiceAssistant,This prject was developed in python3 using AI speech recognition technique,mrinavkumar1999,[],https://github.com/mrinavkumar1999/VirtualVoiceAssistant,https://api.github.com/users/mrinavkumar1999,https://api.github.com/repos/mrinavkumar1999/VirtualVoiceAssistant,New Delhi
GitHub_Project,GITHUB  Serach Project  which we are using search the voice (Speech Recognition) ,Pinki-Lakshakar,[],https://github.com/Pinki-Lakshakar/GitHub_Project,https://api.github.com/users/Pinki-Lakshakar,https://api.github.com/repos/Pinki-Lakshakar/GitHub_Project,Bangalore
weather-speak-py,Uses speech recognition and a weather API to return the current weather of a city.,nicroy23,[],https://github.com/nicroy23/weather-speak-py,https://api.github.com/users/nicroy23,https://api.github.com/repos/nicroy23/weather-speak-py,Canada
Voice_Todo-App-React,"Add and Delete Task with voice commands. Built with React , material UI , react-speech-recognition library.",SanketW12,[],https://github.com/SanketW12/Voice_Todo-App-React,https://api.github.com/users/SanketW12,https://api.github.com/repos/SanketW12/Voice_Todo-App-React,PUNE
bidirectional-rnn-speech-recognition,Speech Recognition using Bidirectional Recurrent Neural Networks and Time Distributed Dense,florenciopaucar,[],https://github.com/florenciopaucar/bidirectional-rnn-speech-recognition,https://api.github.com/users/florenciopaucar,https://api.github.com/repos/florenciopaucar/bidirectional-rnn-speech-recognition,"Helskinki, Finland"
speech-recognition-unit-for-pascal,import unit about speech recognition for pascal programing with python 3.9.0,Privmk,[],https://github.com/Privmk/speech-recognition-unit-for-pascal,https://api.github.com/users/Privmk,https://api.github.com/repos/Privmk/speech-recognition-unit-for-pascal,AnGiang Vietnam
django_voice_bot,Package for django onpage support bot with speech recognition and voice commands,Dostoyewski,"['django-support-bot', 'speech-recognition', 'trigger', 'voice-bot', 'voice-commands']",https://github.com/Dostoyewski/django_voice_bot,https://api.github.com/users/Dostoyewski,https://api.github.com/repos/Dostoyewski/django_voice_bot,Saint-Petersburg
voice_dial,An application which integrates speech recognition into a traditional dialer app.,Abhijnan-Bajpai,[],https://github.com/Abhijnan-Bajpai/voice_dial,https://api.github.com/users/Abhijnan-Bajpai,https://api.github.com/repos/Abhijnan-Bajpai/voice_dial,Bangalore
voiceATM,Voice controlled ATM prototype implemented using google speech recognition with python,surajgupta-git,[],https://github.com/surajgupta-git/voiceATM,https://api.github.com/users/surajgupta-git,https://api.github.com/repos/surajgupta-git/voiceATM,Bloomington
voice-assistance,A  voice assistance that will use speech recognition to browse content.,vanshika-goel0109,[],https://github.com/vanshika-goel0109/voice-assistance,https://api.github.com/users/vanshika-goel0109,https://api.github.com/repos/vanshika-goel0109/voice-assistance,Raebareli Uttar Pradesh
PyJarvis,This is  a desktop assistant in python which can performs certain tasks through GOOGLE SPEECH RECOGNITION .,VinayakSingoriya,[],https://github.com/VinayakSingoriya/PyJarvis,https://api.github.com/users/VinayakSingoriya,https://api.github.com/repos/VinayakSingoriya/PyJarvis,"IIPS, DAVV, Indore"
capstone,Researching neural net for speech recognition. Capstone project for Flatiron Data Science Bootcamp.,anbillinger,[],https://github.com/anbillinger/capstone,https://api.github.com/users/anbillinger,https://api.github.com/repos/anbillinger/capstone,"Bay Area, CA"
Android-Shopping-List-App,An android application that uses speech recognition to create a shopping list,Timmutegi,[],https://github.com/Timmutegi/Android-Shopping-List-App,https://api.github.com/users/Timmutegi,https://api.github.com/repos/Timmutegi/Android-Shopping-List-App,"Nairobi, Kenya"
audio-transcriber-docker,Automatically transcribe the audio of video / audio files using Speech Recognition.,book000,"['docker', 'docker-image', 'speech-recognition', 'speech-to-text', 'transcriber']",https://github.com/book000/audio-transcriber-docker,https://api.github.com/users/book000,https://api.github.com/repos/book000/audio-transcriber-docker,Japan
vosk_dual_speech_stt,"Kaldi, vosk, dual voices, speech to text recognition. Russian voice example",format37,[],https://github.com/format37/vosk_dual_speech_stt,https://api.github.com/users/format37,https://api.github.com/repos/format37/vosk_dual_speech_stt,Moscow
youtube-subs-generator,Subs generator by voice recognition in Web Speech API at YouTube,pushback,[],https://github.com/pushback/youtube-subs-generator,https://api.github.com/users/pushback,https://api.github.com/repos/pushback/youtube-subs-generator,Japan
Virtual-Assistant,"This is basically a virtual assistant built using python ,wikipedia ,wolframalpha and speech recognition .",SurabhiSuresh22,"['python', 'speech-recognition-api', 'virtual-assistant', 'wikipedia', 'wolframalpha']",https://github.com/SurabhiSuresh22/Virtual-Assistant,https://api.github.com/users/SurabhiSuresh22,https://api.github.com/repos/SurabhiSuresh22/Virtual-Assistant,"Kerala,India"
Tues_Translator-unfinished-,Desktop Version / Python / Tkinter GUI / GTTS + Speech Recognition API from Google / Database MySQL,MinhTueCung,[],https://github.com/MinhTueCung/Tues_Translator-unfinished-,https://api.github.com/users/MinhTueCung,https://api.github.com/repos/MinhTueCung/Tues_Translator-unfinished-,Germany
Speech_Recognition_in_Kannada,A simple and easy Speech Recognition for Kannada Language in just 10 lines of Python Code.,arnoldsachith,[],https://github.com/arnoldsachith/Speech_Recognition_in_Kannada,https://api.github.com/users/arnoldsachith,https://api.github.com/repos/arnoldsachith/Speech_Recognition_in_Kannada,Bangalore
speech-exec,Execute bash statements with your voice using Google Cloud Speech Recognition.,Lyssers,[],https://github.com/Lyssers/speech-exec,https://api.github.com/users/Lyssers,https://api.github.com/repos/Lyssers/speech-exec,London
Speech-App,A speech recognition App in Javascript using on of the inbuilt extensions of Google chrome,Emmriz,[],https://github.com/Emmriz/Speech-App,https://api.github.com/users/Emmriz,https://api.github.com/repos/Emmriz/Speech-App,Lagos
Python-Projects,Calculator | Data visualization | RPG | Speech recognition AI | Web browser | Web scrapery,RafaelxFernandes,[],https://github.com/RafaelxFernandes/Python-Projects,https://api.github.com/users/RafaelxFernandes,https://api.github.com/repos/RafaelxFernandes/Python-Projects,"Brazil, Rio de Janeiro"
your-points-please,nativescript app for android using speech recognition to handle points for games,aabeling,[],https://github.com/aabeling/your-points-please,https://api.github.com/users/aabeling,https://api.github.com/repos/aabeling/your-points-please,Germany
vistec-ser,Speech Emotion Recognition using PyTorch sponsored by AIS and VISTEC-DEPA AIResearch Institute Thailand.,tann9949,"['speech-emotion-recognition', 'speech-processing', 'tensorflow']",https://github.com/tann9949/vistec-ser,https://api.github.com/users/tann9949,https://api.github.com/repos/tann9949/vistec-ser,"Bangkok, Thailand"
MobilePlayer,A music player (audio and video) incorporated with Forum and Speech Recognition functionalities,CodeYueXiong,[],https://github.com/CodeYueXiong/MobilePlayer,https://api.github.com/users/CodeYueXiong,https://api.github.com/repos/CodeYueXiong/MobilePlayer,"Munich, Germany"
CORONA_Latest_Info_Speech_Recognition,coronavirus latest Update Information by using API for web scraping and python speech recognition. ,aminmb2800,[],https://github.com/aminmb2800/CORONA_Latest_Info_Speech_Recognition,https://api.github.com/users/aminmb2800,https://api.github.com/repos/aminmb2800/CORONA_Latest_Info_Speech_Recognition,Berlin 
Evaluation-of-ASR-in-Musical-Environment,Semester project for 18-781 (Speech Recognition and Understanding) with Dr. Ian Lane.,justinnuwin,[],https://github.com/justinnuwin/Evaluation-of-ASR-in-Musical-Environment,https://api.github.com/users/justinnuwin,https://api.github.com/repos/justinnuwin/Evaluation-of-ASR-in-Musical-Environment,"Fremont, CA"
Speech_Recognition_Comparison,Program made to plot Google's speech recognition API using a box and whisker plot,Rv-ben,[],https://github.com/Rv-ben/Speech_Recognition_Comparison,https://api.github.com/users/Rv-ben,https://api.github.com/repos/Rv-ben/Speech_Recognition_Comparison,Long Beach 
Sequence-Model---Trigger-Word-Detection,Speech Recognition in sequential models. Trigger word detection for a program to activate like 'Hello',jaikushwaha7,[],https://github.com/jaikushwaha7/Sequence-Model---Trigger-Word-Detection,https://api.github.com/users/jaikushwaha7,https://api.github.com/repos/jaikushwaha7/Sequence-Model---Trigger-Word-Detection,"Pune, India"
number-guessing-game,Number guessing game where you speak your guess into the microphone using the speech recognition API.,akash02-das,[],https://github.com/akash02-das/number-guessing-game,https://api.github.com/users/akash02-das,https://api.github.com/repos/akash02-das/number-guessing-game,"Dhaka, Bangladesh"
Deep-Learning-Projects,"Projects about Speaker Identification, Speech Recognition, my own Pytorch library implementation",ziqian98,[],https://github.com/ziqian98/Deep-Learning-Projects,https://api.github.com/users/ziqian98,https://api.github.com/repos/ziqian98/Deep-Learning-Projects,Pittsburgh
speak-number-guess,Number guessing game where you speak your guess into the microphone using the speech recognition API.,Ishaan-11,"['css', 'html', 'javascript', 'speech-recognition']",https://github.com/Ishaan-11/speak-number-guess,https://api.github.com/users/Ishaan-11,https://api.github.com/repos/Ishaan-11/speak-number-guess,"New Delhi, India"
project_speaker_verification_recognition,A small project for comparing two speaker verification and recognition models using the speech commands data,benedictmulongo,[],https://github.com/benedictmulongo/project_speaker_verification_recognition,https://api.github.com/users/benedictmulongo,https://api.github.com/repos/benedictmulongo/project_speaker_verification_recognition,sweden
Number_Guess,A number guess game that uses Speech Recognition to record and compare answers. ,etorres-revature,"['css', 'javascript', 'number-guess', 'speechrecognition']",https://github.com/etorres-revature/Number_Guess,https://api.github.com/users/etorres-revature,https://api.github.com/repos/etorres-revature/Number_Guess,"New Orleans, LA"
voice-based-voice-search,voice based voice search in a video | python | speech-recognition | GUI (tkinter),100mya,[],https://github.com/100mya/voice-based-voice-search,https://api.github.com/users/100mya,https://api.github.com/repos/100mya/voice-based-voice-search,"Durg, Chhattisgarh"
ShabdKosh,A virtual assistant built using python's speech_recognition and gTTS module. ,ashish-mj,"['gtts', 'speech-recognition', 'virtual-assistant']",https://github.com/ashish-mj/ShabdKosh,https://api.github.com/users/ashish-mj,https://api.github.com/repos/ashish-mj/ShabdKosh,Pune
SpeechRec_API,this is my sample file of API code for Speech Recognition to Text.,takuyatta,[],https://github.com/takuyatta/SpeechRec_API,https://api.github.com/users/takuyatta,https://api.github.com/repos/takuyatta/SpeechRec_API,Japan
speech-to-text-experiment,Experiments with speech recognition api  that is currently only supported by chromium based browsers (afaik),andreas-schoch,[],https://github.com/andreas-schoch/speech-to-text-experiment,https://api.github.com/users/andreas-schoch,https://api.github.com/repos/andreas-schoch/speech-to-text-experiment,Switzerland
AI-assistant,AI Assistant helps you save basic manual operations by just Speech Recognition in python,yasho0o7,[],https://github.com/yasho0o7/AI-assistant,https://api.github.com/users/yasho0o7,https://api.github.com/repos/yasho0o7/AI-assistant,"Kandivali-(w), Mumbai"
raf_pg,"Homeworks and project from ""Speech Recognition"" course at Faculty of Computing in Belgrade",jelic98,[],https://github.com/jelic98/raf_pg,https://api.github.com/users/jelic98,https://api.github.com/repos/jelic98/raf_pg,"London, United Kingdom"
UrduLanguageModel,Language Model for Urdu Speech Recognition. Created in SRI Language Modeling Toolkit,mhadnanali,[],https://github.com/mhadnanali/UrduLanguageModel,https://api.github.com/users/mhadnanali,https://api.github.com/repos/mhadnanali/UrduLanguageModel,Hefei China
cit371-helicopter-commander,Control a helicopter in Grand Theft Auto: San Andreas using speech recognition,andraantariksa,"['cpp', 'grand-theft-auto', 'helicopter', 'san-andreas', 'speech-recognition']",https://github.com/andraantariksa/cit371-helicopter-commander,https://api.github.com/users/andraantariksa,https://api.github.com/repos/andraantariksa/cit371-helicopter-commander,"Bekasi, Indonesia"
cmake-deepspeech,An example of using cmake with Mozilla's deepspeech STT speech recognition of .wav files,BenjaminHinchliff,"['c', 'cmake', 'cplusplus', 'cpp', 'cpp11', 'deepspeech', 'speech-to-text', 'stt']",https://github.com/BenjaminHinchliff/cmake-deepspeech,https://api.github.com/users/BenjaminHinchliff,https://api.github.com/repos/BenjaminHinchliff/cmake-deepspeech,"California, USA"
Speech-Recognition,"Small Speech Recognition app that detects simple words, using a Convolutional Neural Network (CNN)",NickMonks,[],https://github.com/NickMonks/Speech-Recognition,https://api.github.com/users/NickMonks,https://api.github.com/repos/NickMonks/Speech-Recognition,United Kingdom
Axel-Browser-Assistant,Browser Assistant using speech recognition APIs in JavaScript and some other basic NLP concepts,altf4-89,[],https://github.com/altf4-89/Axel-Browser-Assistant,https://api.github.com/users/altf4-89,https://api.github.com/repos/altf4-89/Axel-Browser-Assistant,Kolkata/Bengaluru
Smart_Chat_client,"React,React-scroll-to-bottom,React-speech-recognition,socket.io-client",SupriyaShekar123,[],https://github.com/SupriyaShekar123/Smart_Chat_client,https://api.github.com/users/SupriyaShekar123,https://api.github.com/repos/SupriyaShekar123/Smart_Chat_client,"Amstelveen,Netherlands "
Speech-Recognition,Speech Recognition by matching patterns using Cross-Correlation Technique in MATLAB.,atulya06,[],https://github.com/atulya06/Speech-Recognition,https://api.github.com/users/atulya06,https://api.github.com/repos/atulya06/Speech-Recognition,"Ranchi, Jharkhand"
speak-number-guess,Number guessing game where you speak your guess into the microphone using the speech recognition API,Belchenkov,"['css3', 'html5', 'js6', 'speechrecognition']",https://github.com/Belchenkov/speak-number-guess,https://api.github.com/users/Belchenkov,https://api.github.com/repos/Belchenkov/speak-number-guess,"Russia, Saratov"
My-Bot,"A AI based bot which responds to what, I speak as it is based speech recognition",ShivamModi1012,[],https://github.com/ShivamModi1012/My-Bot,https://api.github.com/users/ShivamModi1012,https://api.github.com/repos/ShivamModi1012/My-Bot,Zirakpur
JS-speak-number-guess,Number guessing game where you speak your guess into the microphone using the speech recognition API,michaelhaule,[],https://github.com/michaelhaule/JS-speak-number-guess,https://api.github.com/users/michaelhaule,https://api.github.com/repos/michaelhaule/JS-speak-number-guess,"Dodoma, Tanzania"
majore,Project of Advanced Computer Vision on Multiresolution and Multimodal Speech Recognition Transformers,Deathn0t,[],https://github.com/Deathn0t/majore,https://api.github.com/users/Deathn0t,https://api.github.com/repos/Deathn0t/majore,"Paris, France"
obi,"smart chatbot,  capable of engaging in human communication, speech recognition and much more",zolum,[],https://github.com/zolum/obi,https://api.github.com/users/zolum,https://api.github.com/repos/zolum/obi,Lagos
Speech-Recognition,Comparison of Speech Recognition Models and their use on a voice controlled bot,Aaatresh,[],https://github.com/Aaatresh/Speech-Recognition,https://api.github.com/users/Aaatresh,https://api.github.com/repos/Aaatresh/Speech-Recognition,"Ann Arbor, USA"
Simple-Speech-Recognition,This is simple speech recognition software created using speechrecognition library and python,StealthyKnifer,[],https://github.com/StealthyKnifer/Simple-Speech-Recognition,https://api.github.com/users/StealthyKnifer,https://api.github.com/repos/StealthyKnifer/Simple-Speech-Recognition,"Kolkata, West Bengal"
KotlinTalk,Speech recognition template project for sphinx4 using Kotlin and Gradle framework.,maxc-dev,['sphinx-4'],https://github.com/maxc-dev/KotlinTalk,https://api.github.com/users/maxc-dev,https://api.github.com/repos/maxc-dev/KotlinTalk,"United Kingdom, Croydon"
J.A.R.V.I.S,"This is a voice assisted desktop assistant called J.A.R.V.I.S,developed using python language.""pyttsx3"" and ""speech_recognition"" are some of the libraries used in this project.",Abhishekkole,[],https://github.com/Abhishekkole/J.A.R.V.I.S,https://api.github.com/users/Abhishekkole,https://api.github.com/repos/Abhishekkole/J.A.R.V.I.S,Hyderabad
Speech-Recognition,Tensorflow implementation for Speech Recognition using Convolutional Neural Networks. The trained model is deployable on a Raspberry Pi to classify spoken words.,mhagglun,"['convolutional-neural-networks', 'deep-learning', 'raspberry-pi', 'speech-recognition', 'tensorflow']",https://github.com/mhagglun/Speech-Recognition,https://api.github.com/users/mhagglun,https://api.github.com/repos/mhagglun/Speech-Recognition,"Stockholm, Sweden"
Speech-To-Text-conversion,Speech recognition is the ability of a computer software to identify words and phrases in spoken language and convert them to human readable text.,tiwnilesh022,[],https://github.com/tiwnilesh022/Speech-To-Text-conversion,https://api.github.com/users/tiwnilesh022,https://api.github.com/repos/tiwnilesh022/Speech-To-Text-conversion,delhi(ncr)
Simple_Speech_Recognition_Using_Deep_Learning,"In this repo, I've built a simple speech recognition CNN model for processing speech signals and transforms the wave input to text output.",bala-codes,[],https://github.com/bala-codes/Simple_Speech_Recognition_Using_Deep_Learning,https://api.github.com/users/bala-codes,https://api.github.com/repos/bala-codes/Simple_Speech_Recognition_Using_Deep_Learning,Coimbatore
Customer-Assistance-Chatbot,"An Android ChatBot for Customer Assistance powered by IBM Watson Services (Assistant V1, Text-to-Speech, and Speech-to-Text with Speaker Recognition) on IBM Cloud.",abhilashsaj,"['ai', 'artificial-intelligence', 'chatbots', 'ibm-cloud', 'ibm-watson', 'speech-recognition']",https://github.com/abhilashsaj/Customer-Assistance-Chatbot,https://api.github.com/users/abhilashsaj,https://api.github.com/repos/abhilashsaj/Customer-Assistance-Chatbot,Kerala/Dubai
ser-based-conditional-gan,Generating human faces through conditional GANs which are conditioned on emotions identified from a human speech using SER (Speech Emotion Recognition),harshit158,[],https://github.com/harshit158/ser-based-conditional-gan,https://api.github.com/users/harshit158,https://api.github.com/repos/harshit158/ser-based-conditional-gan,"Boston, MA"
AI-assistant,"An AI assistant built using python ,which is having features like speech recognition,speech-to-text features and computational features using language processing.",Adityaukumar,[],https://github.com/Adityaukumar/AI-assistant,https://api.github.com/users/Adityaukumar,https://api.github.com/repos/Adityaukumar/AI-assistant,hyderabad
SpeechRecognition,A machine learning algorithm designed to understand simple speech commands in this dataset https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data,usef-kh,[],https://github.com/usef-kh/SpeechRecognition,https://api.github.com/users/usef-kh,https://api.github.com/repos/usef-kh/SpeechRecognition,"Boston, Massachusetts"
LetsTalk,A simple speech recognition program that uses google text to speech. The main motive in writing this program is to learn Python and create something cool.,gkhabas76,[],https://github.com/gkhabas76/LetsTalk,https://api.github.com/users/gkhabas76,https://api.github.com/repos/gkhabas76/LetsTalk,Nepal
speech-emotion-recognition,Speech Emotion Recognition is used to recognize human emotion and their state of speech as well. This can be determined by tone and the pitch of the voice.,Supraja9726,[],https://github.com/Supraja9726/speech-emotion-recognition,https://api.github.com/users/Supraja9726,https://api.github.com/repos/Supraja9726/speech-emotion-recognition,Chennai
Part-of-Speech-Tagging-with-Hidden-Markov-Models," Pomegranate library to build a hidden Markov model for part of speech tagging with a universal tagset. Hidden Markov models have been able to achieve >96% tag accuracy with larger tagsets on realistic text corpora. Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision",ahmed-hassan97,[],https://github.com/ahmed-hassan97/Part-of-Speech-Tagging-with-Hidden-Markov-Models,https://api.github.com/users/ahmed-hassan97,https://api.github.com/repos/ahmed-hassan97/Part-of-Speech-Tagging-with-Hidden-Markov-Models,kafrsaqr-zagazig-egypt
ml-nlp-data-science,"This is my personal playground which includes but not limited to Machine Learning, Deep Learning, Neural Networks, Image Recognition, Speech Recognition, Data Science, and Natural Language Processing. ",rakib06,"['data-science', 'deep-neural-networks', 'machine-learning-algorithms', 'natural-language-processing']",https://github.com/rakib06/ml-nlp-data-science,https://api.github.com/users/rakib06,https://api.github.com/repos/rakib06/ml-nlp-data-science,"Dhaka, Bangladesh"
Speech_assistant,"This Application is build using python libraries Speech_recognition, webbrowser and playsound. Using this application user can search anything from internet with speech and also system will respond him speech format.",AkshRidlan,[],https://github.com/AkshRidlan/Speech_assistant,https://api.github.com/users/AkshRidlan,https://api.github.com/repos/AkshRidlan/Speech_assistant,"Mumbai,India"
speechRecognition,Copy of google with speech recognition(works only in Google Chrome :c ). Working google search engine with some extra stylesheet.,Rartosz,[],https://github.com/Rartosz/speechRecognition,https://api.github.com/users/Rartosz,https://api.github.com/repos/Rartosz/speechRecognition,Łódź/Zielona Góra/Warszawa
RoboVec,"A home robot powered by deep learning, computer vision, object detection and speech recognition. He is VECTOR",surajitsaikia27,[],https://github.com/surajitsaikia27/RoboVec,https://api.github.com/users/surajitsaikia27,https://api.github.com/repos/surajitsaikia27/RoboVec,"Bilbao, Spain"
Robbie-12.20-Personal-Virtual-Assistant,It is a Speech Recognition Personal Virtual Assistant made with Python that can handle much of your work.,SyedHuzaifa007,"['assistant', 'battery', 'playing-movies', 'speech-recognition', 'weather']",https://github.com/SyedHuzaifa007/Robbie-12.20-Personal-Virtual-Assistant,https://api.github.com/users/SyedHuzaifa007,https://api.github.com/repos/SyedHuzaifa007/Robbie-12.20-Personal-Virtual-Assistant,"Lahore, Pakistan"
nba-voice-assistant,Uses speech recognition module and NBA API to get player stats in a given season from the user's voice.,iamandrewliao,[],https://github.com/iamandrewliao/nba-voice-assistant,https://api.github.com/users/iamandrewliao,https://api.github.com/repos/iamandrewliao/nba-voice-assistant,"NYC, ATL"
Expense-Tracker,An expense tracker app which can track your income and expenditure. Supports local browser storage and Speech Recognition!! ,nikhilsujith,[],https://github.com/nikhilsujith/Expense-Tracker,https://api.github.com/users/nikhilsujith,https://api.github.com/repos/nikhilsujith/Expense-Tracker,Jersey City 
AimlChatbot,"A NLP/NLU chatbot in Java, spring-boot, web socket, Speech Recognition, Natural language Processing, NLU and AIML",ntshvicky,"['ai', 'chatbot', 'java', 'natural-language-processing', 'natural-language-understanding', 'nlp', 'nlu', 'spring-boot', 'websocket', 'websocket-chat']",https://github.com/ntshvicky/AimlChatbot,https://api.github.com/users/ntshvicky,https://api.github.com/repos/ntshvicky/AimlChatbot,Ranchi
personal-assistant,This project is an automated GUI text and speech recognition software that will assist me with my daily workflow.,iSOLveIT,[],https://github.com/iSOLveIT/personal-assistant,https://api.github.com/users/iSOLveIT,https://api.github.com/repos/iSOLveIT/personal-assistant,Ghana
my_own_bot,"Speech Recognition bot which can play music , find you a movie and you can search any wiki topic you want !!!",redrivals,[],https://github.com/redrivals/my_own_bot,https://api.github.com/users/redrivals,https://api.github.com/repos/redrivals/my_own_bot,"Delhi,India"
Memory-game-using-speech,A game to test your memory powered by your voice using speech recognition module by Google API.,sanskritikhare142,[],https://github.com/sanskritikhare142/Memory-game-using-speech,https://api.github.com/users/sanskritikhare142,https://api.github.com/repos/sanskritikhare142/Memory-game-using-speech,Chennai
SpeechRecognitionApplication,SpeechRecognition through google's Speech_Recognition API and building a simple rule based system to send mails,skrakesh5,[],https://github.com/skrakesh5/SpeechRecognitionApplication,https://api.github.com/users/skrakesh5,https://api.github.com/repos/skrakesh5/SpeechRecognitionApplication,Bengaluru
dnn_speech_recognition,Implement a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline,tnakatani,"['asr', 'librispeech', 'speech-recognition']",https://github.com/tnakatani/dnn_speech_recognition,https://api.github.com/users/tnakatani,https://api.github.com/repos/tnakatani/dnn_speech_recognition,"Pittsburgh, PA"
ner-hmm-pos-tagging,Named-Entity Recognition pada Teks Berbahasa Indonesia menggunakan Metode Hidden Markov Model dan Part-of-Speech Tagging,mridhoputra,"['hiddenmarkovmodel', 'hmm', 'ner', 'postagging', 'word-features']",https://github.com/mridhoputra/ner-hmm-pos-tagging,https://api.github.com/users/mridhoputra,https://api.github.com/repos/mridhoputra/ner-hmm-pos-tagging,"Palembang, Indonesia"
VanillaJS-Speech-Recognition-Game,"Learning how to build a simple numbers guessing game that utilizes Speech Recognition API (HTML, CSS, JavaScript)",smkattoula,[],https://github.com/smkattoula/VanillaJS-Speech-Recognition-Game,https://api.github.com/users/smkattoula,https://api.github.com/repos/smkattoula/VanillaJS-Speech-Recognition-Game,"San Diego, CA"
Speech-Recognition-Using-RNNs,A Recurrent Neural Network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline!,manishkadam007,[],https://github.com/manishkadam007/Speech-Recognition-Using-RNNs,https://api.github.com/users/manishkadam007,https://api.github.com/repos/manishkadam007/Speech-Recognition-Using-RNNs,Guwahati
VirtualAssistant,"A simple voice assistant made using python. Responds to voice commands, speech to text recognition, can open websites and applications. ",rushabhnaik16,[],https://github.com/rushabhnaik16/VirtualAssistant,https://api.github.com/users/rushabhnaik16,https://api.github.com/repos/rushabhnaik16/VirtualAssistant,India
Python-SpeechToText,Google Translate based python speech recognition CLI application that takes inputs as microphone recording and saves them in conversions folder.,rkalaiselvan6,[],https://github.com/rkalaiselvan6/Python-SpeechToText,https://api.github.com/users/rkalaiselvan6,https://api.github.com/repos/rkalaiselvan6/Python-SpeechToText,"Chennai , Tamil Nadu"
autechs,Game Therapy App to Help Children with Autism Disorder Using Occupational Therapy(augmented reality) and Speech Therapy(voice recognition),sobhansalimy,[],https://github.com/sobhansalimy/autechs,https://api.github.com/users/sobhansalimy,https://api.github.com/repos/sobhansalimy/autechs,IRAN
Enterprise-Computer,Raspberry Pi software to control the speech recognition and lighting aboard the model USS Enterprise NCC-1701-A,EthanHaid,[],https://github.com/EthanHaid/Enterprise-Computer,https://api.github.com/users/EthanHaid,https://api.github.com/repos/EthanHaid/Enterprise-Computer,"Vancouver, Canada"
tensor_flow_voice_recognition_for_vr,Work in progress of a Tensor flow based speech recognition to act as a controller for VR environments,spayne,[],https://github.com/spayne/tensor_flow_voice_recognition_for_vr,https://api.github.com/users/spayne,https://api.github.com/repos/spayne/tensor_flow_voice_recognition_for_vr,"Seattle, WA"
Audio-Recognition-Recognizing-key-words,"A basic speech recognition network that recognizes ten different words: ""down"", ""go"", ""left"", ""no"", ""right"", ""stop"", ""up"" and ""yes"".  Setup.",MedentzidisCharalampos,[],https://github.com/MedentzidisCharalampos/Audio-Recognition-Recognizing-key-words,https://api.github.com/users/MedentzidisCharalampos,https://api.github.com/repos/MedentzidisCharalampos/Audio-Recognition-Recognizing-key-words,Thessaloniki
Audio-adversarial-examples,Datasets of audio adversarial examples for deep speech recognition systems and Python code of a detection system,zhenghuatan,[],https://github.com/zhenghuatan/Audio-adversarial-examples,https://api.github.com/users/zhenghuatan,https://api.github.com/repos/zhenghuatan/Audio-adversarial-examples,"Aalborg, Denmark"
speech-emotion-recognition,Speech Emotion Recognition project that analyzes .wav files and predicts the underlying emotion. Multiclass classification with five emotion classes. ,Iasonaspg,"['classification-model', 'jupyter-notebook', 'python', 'speech-emotion-recognition']",https://github.com/Iasonaspg/speech-emotion-recognition,https://api.github.com/users/Iasonaspg,https://api.github.com/repos/Iasonaspg/speech-emotion-recognition,Greece
Part-of-speech-taggling,"In this notebook, you'll use the Pomegranate library to build a hidden Markov model for part of speech tagging with a universal tagset. Hidden Markov models have been able to achieve >96% tag accuracy with larger tagsets on realistic text corpora. Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision, and more.",dgonzalez2711,[],https://github.com/dgonzalez2711/Part-of-speech-taggling,https://api.github.com/users/dgonzalez2711,https://api.github.com/repos/dgonzalez2711/Part-of-speech-taggling,St Charles Mo
Speech-Recognizer-and-Synthesizer,"Speech recognition, is the device to respond to spoken commands, like in simple words we say as, Speech-to-Text Conversion Device whereas Speech Synthesizer is a device that generates spoken language on the basis of written input, i.e. Text-To-Speech Conversion Device.",Supriya1711,[],https://github.com/Supriya1711/Speech-Recognizer-and-Synthesizer,https://api.github.com/users/Supriya1711,https://api.github.com/repos/Supriya1711/Speech-Recognizer-and-Synthesizer,"Madhya Pradesh, India"
Hand-Gesture-Recognition-In-IOT,Hand Gesture Recognition for speech-impaired people because they have their own sign language but normal people don’t know the sign language which is used for intercommunication between speech impaired people.,kartikagarwal9,[],https://github.com/kartikagarwal9/Hand-Gesture-Recognition-In-IOT,https://api.github.com/users/kartikagarwal9,https://api.github.com/repos/kartikagarwal9/Hand-Gesture-Recognition-In-IOT,India
Specch_to_text_using_CNN,"Speech Recognition is an important feature in several applications used such as home automation, artificial intelligence, etc. In many cases we need to convert the speech coming from live stream into text.",aakashspeaks,[],https://github.com/aakashspeaks/Specch_to_text_using_CNN,https://api.github.com/users/aakashspeaks,https://api.github.com/repos/aakashspeaks/Specch_to_text_using_CNN,Pune
speech-recognition,"Speech Recognition module in Python, take an Audio File as input in Flask, create both a GET and POST request on the same route and finally render the transcribed results of the speech file to the user.",Magnifique-d,[],https://github.com/Magnifique-d/speech-recognition,https://api.github.com/users/Magnifique-d,https://api.github.com/repos/Magnifique-d/speech-recognition,Earth
WhatsThatLine,"An online lyrics quiz app built with the Speech Recognition functionality from the Web Speech API, altogether with a lyrics api from APISEEDS, and another lyrics API from Genius.com.",jasontsemf,[],https://github.com/jasontsemf/WhatsThatLine,https://api.github.com/users/jasontsemf,https://api.github.com/repos/jasontsemf/WhatsThatLine,"New York, New York"
Snake-Water-Gun---autonomous,"This is a python based ""Snake-Water-Gun"" game program. The inbuilt Random module made this game possible. The coalescence of Speech Recognition, Code Algorithm and Text to Speech converter makes this program fully autonomous.",AnuragSen23,[],https://github.com/AnuragSen23/Snake-Water-Gun---autonomous,https://api.github.com/users/AnuragSen23,https://api.github.com/repos/AnuragSen23/Snake-Water-Gun---autonomous,Chennai India
ReactAudioAssistant,React application that can be controlled by voice using react-speech-recognition (React hook that converts speech from the microphone to text and makes it available to your React components).,svire,"['firebase', 'firebase-storage', 'react', 'redux', 'speech-recognition', 'speech-to-text']",https://github.com/svire/ReactAudioAssistant,https://api.github.com/users/svire,https://api.github.com/repos/svire/ReactAudioAssistant,Belgrade
NLP_modeling,"This repository will contain codes for all types of NLP tasks such as question answering, speech recognition, speech to text, language translation, sentiment analysis, etc. Also, extensive codes on data pre-processing will be written.",aditagrawal,[],https://github.com/aditagrawal/NLP_modeling,https://api.github.com/users/aditagrawal,https://api.github.com/repos/aditagrawal/NLP_modeling,Bangalore
JARVIS,"A virtual assistant that can perform activities like opening applications, websites , responding to basic and many more thing  questions through speech recognition and text-to-speech engines in Python ",rishiraj7102,[],https://github.com/rishiraj7102/JARVIS,https://api.github.com/users/rishiraj7102,https://api.github.com/repos/rishiraj7102/JARVIS,Mumbai
Voice-Enchancement-using-librosa,Speech Emotion Recognition (SER) is the act of attempting to recognize human emotion and affective states from speech. It is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch.,umeshp6464,[],https://github.com/umeshp6464/Voice-Enchancement-using-librosa,https://api.github.com/users/umeshp6464,https://api.github.com/repos/umeshp6464/Voice-Enchancement-using-librosa,Mumbai
JARVIS,J.A.R.V.I.S. - Just A Rather Very Intelligent System . It is a Voice Control Automated Desktop Assistant coded in Python mainly using Google Speech Recognition and Python’s Inbuilt Speech to text library and various other API.,shrijeet7,"['desktop-assistant', 'google-speech-recognition', 'python3', 'speech-to-text', 'text-to-speech', 'virtual-assistant', 'voice-control', 'voice-recognition']",https://github.com/shrijeet7/JARVIS,https://api.github.com/users/shrijeet7,https://api.github.com/repos/shrijeet7/JARVIS,"kolkata,West bengal , India"
VoiceRecognition,"A simple terminal based voice recognition program written in python with the help of speech_recognition library. Understands simple commands as Hello, Exit, Make a Note, Exit or sleep",AadishSaini,[],https://github.com/AadishSaini/VoiceRecognition,https://api.github.com/users/AadishSaini,https://api.github.com/repos/AadishSaini/VoiceRecognition,"Dwarka, New-Delhi, Delhi"
speech_Recognition,you will build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline,ahmed-hassan97,[],https://github.com/ahmed-hassan97/speech_Recognition,https://api.github.com/users/ahmed-hassan97,https://api.github.com/repos/ahmed-hassan97/speech_Recognition,kafrsaqr-zagazig-egypt
Virtual-Assistant,A very simple AI that uses python's speech recognition module to perform basic tasks as the user instructs it to do.,ayushbali,[],https://github.com/ayushbali/Virtual-Assistant,https://api.github.com/users/ayushbali,https://api.github.com/repos/ayushbali/Virtual-Assistant,India
Speech-Recognition-Using-NodeMCU-,In this repository I will be documenting steps to build a speech recognition application using NodeMCU and ESP 32 Camera Module,AnbuKumar-maker,[],https://github.com/AnbuKumar-maker/Speech-Recognition-Using-NodeMCU-,https://api.github.com/users/AnbuKumar-maker,https://api.github.com/repos/AnbuKumar-maker/Speech-Recognition-Using-NodeMCU-,India
SimpleSpeechRecognition--,Simple speech Recognition script by deploying Google API. 我是为开会听不懂英语写的脚本，哭。,doulemint,[],https://github.com/doulemint/SimpleSpeechRecognition--,https://api.github.com/users/doulemint,https://api.github.com/repos/doulemint/SimpleSpeechRecognition--,Rochester
AI-enabled-desktop-assistant,"This is my AI enabled Desktop assistant created using speech recognition API's in python . it can open files , read articles, play music and much more",ashleydabreu,[],https://github.com/ashleydabreu/AI-enabled-desktop-assistant,https://api.github.com/users/ashleydabreu,https://api.github.com/repos/ashleydabreu/AI-enabled-desktop-assistant,Mumbai 
Guess-game, This is a small game that picks a random word from a list and gives the user three attempts to guess the word . Speech recognition,Betty1999Kamanthe,[],https://github.com/Betty1999Kamanthe/Guess-game,https://api.github.com/users/Betty1999Kamanthe,https://api.github.com/repos/Betty1999Kamanthe/Guess-game,Kenya
SmartSTT,SmartSTT is an In-car speech recognition system which helps the deaf driver to get the messages from their passengers.This is  a prototype assistant. ,cnsnaya,['assistant'],https://github.com/cnsnaya/SmartSTT,https://api.github.com/users/cnsnaya,https://api.github.com/repos/cnsnaya/SmartSTT,"Bhubaneswar,Odisha,India"
englishChallenge,Creating a speech recognition system to learn colors in English - Criando um sistema de reconhecimento de voz para aprender cores em Inglês. @digitalinnovationone e @felipeAguiarCode,jerp86,"['dioxsquad', 'speech', 'speech-recognition']",https://github.com/jerp86/englishChallenge,https://api.github.com/users/jerp86,https://api.github.com/repos/jerp86/englishChallenge,Botucatu-SP
Speech-Recognition-Script,A Speech Recognition Script Created using Python and Tkinter... It gives you the ability to enter a word and it will alert you when it hears it..,amans199,"['pyhton', 'speech-recognition']",https://github.com/amans199/Speech-Recognition-Script,https://api.github.com/users/amans199,https://api.github.com/repos/amans199/Speech-Recognition-Script,Egypt
VUI_Speech_Recognizer,"In this notebook, you will build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline!",suninsunday,[],https://github.com/suninsunday/VUI_Speech_Recognizer,https://api.github.com/users/suninsunday,https://api.github.com/repos/suninsunday/VUI_Speech_Recognizer,"hangzhou,zhejiang"
RMLIntent,"Contains the meta-learning splits for Google Speech Commands and Fluent.AI Dataset used in representation based meta-learning for few-shot spoken intent recognition, interspeech 2020 paper ",AshishMittal,[],https://github.com/AshishMittal/RMLIntent,https://api.github.com/users/AshishMittal,https://api.github.com/repos/AshishMittal/RMLIntent,Bangalore
Speech-recognition-sample,A brief & complete sample of speech recognition were you can test the different parameters and will give you the accuracy of the API model.,Y4rd13,"['python', 'speech-recognition']",https://github.com/Y4rd13/Speech-recognition-sample,https://api.github.com/users/Y4rd13,https://api.github.com/repos/Y4rd13/Speech-recognition-sample,"viña del mar, Chile."
speech-recognition-jarvis-walker,This is my first my major project on speech recognition. This project work as Alexa but for basic day to day tasks. Edits are welcomed!!!,saurabhsen1212,[],https://github.com/saurabhsen1212/speech-recognition-jarvis-walker,https://api.github.com/users/saurabhsen1212,https://api.github.com/repos/saurabhsen1212/speech-recognition-jarvis-walker,"Jabalpur, Madhya Pradesh, India"
PCApp,An app to learn French Language created using PyQt5 and Python. Google speech recognition API's are used. One need authentication keys run the app.,Sumit1673,[],https://github.com/Sumit1673/PCApp,https://api.github.com/users/Sumit1673,https://api.github.com/repos/Sumit1673/PCApp,"Montreal, Quebec, Canada"
brawddegau-adnabod-lleferydd,Corpws brawddegau CC0 ar gyfer promptiau adnabod lleferydd Cymraeg // A corpus of CC0 licensed sentences as prompts for Welsh speech recognition training,techiaith,"['cymraeg', 'sentences', 'speech', 'welsh', 'welsh-speech-recognition']",https://github.com/techiaith/brawddegau-adnabod-lleferydd,https://api.github.com/users/techiaith,https://api.github.com/repos/techiaith/brawddegau-adnabod-lleferydd,Prifysgol Bangor University
Native-Speech-Recognition,"Code to use speech recognition to live update text on screen - Made as part of JavaScript30, 30 day vanilla JS coding challenge.",slenane,[],https://github.com/slenane/Native-Speech-Recognition,https://api.github.com/users/slenane,https://api.github.com/repos/slenane/Native-Speech-Recognition,Ireland
Speech-Recognition,This is basically a speech recognition notepad. To run this application you need to run it on localhost:300 or npm,abhijeet-26,[],https://github.com/abhijeet-26/Speech-Recognition,https://api.github.com/users/abhijeet-26,https://api.github.com/repos/abhijeet-26/Speech-Recognition,kolkata
Lucy,"# Lucy ## For Demo click here : https://voiceassistance.netlify.app/ An intelligent virtual assistant (IVA) or intelligent personal assistant (IPA) is a software agent that can perform tasks or services for an individual based on commands or questions. Sometimes the term ""chatbot"" is used to refer to virtual assistants generally or specifically accessed by online chat. In some cases, online chat programs are exclusively for entertainment purposes. Some virtual assistants are able to interpret human speech and respond via synthesized voices. Users can ask their assistants questions, control home automation devices and media playback via voice, and manage other basic tasks such as email, to-do lists, and calendars with verbal (spoken?) commands.[1] A similar concept, however with differences, lays under the dialogue systems.   ## screenshot   ![image](https://raw.githubusercontent.com/ZiaCodes/Lucy/master/Assets/example/Lucy%20Voice%20Assistance%20-%20Google%20Chrome%2031-07-2020%2001_48_59.png)   # Installation  > git clone https://github.com/ZiaCodes/Lucy.git   ## Technologies Used > HTML5 > CSS3 > Javascript > Web Speech recognition API   ## Lucy is an open source so you can also download and customize according to your workflow.   ### Downloading Link : https://github.com/ZiaCodes/Lucy/archive/master.zip",ZiaCodes,"['hacktoberfest', 'hacktoberfest2021', 'html', 'lucy-bot', 'web-speech-api']",https://github.com/ZiaCodes/Lucy,https://api.github.com/users/ZiaCodes,https://api.github.com/repos/ZiaCodes/Lucy,"jalpaiguri,India"
TellMeWhereRecognitionApp,It is the Android App where we use speech recognition. And Whatever country or place speaks up then the map will show that location. In this we use Recognizer Intent to get content for supporting speech recognition through starting an Intent. And to use google map we use the google map API. And use geocoder to get latitude and longitude from the name of the place and show the location with maximum confidence level on map.,Himanshu-Singh-Bisht,[],https://github.com/Himanshu-Singh-Bisht/TellMeWhereRecognitionApp,https://api.github.com/users/Himanshu-Singh-Bisht,https://api.github.com/repos/Himanshu-Singh-Bisht/TellMeWhereRecognitionApp,"Delhi , India"
gluon_bLNet,"Proposed in ""Big-Little Net: An Efficient Multi-Scale Feature Representation for Visual and Speech Recognition"" is a novel architecture for learning multi-scale feature representations with good tradeoffs between speed and accuracy.",aptsunny,[],https://github.com/aptsunny/gluon_bLNet,https://api.github.com/users/aptsunny,https://api.github.com/repos/aptsunny/gluon_bLNet,Shanghai
alan-ai-news-app,This is Conversational Voice Controlled React News Application using Alan AI. Alan AI is a revolutionary speech recognition software that allows you to add voice capabilities to your applications. I built using React JS.,ppm143,[],https://github.com/ppm143/alan-ai-news-app,https://api.github.com/users/ppm143,https://api.github.com/repos/ppm143/alan-ai-news-app,Gandhinagar
probability-and-statistics-with-python-,"Statistics in computer science are used for a number of things, including data mining, data compression and speech recognition. Other areas where statistics are use in computer science include vision and image analysis, artificial intelligence and network and traffic modeling.",iffishells,[],https://github.com/iffishells/probability-and-statistics-with-python-,https://api.github.com/users/iffishells,https://api.github.com/repos/iffishells/probability-and-statistics-with-python-,Pakistan Islamabad
ReactJS_NewsAPP_With_ALANAI,A Voice Controlled React News Application made with the help of Alan AI which is a  speech recognition software that allows us to add voice capabilities to our applications.,centipede13,"['newsapi', 'react', 'reactjs', 'reactproject', 'voice-assistant']",https://github.com/centipede13/ReactJS_NewsAPP_With_ALANAI,https://api.github.com/users/centipede13,https://api.github.com/repos/centipede13/ReactJS_NewsAPP_With_ALANAI,Noida
Rambo,"A virtual assistant made with python using packages like ‘speech_recognition’, ‘pyttsx3’, ‘pywhatkit’. It can be used to perform many tasks like gathering information, play songs, send messages, open applications etc.",kumarlalitroushan,[],https://github.com/kumarlalitroushan/Rambo,https://api.github.com/users/kumarlalitroushan,https://api.github.com/repos/kumarlalitroushan/Rambo,Bhagalpur
alan-news-app,Alan news app is Conversational Voice Controlled React News Application using Alan AI. Alan AI is a revolutionary speech recognition software that allows you to add voice capabilities to your applications.,shekhtausif8090,[],https://github.com/shekhtausif8090/alan-news-app,https://api.github.com/users/shekhtausif8090,https://api.github.com/repos/shekhtausif8090/alan-news-app,Pune
Desktop_Voice_Assistant,"A desktop voice assistant is a digital assistant that uses voice recognition, speech synthesis, and natural language processing (NLP) to provide a service through a particular application. Its create with python language.",nakib33,[],https://github.com/nakib33/Desktop_Voice_Assistant,https://api.github.com/users/nakib33,https://api.github.com/repos/nakib33/Desktop_Voice_Assistant,"Sylhet, Bangladesh"
Persional-assistance,This is my first project i made it using module in python speech_recognition and Wikipedia. This is basically a personal assistance like google assitance in google or siri in apple.  ,avator7,[],https://github.com/avator7/Persional-assistance,https://api.github.com/users/avator7,https://api.github.com/repos/avator7/Persional-assistance,India
Speech-Recognition,"This repository contains all source files and additional assets of Speech Recognition system. In this project, we are using basic python libraries to obtain 70-80% accuracy of our system.",Tirth132108,"['speech-processing', 'speech-recognition', 'speech-synthesis']",https://github.com/Tirth132108/Speech-Recognition,https://api.github.com/users/Tirth132108,https://api.github.com/repos/Tirth132108/Speech-Recognition,Ahmedabad 
SER-models,This repository is an import of the original repository that contains some of the models we had tested on the RAVDESS and TESS dataset for our research on Speech Emotion Recognition Models.,niveditapatel,"['alexnet', 'cnn', 'dataset', 'deeplearning', 'deeplearning-notebooks', 'jupyter-notebook', 'ravdess', 'ravdess-dataset', 'resnet-50', 'svm', 'tess']",https://github.com/niveditapatel/SER-models,https://api.github.com/users/niveditapatel,https://api.github.com/repos/niveditapatel/SER-models,"Ahmedabad, India"
Voice-AI-in-NodeMCU,"A virtual desktop assistant can perform different tasks without any physical intervention with keyboard and mouse. The system takes the voice commands of the user, analyzes the commands using speech recognition technology and acts accordingly.",AnbuKumar-maker,[],https://github.com/AnbuKumar-maker/Voice-AI-in-NodeMCU,https://api.github.com/users/AnbuKumar-maker,https://api.github.com/repos/AnbuKumar-maker/Voice-AI-in-NodeMCU,India
JarvisMyDesktopAssistant,"I made a desktop assistant which is capable of opening wikipedia, youtube and google on users command. It also greets the user according to time. I have used modules like pyttsx3, datetime, speech_recognition, wikipedia, webbrowser in this project.",Chelsi-create,[],https://github.com/Chelsi-create/JarvisMyDesktopAssistant,https://api.github.com/users/Chelsi-create,https://api.github.com/repos/Chelsi-create/JarvisMyDesktopAssistant,India
Speach-Recognition,"This is a simple speech recognition algorithm. This was a Learning Project, in which I learned how to apply machine learning to sounds, using concepts like Mfcc and the role of Fourier transform.",Sudhanshu1304,"['fourier-transform', 'speach-recognition', 'tensorflow']",https://github.com/Sudhanshu1304/Speach-Recognition,https://api.github.com/users/Sudhanshu1304,https://api.github.com/repos/Sudhanshu1304/Speach-Recognition,PUNE
DNN_Speech_Recognizer,"Build a deep neural network that functions as part of an end-to-end automatic speech recognition (ASR) pipeline. The model will convert raw audio into feature representations, which will then turn them into transcribed text.",AbdullahMu,[],https://github.com/AbdullahMu/DNN_Speech_Recognizer,https://api.github.com/users/AbdullahMu,https://api.github.com/repos/AbdullahMu/DNN_Speech_Recognizer,"Riyadh, Saudi Arabia"
Arabic-Speech-Recognition-Dataset,"This data was collected as part of the Speech Recognition course during the African Master's in Machine Intelligence, taught by Emmanuel Dupoux, Laurent Besacier, Gabriel Synnaeve and Neil Zeghidour.",AhmedMnsour,[],https://github.com/AhmedMnsour/Arabic-Speech-Recognition-Dataset,https://api.github.com/users/AhmedMnsour,https://api.github.com/repos/AhmedMnsour/Arabic-Speech-Recognition-Dataset,Accra
Siri2.0,"A ’Siri’-like iOS app that uses Google Cloud’s Speech Recognition service and MS LUIS for conversational abilities, and a Flask server that consumes WolframAlpha's API for general intelligence.",Sanshit-sagar,[],https://github.com/Sanshit-sagar/Siri2.0,https://api.github.com/users/Sanshit-sagar,https://api.github.com/repos/Sanshit-sagar/Siri2.0,"La Jolla, CA"
Sentence-Detection,"The task of sentence boundary detection is to identify sentences within a text. Many natural language processing tasks take a sentence as an input unit, such as part-of-speech tagging, dependency parsing, named entity recognition or machine translation.",Mann1904,[],https://github.com/Mann1904/Sentence-Detection,https://api.github.com/users/Mann1904,https://api.github.com/repos/Mann1904/Sentence-Detection,Ahmedabad
Jasmine-Mini-Alexa-,"This is a Program like Alexa. In this, I used python packages like speech recognition, pyttsx3, Wikipedia, pywhatkit, etc. Users can command to play anything on youtube, search on google, also talk to you, ask for the current time, etc.",akash-kaushik,[],https://github.com/akash-kaushik/Jasmine-Mini-Alexa-,https://api.github.com/users/akash-kaushik,https://api.github.com/repos/akash-kaushik/Jasmine-Mini-Alexa-,Ghaziabad
Industry-Research,"Regarding some of the applications of the Internet in industry, including natural language processing, computer vision, recommendation systems, speech recognition, etc., we will gather the strengths of hundreds of companies and increase code capabilities.",DragonYong,"['cv', 'nlp-machine-learning', 'speaker', 'tensorflow2', 'torch']",https://github.com/DragonYong/Industry-Research,https://api.github.com/users/DragonYong,https://api.github.com/repos/DragonYong/Industry-Research,BeiJing
Virtual-Assistant---GWEN,"Gwen is an autonomous virtual assistant created using python. It is a digital companion, that can assist you anytime, anywhere with its perplexing abilities. The coalescence of Speech Recognition, Code Algorithm with various python packages and text to speech converter makes this program fully autonomous.",AnuragSen23,[],https://github.com/AnuragSen23/Virtual-Assistant---GWEN,https://api.github.com/users/AnuragSen23,https://api.github.com/repos/AnuragSen23/Virtual-Assistant---GWEN,Chennai India
voice-translation-using-python-and-google-api,This Project is built from python and google API where i have used speech_recognition as spr(to translate voice in to Text) googletrans import Translator(to convert Text from one language to another language) gtts import gTTS(to convert text to voice using google text to speech api),saurav5101998,[],https://github.com/saurav5101998/voice-translation-using-python-and-google-api,https://api.github.com/users/saurav5101998,https://api.github.com/repos/saurav5101998/voice-translation-using-python-and-google-api,Jalandhar
SpeechToText,"In this project i have converted Speech to text with the help of Speech Recognition library, then by using NLP toolkit i converted that text to sentence and words and I have used Term frequency Inverse Document Frequency(TF-IDF) concept which reflect how important a word is.",lmudu2,[],https://github.com/lmudu2/SpeechToText,https://api.github.com/users/lmudu2,https://api.github.com/repos/lmudu2/SpeechToText,USA 
Speech-Recognition-using-Flask,"Speech recognition module is being imported in this project. Then I have used Flask to take in an audio file and create both GET and POST request on the same route. Finally, I have rendered the transcribed results of the speech file to the user.",debjbhow,[],https://github.com/debjbhow/Speech-Recognition-using-Flask,https://api.github.com/users/debjbhow,https://api.github.com/repos/debjbhow/Speech-Recognition-using-Flask,"Kolkata, India"
Must-read-papers-on-GNN,"""I think the first wave of deep learning progress was mainly big companies with a ton of data training very large neural networks, right? So if you want to build a speech recognition system, train it on 100,000 hours of data."" ― Andrew Ng",manjunath5496,[],https://github.com/manjunath5496/Must-read-papers-on-GNN,https://api.github.com/users/manjunath5496,https://api.github.com/repos/manjunath5496/Must-read-papers-on-GNN,"Bangalore, India"
VOICE-based-React-News-Application,A Conversational Voice Controlled React News Application using Alan AI. Alan AI is a revolutionary speech recognition software that allows you to add voice capabilities to your applications. It allows you to control absolutely everything in the app using your voice. ,navjyot18,[],https://github.com/navjyot18/VOICE-based-React-News-Application,https://api.github.com/users/navjyot18,https://api.github.com/repos/navjyot18/VOICE-based-React-News-Application,"yavatmal, maharashtra"
Alan_ai_news_application,"Alan AI is a revolutionary speech recognition software that allows you to add voice capabilities to your applications. It allows you to control absolutely everything in the app using your voice. Another huge benefit is that it's extremely easy to integrate it. We'll do it together in this video and afterward, you'll be able to create your own voice-controlled apps.  ",piyushgupta428,[],https://github.com/piyushgupta428/Alan_ai_news_application,https://api.github.com/users/piyushgupta428,https://api.github.com/repos/piyushgupta428/Alan_ai_news_application,United States
flair-python,"Flair is a library for state-of-the-art NLP developed by Zalando Research. It’s built in Python on top of the PyTorch framework. Flair allows for the application of state-of-the-art NLP models to text, such as named entity recognition (NER), part-of-speech tagging (PoS), sense disambiguation, and classification",SaifAlmaliki,"['deep-learning', 'flair', 'nlp', 'pytorch', 'text-classification']",https://github.com/SaifAlmaliki/flair-python,https://api.github.com/users/SaifAlmaliki,https://api.github.com/repos/SaifAlmaliki/flair-python,"Duisburg, Germany"
Speaker_identification_Biometric_using_Voiceit2_API_2.0,"Speaker identification is the process of authenticating the speaker's true identity, i.e. the process of automatically recognizing a speaker based on the information contained in each speech wave. This is one of the biometrics applications. This technique allows the speaker's voice to be used to verify his identity. Speaker recognition is done in four steps. The first step is the acquisition of digital data. In the second stage, the function is extracted. The third step involves grouping feature vectors and storing them in the database. The final step is making decisions by matching the pattern. The speaker recognition process involves two different modules, such as Function extraction and function matching. In our project, we used the Mela frequency cepstrum factor (MFCC) method for feature extraction and vector quantization (VQ) for feature matching. The goal of this project is to build a simple and complete speaker recognition system that is tested on a speech database and we use the Voiceit2 API 2,0 and Tkinter for demonstration. The complete system is built into the PYTHON Platform.",rvsolanki97,[],https://github.com/rvsolanki97/Speaker_identification_Biometric_using_Voiceit2_API_2.0,https://api.github.com/users/rvsolanki97,https://api.github.com/repos/rvsolanki97/Speaker_identification_Biometric_using_Voiceit2_API_2.0,Frankfurt am main
ML_Coursera,"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI.",milinbhade1214,[],https://github.com/milinbhade1214/ML_Coursera,https://api.github.com/users/milinbhade1214,https://api.github.com/repos/milinbhade1214/ML_Coursera,Amravati
Jarvis-Desktop-Assistant,"Made with Python libraries such as pyttsx3, datetime, speech recognition, wikipedia, webbrowser, os, smtplib. Jarvis is a raw python based app. A desktop app that can help you in your daily chores like writing your daily routine. It will also help you to google something, you will deliver command and it will find you the result, same as YouTube, Wikipedia. It can also help to send email over command.",stsharin,[],https://github.com/stsharin/Jarvis-Desktop-Assistant,https://api.github.com/users/stsharin,https://api.github.com/repos/stsharin/Jarvis-Desktop-Assistant,"Dhaka, Bangladesh"
AutomatedDetectionOfHateSpeechTowardsWomanOnTwitter,"Given the steadily growing body of social media content, hate speech towards women is increasing. Such kind of contents have the potential to cause harm and suffering on an individual basis, and they may lead to social tension and disorder beyond cyber space. To support the automatic detection of cyber hate online, specifically on Twitter, we build a supervised learning model which is developed to classify cyber hate towards woman on Twitter. Turkish tweets, with a hashtag specific to choice of clothing for women, have been collected and five machine learning based classification algorithms were applied including Support Vector Machines (using polynomial and RBF Kernel), J48, Naive Bayes, Random Forest and Random Tree. Preliminary results showed that hateful contents can be detected with high precision however more sophisticated approaches are necessary to improve recall. Keywords—Hate speech recognition, machine learning, classification, tf-idf",yaseminkilic,[],https://github.com/yaseminkilic/AutomatedDetectionOfHateSpeechTowardsWomanOnTwitter,https://api.github.com/users/yaseminkilic,https://api.github.com/repos/yaseminkilic/AutomatedDetectionOfHateSpeechTowardsWomanOnTwitter,Turkey
Machine-Learning---Sensor-Data-Analytics,"Employing machine learning to the sensors and signal data is making the devices smarter than ever. Get started with ML and Azure. Over the past few years, Deep Neural Networks have provided us the best results on a variety of problems, such as pattern recognition, computer vision, and Speech recognition and image classification.  Employing Machine Learning to the sensors and signal data is making the devices smarter than ever and is going to be a breakthrough in the field of IoT. Whether you are using sounds, vibrations, images, electrical signals or accelerometer or other kinds of sensor data, you can build richer analytics by teaching a machine to detect and classify events happening in real-time, at the edge, using an inexpensive micro controller for processing - even with noisy, high variation data.",AnbuKumar-maker,[],https://github.com/AnbuKumar-maker/Machine-Learning---Sensor-Data-Analytics,https://api.github.com/users/AnbuKumar-maker,https://api.github.com/repos/AnbuKumar-maker/Machine-Learning---Sensor-Data-Analytics,India
LinuxWorld2k18-DETECTING-AND-CATEGORISING-OF-DEPRESSION-,"The project aims at developing a market ready product service for RHEL clients which can be used to provide a service which includes detecting and categorising of DEPRESSION in client and help them to get out of that situation by providing other number of services in a safe and secure way. The project is a python-cgi implementation of a number of Cloud Services aiming at providing the clients means for CLOUD COMPUTING. It also included the implementation of Distributed Computing using Hadoop framework to resolve the issue of Big Data. Along with this, the services for the client is secured by Face recognition using machine learning and include parts of speech production and recognition using Python Modules. Skills Used: Docker, Machine Learning, Python, PAAS, SAAS, Ansible, HTML, CGI",ravi-kumar12,[],https://github.com/ravi-kumar12/LinuxWorld2k18-DETECTING-AND-CATEGORISING-OF-DEPRESSION-,https://api.github.com/users/ravi-kumar12,https://api.github.com/repos/ravi-kumar12/LinuxWorld2k18-DETECTING-AND-CATEGORISING-OF-DEPRESSION-,Kolkata
DIMENSIONALITY-REDUCTION-EXPERIMENT,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension. Working in high-dimensional spaces can be undesirable for many reasons; raw data are often sparse as a consequence of the curse of dimensionality, and analyzing the data is usually computationally intractable. Dimensionality reduction is common in fields that deal with large numbers of observations and/or large numbers of variables, such as signal processing, speech recognition, neuroin formatics, and bioinformatics.",Man-ash,[],https://github.com/Man-ash/DIMENSIONALITY-REDUCTION-EXPERIMENT,https://api.github.com/users/Man-ash,https://api.github.com/repos/Man-ash/DIMENSIONALITY-REDUCTION-EXPERIMENT,India
Deep-Machine-Learning,"The purpose with this course is to give a thorough introduction to deep machine learning, also known as deep learning or deep neural networks. Over the last few years, deep machine learning has dramatically changed the state of the art performance in various fields including speech-recognition, computer vision and reinforcement learning (used, e.g., to learn how to play Go). We focus primarily on basic principles regarding how these networks are constructed and trained, but we also cover many of the key techniques used in different applications. The overall objective is to provide a solid understanding of how and why deep machine learning is useful, as well as the skills to apply them to solve problems of practical importance.",ellgui,[],https://github.com/ellgui/Deep-Machine-Learning,https://api.github.com/users/ellgui,https://api.github.com/repos/ellgui/Deep-Machine-Learning,Gothenburg
An-ANN,"An ANN is a model based on a collection of connected units or nodes called ""artificial neurons"", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.  The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.  Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[68]",Aryia-Behroziuan,[],https://github.com/Aryia-Behroziuan/An-ANN,https://api.github.com/users/Aryia-Behroziuan,https://api.github.com/repos/Aryia-Behroziuan/An-ANN,IRAN
neurons,"An ANN is a model based on a collection of connected units or nodes called ""artificial neurons"", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.  The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.  Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[68]  Decision trees Main article: Decision tree learning Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision making.  Support vector machines Main article: Support vector machines Support vector machines (SVMs), also known as support vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category or the other.[69] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.   Illustration of linear regression on a data set. Regression analysis Main article: Regression analysis Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization (mathematics) methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[70]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.  Bayesian networks Main article: Bayesian network  A simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet. A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.  Genetic algorithms Main article: Genetic algorithm A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[71][72] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[73]  Training models Usually, machine learning models require a lot of data in order for them to perform well. Usually, when training a machine learning model, one needs to collect a large, representative sample of data from a training set. Data from the training set can be as varied as a corpus of text, a collection of images, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model.  Federated learning Main article: Federated learning Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[74]  Applications There are many applications for machine learning, including:  Agriculture Anatomy Adaptive websites Affective computing Banking Bioinformatics Brain–machine interfaces Cheminformatics Citizen science Computer networks Computer vision Credit-card fraud detection Data quality DNA sequence classification Economics Financial market analysis[75] General game playing Handwriting recognition Information retrieval Insurance Internet fraud detection Linguistics Machine learning control Machine perception Machine translation Marketing Medical diagnosis Natural language processing Natural language understanding Online advertising Optimization Recommender systems Robot locomotion Search engines Sentiment analysis Sequence mining Software engineering Speech recognition Structural health monitoring Syntactic pattern recognition Telecommunication Theorem proving Time series forecasting User behavior analytics In 2006, the media-services provider Netflix held the first ""Netflix Prize"" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[76] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (""everything is a recommendation"") and they changed their recommendation engine accordingly.[77] In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.[78] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors' jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[79] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.[80] In 2019 Springer Nature published the first research book created using machine learning.[81]  Limitations Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[82][83][84] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[85]  In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[86] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[87][88]  Bias Main article: Algorithmic bias Machine learning approaches in particular can suffer from different data biases. A machine learning system trained on current customers only may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on man-made data, machine learning is likely to pick up the same constitutional and unconscious biases already present in society.[89] Language models learned from data have been shown to contain human-like biases.[90][91] Machine learning systems used for criminal risk assessment have been found to be biased against black people.[92][93] In 2015, Google photos would often tag black people as gorillas,[94] and in 2018 this still was not well resolved, but Google reportedly was still using the workaround to remove all gorillas from the training data, and thus was not able to recognize real gorillas at all.[95] Similar issues with recognizing non-white people have been found in many other systems.[96] In 2016, Microsoft tested a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[97] Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[98] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who reminds engineers that ""There’s nothing artificial about AI...It’s inspired by people, it’s created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.”[99]  Model assessments Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[100]  In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).[101]  Ethics Machine learning poses a host of ethical questions. Systems which are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.[102] For example, using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants against similarity to previous successful applicants.[103][104] Responsible collection of data and documentation of algorithmic rules used by a system thus is a critical part of machine learning.  Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[105][106]  Other forms of ethical challenges, not related to personal biases, are more seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is huge potential for machine learning in health care to provide professionals a great tool to diagnose, medicate, and even plan recovery paths for patients, but this will not happen until the personal biases mentioned previously, and these ""greed"" biases are addressed.[107]  Hardware Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units.[108] By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[109] OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[110][111]  Software Software suites containing a variety of machine learning algorithms include the following:  Free and open-source so",Aryia-Behroziuan,"['an-ann', 'android', 'artificial-intelligence', 'aryia-behroziuan', 'bootstrap', 'csharp', 'deep-learning', 'expressjs', 'firebase', 'neural-network', 'wikipedia']",https://github.com/Aryia-Behroziuan/neurons,https://api.github.com/users/Aryia-Behroziuan,https://api.github.com/repos/Aryia-Behroziuan/neurons,IRAN
Models,"rtificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems ""learn"" to perform tasks by considering examples, generally without being programmed with any task-specific rules.  An ANN is a model based on a collection of connected units or nodes called ""artificial neurons"", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.  The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.  Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[68]",Aryia-Behroziuan,[],https://github.com/Aryia-Behroziuan/Models,https://api.github.com/users/Aryia-Behroziuan,https://api.github.com/repos/Aryia-Behroziuan/Models,IRAN
Deep-Learning,"Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised. Deep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, machine vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance. Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog. The adjective ""deep"" in deep learning comes from the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, and then that a network with a nonpolynomial activation function with one hidden layer of unbounded width can on the other hand so be. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the ""structured"" part.",aaaastark,[],https://github.com/aaaastark/Deep-Learning,https://api.github.com/users/aaaastark,https://api.github.com/repos/aaaastark/Deep-Learning,"Lahore, Pakistan"
Robot-learning,"In developmental robotics, robot learning algorithms generate their own sequences of learning experiences, also known as a curriculum, to cumulatively acquire new skills through self-guided exploration and social interaction with humans. These robots use guidance mechanisms such as active learning, maturation, motor synergies and imitation.  Association rules Main article: Association rule learning See also: Inductive logic programming Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of ""interestingness"".[60]  Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves ""rules"" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[61] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.  Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[62] For example, the rule {\displaystyle \{\mathrm {onions,potatoes} \}\Rightarrow \{\mathrm {burger} \}}\{{\mathrm  {onions,potatoes}}\}\Rightarrow \{{\mathrm  {burger}}\} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.  Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[63]  Inductive logic programming (ILP) is an approach to rule-learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.  Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[64][65][66] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[67] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.  Models Performing machine learning involves creating a model, which is trained on some training data and then can process additional data to make predictions. Various types of models have been used and researched for machine learning systems.  Artificial neural networks Main article: Artificial neural network See also: Deep learning  An artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another. Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems ""learn"" to perform tasks by considering examples, generally without being programmed with any task-specific rules.  An ANN is a model based on a collection of connected units or nodes called ""artificial neurons"", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a ""signal"", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called ""edges"". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.  The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.  Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[68]",Aryia-Behroziuan,"['android', 'artificial-intelligence', 'aryia-behroziuan', 'blog', 'csharp', 'data-science', 'express', 'flask', 'golang', 'machine-learning', 'nodejs', 'python', 'robot-learning']",https://github.com/Aryia-Behroziuan/Robot-learning,https://api.github.com/users/Aryia-Behroziuan,https://api.github.com/repos/Aryia-Behroziuan/Robot-learning,IRAN
Ai-assistant,"import speech_recognition as sr  import playsound  from gtts import gTTS  import random from time import ctime  import webbrowser  import yfinance as yf  import ssl import certifi import time import os   class person:     name = ''     def setName(self, name):         self.name = name  def there_exists(terms):     for term in terms:         if term in voice_data:             return True  r = sr.Recognizer()  def record_audio(ask=False):     with sr.Microphone() as source:          if ask:             speak(ask)         audio = r.listen(source)          voice_data = ''         try:             voice_data = r.recognize_google(audio)           except sr.UnknownValueError:              speak('I did not get that')         except sr.RequestError:             speak('Sorry, the service is down')          print(f"">> {voice_data.lower()}"")         return voice_data.lower()  def speak(audio_string):     tts = gTTS(text=audio_string, lang='en')      r = random.randint(1,20000000)     audio_file = 'audio' + str(r) + '.mp3'     tts.save(audio_file)      playsound.playsound(audio_file)      print(f""kiri: {audio_string}"")     os.remove(audio_file)   def respond(voice_data):          if there_exists(['hey','hi','hello']):         greetings = [f""hey, how can I help you {person_obj.name}"", f""hey, what's up? {person_obj.name}"", f""I'm listening {person_obj.name}"", f""how can I help you? {person_obj.name}"", f""hello {person_obj.name}""]         greet = greetings[random.randint(0,len(greetings)-1)]         speak(greet)          if there_exists([""what is your name"",""what's your name"",""tell me your name""]):         if person_obj.name:             speak(""my name is kyle"")         else:             speak(""my name is kyle . what's your name?"")      if there_exists([""my name is""]):         person_name = voice_data.split(""is"")[-1].strip()         speak(f""okay, i will remember that {person_name}"")         person_obj.setName(person_name)            if there_exists([""how are you"",""how are you doing""]):         speak(f""I'm very well, thanks for asking {person_obj.name}"")           if there_exists([""what's the time"",""tell me the time"",""what time is it""]):         time = ctime().split("" "")[3].split("":"")[0:2]         if time[0] == ""00"":             hours = '12'         else:             hours = time[0]         minutes = time[1]         time = f'{hours} {minutes}'         speak(time)           if there_exists([""search for""]) and 'youtube' not in voice_data:         search_term = voice_data.split(""for"")[-1]         url = f""https://google.com/search?q={search_term}""         webbrowser.get().open(url)         speak(f'Here is what I found for {search_term} on google')           if there_exists([""youtube""]):         search_term = voice_data.split(""for"")[-1]         url = f""https://www.youtube.com/results?search_query={search_term}""         webbrowser.get().open(url)         speak(f'Here is what I found for {search_term} on youtube')           if there_exists([""price of""]):         search_term = voice_data.lower().split("" of "")[-1].strip()          stocks = {             ""apple"":""AAPL"",             ""microsoft"":""MSFT"",             ""facebook"":""FB"",             ""tesla"":""TSLA"",             ""bitcoin"":""BTC-USD""         }         try:             stock = stocks[search_term]             stock = yf.Ticker(stock)             price = stock.info[""regularMarketPrice""]              speak(f'price of {search_term} is {price} {stock.info[""currency""]} {person_obj.name}')         except:             speak('oops, something went wrong')     if there_exists([""exit"", ""quit"", ""goodbye""]):         speak(""going offline"")         exit()   time.sleep(1)  person_obj = person() while(1):     voice_data = record_audio()      respond(voice_data) ",musty449,[],https://github.com/musty449/Ai-assistant,https://api.github.com/users/musty449,https://api.github.com/repos/musty449/Ai-assistant,"istanbul, Turkey"
ai,"Artificial intelligence From Wikipedia, the free encyclopedia Jump to navigationJump to search ""AI"" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation). Part of a series on Artificial intelligence Major goals[show] Approaches[show] Philosophy[show] History[show] Technology[show] Glossary[show] vte Artificial intelligence (AI), is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of ""intelligent agents"": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.[3] Colloquially, the term ""artificial intelligence"" is often used to describe machines (or computers) that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"".[4]  As machines become increasingly capable, tasks considered to require ""intelligence"" are often removed from the definition of AI, a phenomenon known as the AI effect.[5] A quip in Tesler's Theorem says ""AI is whatever hasn't been done yet.""[6] For instance, optical character recognition is frequently excluded from things considered to be AI,[7] having become a routine technology.[8] Modern machine capabilities generally classified as AI include successfully understanding human speech,[9] competing at the highest level in strategic game systems (such as chess and Go),[10] autonomously operating cars, intelligent routing in content delivery networks, and military simulations.[11]  Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism,[12][13] followed by disappointment and the loss of funding (known as an ""AI winter""),[14][15] followed by new approaches, success and renewed funding.[13][16] For most of its history, AI research has been divided into sub-fields that often fail to communicate with each other.[17] These sub-fields are based on technical considerations, such as particular goals (e.g. ""robotics"" or ""machine learning""),[18] the use of particular tools (""logic"" or artificial neural networks), or deep philosophical differences.[21][22][23] Sub-fields have also been based on social factors (particular institutions or the work of particular researchers).[17]  The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.[18] General intelligence is among the field's long-term goals.[24] Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.  The field was founded on the assumption that human intelligence ""can be so precisely described that a machine can be made to simulate it"".[25] This raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity.[30] Some people also consider AI to be a danger to humanity if it progresses unabated.[31][32] Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.[33]  In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.[34][16]",Aryia-Behroziuan,[],https://github.com/Aryia-Behroziuan/ai,https://api.github.com/users/Aryia-Behroziuan,https://api.github.com/repos/Aryia-Behroziuan/ai,IRAN